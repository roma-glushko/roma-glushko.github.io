<!DOCTYPE html><html lang="en" class="blogpost-view-page"><head><meta charSet="utf-8"/><meta http-equiv="x-ua-compatible" content="ie=edge"/><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/><style data-href="/styles.f14b81060f62ed5dfbd5.css">code[class*=language-],pre[class*=language-]{color:#f8f8f2;background:none;text-shadow:0 1px rgba(0,0,0,.3);font-family:Consolas,Monaco,Andale Mono,Ubuntu Mono,monospace;font-size:1em;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;word-wrap:normal;line-height:1.5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-ms-hyphens:none;hyphens:none}pre[class*=language-]{padding:1em;margin:.5em 0;overflow:auto;border-radius:.3em}:not(pre)>code[class*=language-],pre[class*=language-]{background:#272822}:not(pre)>code[class*=language-]{padding:.1em;border-radius:.3em;white-space:normal}.token.cdata,.token.comment,.token.doctype,.token.prolog{color:#8292a2}.token.punctuation{color:#f8f8f2}.token.namespace{opacity:.7}.token.constant,.token.deleted,.token.property,.token.symbol,.token.tag{color:#f92672}.token.boolean,.token.number{color:#ae81ff}.token.attr-name,.token.builtin,.token.char,.token.inserted,.token.selector,.token.string{color:#a6e22e}.language-css .token.string,.style .token.string,.token.entity,.token.operator,.token.url,.token.variable{color:#f8f8f2}.token.atrule,.token.attr-value,.token.class-name,.token.function{color:#e6db74}.token.keyword{color:#66d9ef}.token.important,.token.regex{color:#fd971f}.token.bold,.token.important{font-weight:700}.token.italic{font-style:italic}.token.entity{cursor:help}.view-page-header-wrapper{display:flex;justify-content:center}.view-page-header-wrapper .logo-wrapper{align-items:center;display:flex}.view-page-header-wrapper .logo{border:1px solid var(--avatarBorderColor);border-radius:50%;height:90px;-webkit-user-select:none;-ms-user-select:none;user-select:none;width:90px}.view-page-header-wrapper .logo-img{width:5rem;height:auto;border-radius:50%;transform:translate(5px,5px);-ms-transform:translate(5px,5px);-webkit-transform:translate(5px,5px)}.view-page-header-wrapper .name{font-size:2rem;padding-left:.5rem;margin-top:.2rem;margin-bottom:.2rem}.view-page-header-wrapper .blog-title{color:var(--thoughtsPageTitleColor);font-family:Dancing Script,cursive;font-size:4rem;font-weight:700;margin-top:auto;margin-bottom:auto;padding-left:1.5rem;text-align:center}@media (max-width:575px){.view-page-header-wrapper .blog-title{font-size:3rem;line-height:3rem;padding-left:1rem}.view-page-header-wrapper .name{font-size:1.5rem}.view-page-header-wrapper .logo{width:90px;height:90px}.view-page-header-wrapper .logo-img{width:5rem}}.view-page-header-wrapper .blog-title a{color:var(--thoughtsPageTitleColor)}.thought-author-wrapper{text-align:center}.thought-author-wrapper .avatar{margin:0 auto;border-radius:50%;width:122px;height:122px;border:1px solid var(--avatarBorderColor)}.thought-author-wrapper .logo-img{width:7rem;height:auto;border-radius:50%;transform:translate(5px,5px);-ms-transform:translate(5px,5px);-webkit-transform:translate(5px,5px)}.thought-author-wrapper .name{font-size:2rem;margin-top:.2rem;margin-bottom:.2rem}.thought-author-wrapper .thought-section-descr{font-size:.9rem;margin-top:0;margin-bottom:0}.main-navigation ul{display:flex;justify-content:center;padding-left:0;text-align:center}.main-navigation ul li{list-style:none;text-transform:lowercase}.main-navigation ul:last-child:after,.main-navigation ul li:before{content:"\2022";padding-left:5px;vertical-align:middle}.main-navigation ul:last-child:after{line-height:25px}.main-navigation ul li a{padding-left:5px;vertical-align:middle}body{--themeSwitcherTrackBackgroundColor:var(--grey);--themeSwitcherThumbBackgroundColor:var(--white)}body.dark{--themeSwitcherTrackBackgroundColor:var(--midnightDarker);--themeSwitcherThumbBackgroundColor:var(--grey)}.theme-switcher{text-align:center}.theme-switcher-toggler{touch-action:pan-x;display:inline-block;position:relative;cursor:pointer;background-color:transparent;border:0;padding:0;-webkit-touch-callout:none;-webkit-user-select:none;-ms-user-select:none;user-select:none}.theme-switcher-track{width:50px;height:24px;padding:0;border-radius:30px;background-color:var(--themeSwitcherTrackBackgroundColor);transition:all .2s ease}.theme-switcher-toggler--checked .theme-switcher-thumb{transform:translateX(26px)}.theme-switcher-thumb{position:absolute;top:1px;left:1px;width:22px;height:22px;border-radius:50%;background-color:var(--themeSwitcherThumbBackgroundColor);box-sizing:border-box;transition:all .5s cubic-bezier(.23,1,.32,1) 0ms;transform:translateX(0)}.theme-switcher-input{display:none}body{--contentTextColor:var(--black);--contentNavColor:grey}body.dark{--contentTextColor:var(--white);--contentNavColor:#8b949e}.blog-content-nav-wrapper{height:100%}.blog-content-nav-wrapper h2{margin-bottom:.3rem;margin-left:-1.5rem}.blog-content-nav-wrapper ul.blog-content-nav{color:var(--contentNavColor);list-style:decimal;margin:0;padding-left:1.5rem;padding-right:1rem;position:-webkit-sticky;position:sticky;top:1rem}.blog-content-nav-wrapper ul.blog-content-nav:hover{color:var(--gray)}.blog-content-nav-wrapper ul.blog-content-nav li a{color:var(--contentNavColor)}.blog-content-nav-wrapper ul.blog-content-nav li.active a{font-weight:700}.blog-content-nav-wrapper ul.blog-content-nav:hover li a{color:var(--gray)}@media (max-width:1200px){.blog-content-nav-wrapper h2{font-weight:500;letter-spacing:0;margin-top:0}.blog-content-nav-wrapper ul.blog-content-nav{color:var(--contentTextColor);font-size:1.4rem;letter-spacing:-.003em;line-height:1.6;margin-bottom:1.2rem;margin-top:0;text-align:justify}.blog-content-nav-wrapper ul.blog-content-nav li a{color:var(--contentTextColor)}.blog-content-nav-wrapper ul.blog-content-nav li.active a{font-weight:400}.blog-content-nav-wrapper ul.blog-content-nav li{margin-left:30px;margin-top:.8em}}body{--blogHeaderColor:var(--red);--blogTagColor:grey}body.dark{--blogHeaderColor:var(--pink);--blogTagColor:var(--grey)}.blog-wrapper header{max-width:43rem;margin:auto;padding:1rem}.blog-wrapper h1{color:var(--blogHeaderColor);font-size:3rem;line-height:4rem;margin-bottom:1rem;margin-top:1rem;text-align:center}@media (max-width:575px){.blog-wrapper h1{font-size:2rem;line-height:3rem}}.blog-wrapper .blog-details{margin-bottom:1rem}.blog-wrapper .blog-createdat{font-weight:400}.blog-wrapper .theme-switcher{float:right;margin-left:1rem;margin-top:0}.blog-wrapper .cover,.blog-wrapper .cover-filter{left:50%;margin-left:-50vw;overflow:hidden;position:relative;width:100vw}.blog-wrapper .cover{max-height:600px}ul.blog-tags{display:flex;font-size:.9rem;flex-direction:row;flex-wrap:wrap;justify-content:center;list-style:none;padding:0;text-align:center}ul.blog-tags li{border:1px solid var(--blogTagColor);border-radius:4px;color:var(--blogTagColor);padding:5px 10px;margin-right:5px;margin-bottom:5px;white-space:nowrap}.blog-wrapper .content-wrapper{display:grid;grid-template-columns:1fr 43rem 1fr;margin:auto 0;padding:1rem}@media (max-width:1200px){.blog-wrapper .content-wrapper{display:block}}body{--thoughtHeaderColor:var(--red)}body.dark{--thoughtHeaderColor:var(--pink)}.thought-wrapper h1{color:var(--thoughtHeaderColor);font-size:3rem;line-height:4rem;margin-bottom:1rem;margin-top:1rem;text-align:center}@media (max-width:575px){.thought-wrapper h1{font-size:2rem;line-height:3rem}}.thought-wrapper .thought-details{font-size:.9rem;margin-bottom:1rem}.thought-wrapper .thought-createdat{font-weight:400}.thought-wrapper .theme-switcher{float:right;margin-left:1rem;margin-top:0}.thought-wrapper .cover,.thought-wrapper .cover-filter{left:50%;margin-left:-50vw;overflow:hidden;position:relative;width:100vw}.thought-wrapper .cover{max-height:600px}body{--backquoteBorderColor:var(--red);--imageTitleColor:grey}body.dark{--backquoteBorderColor:var(--pink);--imageTitleColor:#8b949e}.content h2,.content h3,.content h4,.content h5,.content h6{font-weight:500;letter-spacing:0;margin-top:1.95em;margin-bottom:-.3em}.content h2:first-of-type{margin-top:0}.content,.content p{font-size:1.4rem;letter-spacing:-.003em;line-height:1.6;margin-bottom:1.2rem;margin-top:.5rem;text-align:justify}.content p{margin-top:2rem}.content p:first-letter{padding-left:1.5rem}.content ul{padding:0}.content ul ol{padding:0;margin:0}.content a{text-decoration:underline}.content ol li,.content ul li{margin-left:30px;margin-top:.8em}.content blockquote{box-shadow:var(--backquoteBorderColor) 3px 0 0 0 inset;font-size:1.3rem;font-style:italic;line-height:1.7;margin-left:-20px;padding-left:20px}@media (max-width:1200px){.content h2 .anchor{display:none}}@media (max-width:575px){.content blockquote{margin:.5rem}}.content .image-title{text-align:center}.content .image-title,.content .image-title a{color:var(--imageTitleColor);font-size:1.1rem}.content .gatsby-highlight{font-size:1rem}body{--blogNavigationLinkColor:var(--red);--allPostsNavigationLinkColor:var(--black)}body.dark{--blogNavigationLinkColor:var(--pink);--allPostsNavigationLinkColor:var(--white)}.blog-navigation-wrapper{padding-left:1rem;padding-right:1rem}.blog-navigation-wrapper h3{font-size:1.5rem;text-align:center}.blog-navigation .nav-links{padding:0;text-align:center;width:100%}.blog-navigation .nav-links a{color:var(--blogNavigationLinkColor);display:block;font-weight:700;margin-bottom:.875rem;text-decoration:none}.blog-navigation a.all-posts{color:var(--allPostsNavigationLinkColor)}body{--thoughtNavigationLinkColor:var(--red);--allThoughtsNavigationLinkColor:var(--black)}body.dark{--thoughtNavigationLinkColor:var(--pink);--allThoughtsNavigationLinkColor:var(--white)}.thought-navigation-wrapper{padding-left:1rem;padding-right:1rem}.thought-navigation .nav-links{padding:0;text-align:center;width:100%}.thought-navigation .nav-links a{color:var(--thoughtNavigationLinkColor);display:block;font-weight:700;margin-bottom:.875rem;text-decoration:none}.thought-navigation a.all-thoughts{color:var(--allThoughtsNavigationLinkColor)}body{--black:#000;--blackLigher:#262626;--red:#e74c3c;--brownDarker:#5a4e3e}body,body.dark{--white:#fff;--grey:#ebebeb}body.dark{--pink:#ffa7c4;--midnight:#373c49;--midnightDarker:rgba(0,0,0,0.27)}body{--bodyBackgroundColor:var(--white);--bodyTextColor:var(--black);--linkColor:var(--black);--linkHoverColor:var(--red);--thoughtCoverBlendColor:var(--brownDarker);--thoughtCoverBlendMode:lighten}body.dark{--bodyBackgroundColor:var(--midnight);--bodyTextColor:var(--white);--linkColor:var(--white);--linkHoverColor:var(--pink)}@font-face{font-family:Ledger;font-weight:400;font-style:normal;font-display:swap}html{scroll-behavior:smooth}body{color:var(--bodyTextColor);background-color:var(--bodyBackgroundColor);box-sizing:border-box;font-family:Ledger,serif;margin:0;text-rendering:optimizeLegibility;transition:color .2s ease-out,background .2s ease-out;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale}a{color:var(--linkColor);text-decoration:none}a:hover{color:var(--linkHoverColor)}.avatar{border:1px solid var(--avatarBorderColor);border-radius:50%;height:170px;margin:0 auto;-webkit-user-select:none;-ms-user-select:none;user-select:none;width:170px}.logo-img{border-radius:50%;width:10rem;height:auto;transform:translate(5px,5px)}.clearfix{clear:both}.cover-filter{background-color:var(--thoughtCoverBlendColor)}.cover-filter .cover{mix-blend-mode:var(--thoughtCoverBlendMode);-webkit-user-select:none;-ms-user-select:none;user-select:none}body.dark .cover-filter{-webkit-filter:brightness(.5);filter:brightness(.5)}.not-found-page body,.not-found-page body>div,.not-found-page body>div>div,.not-found-page body>div>div>div,html.not-found-page{height:100%}.not-found-page .row{flex-direction:column}.not-found-wrapper h1{font-size:2.5rem;margin-bottom:1rem;text-align:center;text-transform:uppercase}.not-found-wrapper{text-align:center}.not-found-wrapper p{margin:0}.not-found-wrapper .not-found-img{width:10rem;margin:0 auto;border-radius:50%}.not-found-wrapper .theme-switcher-toggler{margin-top:1rem}.blog-item{list-style:none;margin-bottom:2rem}.blog-item h2{font-size:1.6rem;line-height:2.4rem;margin-top:0;margin-bottom:.5rem}.blog-item h2 a{color:var(--thoughtTeaserHeaderLinkColor)}.blog-item p.blog-digest{font-size:1rem;line-height:1.6rem;margin-bottom:1.2rem;margin-top:.5rem}.blog-item .blog-details{font-size:.8rem;margin-bottom:.5rem}.blog-created-at{font-weight:600;text-transform:uppercase}.blog-item ul.blog-tags{font-size:.8rem;justify-content:start}.hero-header{background-size:cover;background-position:50%;height:40rem;position:relative;overflow:hidden;width:100%;z-index:1}.hero-header canvas{height:100%;width:100%}.hero-header h1.title{position:absolute;pointer-events:none;font-size:4rem;line-height:1.2;padding:0;margin:0;text-align:center;top:50%;width:100%;transform:translate3d(0,-50%,0)}.hero-header .title .highlight{color:var(--thoughtsPageTitleColor)}.hero-header .title .subscript{font-size:3rem}body{--liveCircleColorOn:rgba(231,76,60,0.2);--liveCircleColorOff:rgba(231,76,60,0)}body.dark{--liveCircleColor:rgba(255,167,196,0.5);--liveCircleColorOff:rgba(255,167,196,0)}.lab-header{background-size:cover;background-position:50%;height:40rem;position:relative;overflow:hidden;width:100%;z-index:1}.lab-header canvas{height:100%;width:100%}.lab-header h1.title{position:absolute;pointer-events:none;font-size:4rem;line-height:1.2;padding:0;margin:0;text-align:center;top:50%;width:100%;transform:translate3d(0,-50%,0)}.lab-header .title .highlight{color:var(--thoughtsPageTitleColor)}.lab-header .title .subscript{font-size:3rem;position:relative}.lab-header .title .after{font-size:3rem}.live-circle{background-color:var(--thoughtsPageTitleColor);border-radius:50%;position:absolute;right:-14px;top:14px;width:10px;height:10px}.pulse{animation:live-pulse 2s infinite}@keyframes live-pulse{0%{box-shadow:0 0 0 0 var(--liveCircleColorOn)}to{box-shadow:0 0 0 10px var(--liveCircleColorOff)}}.experiment-item{list-style:none;margin-bottom:2rem;text-align:center}.experiment-item h2{font-size:1.6rem;line-height:2.4rem;margin-top:0;margin-bottom:.5rem;width:100%}.experiment-item h2 a{color:var(--thoughtTeaserHeaderLinkColor);width:100%}.experiment-item p.blog-digest{font-size:1rem;line-height:1.6rem;margin-bottom:1.2rem;margin-top:.5rem}.experiment-item .blog-details{font-size:.8rem;margin-bottom:.5rem}.experiment-created-at{font-weight:600;text-transform:uppercase}.experiment-item .experiment-preview{text-align:center}.experiment-item .experiment-preview svg{color:var(--blackLigher);padding:1rem}body{--thoughtTeaserHeaderLinkColor:var(--red)}body.dark{--thoughtTeaserHeaderLinkColor:var(--pink)}.thought-item{list-style:none;margin-bottom:2rem}.thought-item h2{font-size:1.6rem;line-height:2.4rem;margin-top:0}.thought-item h2 a{color:var(--thoughtTeaserHeaderLinkColor)}.thought-item p.thought-digest{font-size:1rem;line-height:1.6rem;margin-bottom:1.2rem;margin-top:.5rem}.thought-item .thought-details{font-size:.8rem;margin-bottom:.5rem}.thought-createdat{font-weight:600;text-transform:uppercase}body{--secondNameColor:var(--red);--storyLinkColor:var(--red);--socialLinkBorderHoverColor:var(--red)}body,body.dark{--avatarBorderColor:var(--grey);--socialLinkBorderColor:var(--grey)}body.dark{--secondNameColor:var(--pink);--storyLinkColor:var(--pink);--socialLinkBorderHoverColor:var(--pink)}.home-page body,.home-page body>div,.home-page body>div>div,.home-page body>div>div>div,html.home-page{height:100%}.container{height:100%;flex-direction:column;justify-content:center}.container,.row{display:flex;align-items:center}.column{flex:50% 1}.sidebar.column{flex:20% 1}@media (max-width:575.98px){.home-page body,.home-page body>div,.home-page body>div>div,.home-page body>div>div>div,html.home-page{height:auto}.container{margin-top:2.5rem;margin-bottom:2.5rem;padding-left:1rem;padding-right:1rem}.row{display:block}.my-story-content{text-align:justify}.column,.sidebar.column{width:100%}.social-item>a>svg{padding:20px}}.my-story-content{font-size:1.1rem;line-height:1.6;max-width:800px;text-align:justify}.my-story-content .intro{text-align:center}.my-story-content .intro .hey{margin-bottom:8px}.my-story-content .intro .title-summary{margin-top:0}.my-story-content a{color:var(--storyLinkColor);font-weight:700}.name{font-family:Dancing Script,cursive;font-size:3rem;margin-top:10px;margin-bottom:5px;text-align:center}.second-name{color:var(--secondNameColor)}.title{text-align:center;font-size:1.2rem;line-height:1.2rem}.home-page .theme-switcher{margin-top:10px}.homepage-sidebar .social{margin-top:20px}.social .social-list{display:flex;flex-flow:row wrap;flex-grow:0;flex-shrink:0;justify-content:center;list-style:none;padding:0;margin:0}.homepage-sidebar .social .social-list .social-item{border:1px solid var(--socialLinkBorderColor);border-radius:50%;margin:.25rem}.homepage-sidebar .social .social-list .social-item:hover{border:1px solid var(--socialLinkBorderHoverColor)}.homepage-sidebar .social .social-list .social-item>a>svg{height:14px;padding:10px;vertical-align:middle;width:14px}body{--footerIconColor:var(--blackLigher);--footerBgColor:var(--grey);--copyrightColor:var(--midnightDarker)}body.dark{--footerIconColor:var(--white);--footerBgColor:var(--midnightDarker);--copyrightColor:var(--grey)}footer{background-color:var(--footerBgColor)}footer,footer a{color:var(--footerIconColor)}footer .footer-wrapper{padding:4rem 1rem}.copyright{color:var(--copyrightColor);text-align:center}.footer-separator{display:flex;justify-content:center}.footer-separator .separator{background-color:#fff;width:3px;height:3px;border-radius:50%;margin-right:20px}footer .social-list .social-item{margin:.5rem}.copyright{font-size:1.1rem;margin:2rem auto 0}.blog-listing-wrapper{max-width:70rem;margin-left:auto;margin-right:auto}.experiment-grid{display:flex;max-width:70rem;margin:0 auto;justify-content:space-between;flex-wrap:wrap}.experiment-grid.no-experiments{justify-content:center}.blog-experiment .no-experiments-placeholder{padding:2rem;margin-bottom:32px;text-align:center}.experiment-grid .experiment-item{flex:0 1 30%;padding:10px}.experiment-grid .experiment-item .cover{height:200px}@media screen and (max-width:992px){.experiment-grid .experiment-item{flex:0 1 45%}}@media screen and (max-width:600px){.experiment-grid .experiment-item{flex:100% 1;flex-direction:column}.experiment-grid .experiment-item .cover{height:auto}}.game{display:flex;justify-content:center;padding:2rem}.game-item{margin:1rem}.game-item .title{margin-bottom:1rem}.player{width:300px;height:300px;border:1px solid #dcdfe6;border-radius:4px;box-shadow:0 2px 12px 0 rgb(0 0 0/10%);display:flex;align-items:center;justify-content:center;font-size:5rem}.human .choice{position:absolute}.controls{display:flex;flex-direction:column;align-items:center;justify-content:center}.controls .score{font-size:2rem;margin-bottom:1rem}.controls .countdown{font-size:3rem;font-weight:700}.controls button.play{display:inline-block;line-height:1;white-space:nowrap;cursor:pointer;background:#fff;border:1px solid #dcdfe6;color:#606266;-webkit-appearance:none;text-align:center;box-sizing:border-box;outline:none;margin:0;transition:.1s;font-weight:500;-moz-user-select:none;-webkit-user-select:none;-ms-user-select:none;padding:12px 20px;font-size:14px;border-radius:4px}.video-background{position:relative;background-color:#666;transform:rotateY(180deg);-webkit-transform:rotateY(180deg);-moz-transform:rotateY(180deg)}.game-item .human-choice-image,.video-background{width:100%;height:100%;-o-object-fit:cover;object-fit:cover}.experiment-view-page .lab-header{height:30rem}.experiment-view-page .experiment-category{display:inline-block;line-height:1;white-space:nowrap;cursor:pointer;background:#fff;border:1px solid #dcdfe6;color:#606266;-webkit-appearance:none;text-align:center;box-sizing:border-box;outline:none;margin:0;transition:.1s;font-weight:500;-moz-user-select:none;-webkit-user-select:none;-ms-user-select:none;padding:12px 20px;font-size:14px;border-radius:4px}.blog-wrapper{max-width:70rem;margin-left:auto;margin-right:auto}.blog-sidebar .blog-intro{font-size:1.1rem;margin-bottom:1rem;padding:0 5rem;text-align:center}.blog-sidebar{margin:2rem auto;max-width:45rem}.blog-sidebar .blog-header-wrapper{margin-bottom:1rem}.blog-sidebar .misc{display:flex;justify-content:space-around}@media screen and (max-width:575px){.blog-sidebar{margin:1rem 0}.blog-sidebar .blog-header-wrapper{margin-bottom:1rem}.blog-sidebar .blog-intro{padding:0 1rem}}.blog-grid{display:flex;justify-content:space-between;flex-wrap:wrap}.blog-grid.no-posts{justify-content:center}.blog-grid .no-posts-placeholder{padding:2rem;margin-bottom:32px;text-align:center}.blog-grid .blog-item{flex:0 1 30%;padding:10px}.blog-grid .blog-item .cover{height:200px}@media screen and (max-width:992px){.blog-grid .blog-item{flex:0 1 45%}}@media screen and (max-width:600px){.blog-grid .blog-item{flex:100% 1;flex-direction:column}.blog-grid .blog-item .cover{height:auto}}body{--thoughtsPageTitleColor:var(--red)}body.dark{--thoughtsPageTitleColor:var(--pink)}.thoughts-wrapper{max-width:70rem;margin-left:auto;margin-right:auto}.thoughts-wrapper .thought-sidebar{float:left;position:-webkit-sticky;position:-moz-sticky;position:-ms-sticky;position:-o-sticky;position:sticky;top:2rem;width:33.3%}@media (max-width:575.98px){.thoughts-wrapper .thought-sidebar{float:none;position:static;margin-bottom:40px;width:auto}}.thought-sidebar .navigation{text-align:center}.thought-sidebar .navigation a{text-transform:uppercase}.thought-sidebar .theme-switcher{margin-top:10px}.thoughts-wrapper .thoughts-list{float:left;padding-left:5rem;margin-right:0;margin-top:0;width:calc(66.6% - 5rem)}@media (max-width:1199.98px){.thoughts-wrapper .thoughts-list{padding-left:4rem;width:calc(66.6% - 4rem)}}@media (max-width:920px){.thoughts-wrapper .thoughts-list{padding-left:2rem;width:calc(66.6% - 2rem)}}@media (max-width:575.98px){.thoughts-wrapper .thoughts-list{float:none;display:block;padding-left:1rem;padding-right:1rem;width:auto}}@media (max-width:575.98px){.thought-sidebar .theme-switcher{margin-top:1rem}}.thoughts-title{font-family:Dancing Script,cursive;font-size:4rem;font-weight:700;margin-top:2.5rem;margin-bottom:2.5rem;text-align:center}.thoughts-title,.thoughts-title a{color:var(--thoughtsPageTitleColor)}body{--socialShareBorderHoverColor:var(--red)}body.dark{--socialShareBorderHoverColor:var(--pink)}.social-share-wrapper{font-size:1.5rem;text-align:center;margin-bottom:1.2rem}.social-share-wrapper h3{font-size:1.5rem}.social-share-wrapper .social-share-item{margin-right:.8rem;vertical-align:middle}.social-share-wrapper .social-share-item:hover{color:var(--socialShareBorderHoverColor)!important}.blogpost-view-page .blogpost-header{margin:1rem 0}.blogpost-view-page .blog-header-wrapper .logo{width:90px;height:90px}.blogpost-view-page .blog-header-wrapper .logo-img{width:5rem}.blogpost-view-page .blog-header-wrapper .name{font-size:1.5rem}.blogpost-view-page .blog-header-wrapper .blog-title{font-size:3rem;padding-left:1rem}.blogpost-view-page .thought-sidebar,.thought-wrapper{margin-left:auto;margin-right:auto;max-width:43rem}.blogpost-view-page .thoughts-title{font-size:3rem;margin-bottom:1rem}@media (max-width:575px){.blogpost-view-page .thoughts-title{font-size:2rem}}.blogpost-view-page .thought-divider{clear:both}.blogpost-view-page .thought-content{margin-top:2rem}.blogpost-view-page .thought-author-wrapper,.blogpost-view-page .thought-navigation-wrapper{margin-bottom:2rem}.blogpost-view-page hr{border:none;margin-bottom:2rem;text-align:center}.blogpost-view-page hr:before{letter-spacing:.6em;text-indent:.6em;content:"***"}body{--thoughtQuoteColor:var(--red)}body.dark{--thoughtQuoteColor:var(--pink)}.thought-view-page .thought-sidebar,.thought-wrapper{margin-left:auto;margin-right:auto;max-width:43rem}@media (max-width:767px){.thought-wrapper{display:block;padding-left:1rem;padding-right:1rem;width:auto}}.thought-view-page .thoughts-title{font-size:3rem;margin-bottom:1rem;margin-top:1rem}@media (max-width:575px){.thought-view-page .thoughts-title{font-size:2rem}}.thought-view-page .thought-divider{clear:both}.thought-view-page .thought-content{margin-top:2rem}.thought-view-page .thought-author-wrapper,.thought-view-page .thought-navigation-wrapper{margin-bottom:2rem}.thought-view-page hr{border:none;margin-bottom:2rem;text-align:center}.thought-view-page hr:before{letter-spacing:.6em;text-indent:.6em;content:"***"}</style><title data-react-helmet="true">How I built my ML workstation ðŸ”¬ - Blog by Roman Glushko</title><meta data-react-helmet="true" property="og:image" content="https://www.romaglushko.com/static/e402de674af0047178bbcc6e2754204d/fd1df/machine-learning-workstation.jpg"/><meta data-react-helmet="true" property="og:url" content="https://www.romaglushko.com/blog/how-i-built-my-ml-workstation/"/><script data-react-helmet="true" type="application/ld+json">{"@context":"http://schema.org","@type":"BlogPosting","image":"/static/e402de674af0047178bbcc6e2754204d/fd1df/machine-learning-workstation.jpg","headline":"How I built my ML workstation ðŸ”¬","dateCreated":"2021-04-07","dateModified":"2021-04-07","datePublished":"2021-04-07","inLanguage":"en-US","isFamilyFriendly":"true","author":{"@type":"Person","name":"Roman Glushko"},"publisher":{"@type":"Person","name":"Roman Glushko"},"mainEntityOfPage":"true","keywords":["machine learning","computer engineering"],"genre":["opinion","thoughts","life experience"],"articleSection":"Thoughts","articleBody":"\n\nKaggle Kernels and Google Colab are great.\n\n<div style=\"width:100%;height:0;padding-bottom:73%;position:relative;\"><iframe src=\"https://giphy.com/embed/UmBdALbYTmCJ2\" width=\"100%\" height=\"100%\" style=\"position:absolute\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen></iframe></div><p><a href=\"https://giphy.com/gifs/UmBdALbYTmCJ2\"></a></p>\n\nI would drop my mic at this point if this article was not be about building a custom ML workstation.\n\nThere is always some \"buts\" that makes our lives harder. When you start to approach nearly real life problems and see hundreds of gigabytes large datasets, your gut feeling starts to tell you that your CPU or AMD GPU devices are not going to be enough to do meaningful things. This is how I came here.\n\nI was taking part in <a href=\"https://www.kaggle.com/c/hpa-single-cell-image-classification\">Human Protein Atlas (HPA) - Single Cell Classification</a> competition on Kaggle. HPA dataset contains nearly 150Gb of 8bits 4-channels protein images. 16bits variant of the dataset holds 350Gb.\n\nHere is what I had at my disposal:\n\n- MacBook Pro 2019 (Intel Core i9 && Intel UHD Graphics 630 1536MB && 16GB DDR4)\n- ~30h GPU and/or ~30h TPU hours per week on Kaggle Kernels\n\nSounds good. I though I would be able to prototype locally and then execute notebooks on the cloud GPU. What could go wrong?\n\n## Life Without GPU\n\nAs it turned out, there are a lot of frictions in the mentioned workflow.\n\nFirst of all, my solution source code quickly became an entire project with a lot of source code and dependencies. I used <a href=\"https://python-poetry.org/\">poetry</a> as a package manager and decided to generate an installable package every time I made meaningful changes to the project in order to test them in the cloud. These installable packages I was uploading into a private Kaggle dataset which in turn was mounted to a notebook. The notebook was calling classes and functions from the package.\n\nThis approach to bring a full-size project turns out to have underwater stones. Kaggle notebooks randomly thrown weird errors after installing project packages. I think it was related to dependency version mismatch and I spotted errors like \"method X is not found in package Y\", etc. Autoreload was not helpful. Several mornings in a row I started my day dealing with new and new suddenly occurred unearthly issues.\n\n<div style=\"width:100%;height:0;padding-bottom:75%;position:relative;\"><iframe src=\"https://giphy.com/embed/l2YWmG9FBDtiqHTi0\" width=\"100%\" height=\"100%\" style=\"position:absolute\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen></iframe></div><p><a href=\"https://giphy.com/gifs/gilmoregirls-netflix-gilmore-girls-l2YWmG9FBDtiqHTi0\"></a></p>\n\nWhile working on the competition, I switched from Keras to PyTorch. PyTorch is much slower on CPU then TensorFlow or Keras. It was time consuming to even perform a dev run of my recent changes. However, PyTorch has outstanding support in academic and other ML-associated communities which means a bunch of (**almost**) read-to-use examples of state-of-art technics.\n\nAlso, when you run your code in the cloud, you can not easily experiment. You have to plan what you are going to experiment with and make that part somehow configurable.\n\nAll in all, the experience was frustrating. I clearly realized if I wanted to do more complex deep learning experiments and projects, then I just need to have 24/7 access to any kind of GPUs.\n\n## Investigation\n\nI have never been interested in custom PC building, hardware or gaming. So it took me a while to understand what did it cost me to build a custom machine.\n\n<div style=\"width:100%;height:0;padding-bottom:75%;position:relative;\"><iframe src=\"https://giphy.com/embed/kxkmUjgUwzhk7uIxOA\" width=\"100%\" height=\"100%\" style=\"position:absolute\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen></iframe></div><p><a href=\"https://giphy.com/gifs/hyperrpg-twitch-kollok-kollok1991-kxkmUjgUwzhk7uIxOA\"></a></p>\n\nThere are a lot of resources on building gaming PCs. While building a deep learning workstation sounds like a similar task, there are nuances that should be accounted in order to build a cost-efficient and ML-compatible machine.\n\nI have found a few useful blog posts which helped me to quickly grasp the topic. Particularly, I could highlight two posts from <a target=\"_blank\" rel=\"noopener\" href=\"https://twitter.com/Tim_Dettmers\">Tim Dettmers</a>:\n\n- <a target=\"_blank\" rel=\"noopener\" href=\"https://timdettmers.com/2018/12/16/deep-learning-hardware-guide/\">A Full Hardware Guide to Deep Learning</a>\n- <a target=\"_blank\" rel=\"noopener\" href=\"https://timdettmers.com/2020/09/07/which-gpu-for-deep-learning/\">Which GPU(s) to Get for Deep Learning: My Experience and Advice for Using GPUs in Deep Learning</a>\n\nIn his blog, Tim explained at length importance of each PC part for ML workstation and provides general pieces of advice on choosing them. Here I'm going to mention information that was helpful for me along with details Tim did not focus on.\n\nAlso, <a target=\"_blank\" rel=\"noopener\" href=\"https://pcpartpicker.com\">PCPartsPicker's Builder</a> was super helpful during planning PC. It suggested possible components compatibilities and things to check before ordering the list. It helped to overcome my constant fear that I could buy something that would not work together.\n\n## Parts for ML build\n\nWhen it comes to building a deep learning machine (or any custom PC), there are 8 parts that should be considered:\n\n- <a href=\"#gpu\">GPU</a>\n- <a href=\"#motherboard\">Motherboard (a.k.a. MoBo)</a>\n- <a href=\"#cpu\">CPU</a>\n- <a href=\"#ram\">RAM</a>\n- <a href=\"#storage\">Storage</a>\n- <a href=\"#power-system-unit\">Power System Unit (PSU)</a>\n- <a href=\"#cooling\">Cooling</a>\n- <a href=\"#pc-case\">PC case</a>\n\nHere is an overview:\n\n### GPU\n\nGPU is **the key component** of any ML workstation. It's designed to perform computations on **big chunks of data** (throughput-optimized) **in parallel** which makes it perfect for model training or inference where it's really needed (<a target=\"_blank\" rel=\"noopener\" href=\"https://www.quora.com/Why-are-GPUs-well-suited-to-deep-learning/answer/Tim-Dettmers-1\" title=\"Why GPU is faster then CPU?\">here is details</a>).\n\nThe very fist consideration is that we need **NVIDIA graphic cards only** for deep learning. Unfortunately, there is a monopoly in ML framework world. Most of the popular and production-ready frameworks (TensorFlow, PyTorch, Keras) are designed and optimized for CUDA-enabled devices. CUDA is a proprietary platform and set of APIs for parallel computations owned by NVIDIA. This is the reason why we mean \"CUDA cards\" when talk about the GPU in ML context.\n\nIt makes sense to dig just slightly deeper in a simplified CUDA architecture. Modern GPUs are based on **tensor cores** that are capable of multiplying **4x4 matrices in one operation** which is blazing fast. Despite that, tensor cores need data to perform computations on. Data passes the following way in order to be loaded efficiently:\n\n- **From CPU to Global GPU Memory**. CPU threads load preprocessed batches into entirely separate GPU device memory (don't be confused with PC RAM). The device memory is the slowest kind of memory in the GPU.\n- **From Global GPU Memory to Shared Memory**. Shared memory is **~10-50x faster** then the global GPU memory, but it's also much smaller (normally hundreds of Kbs). This memory is purely available for a Streaming Multiprocessor (SM) that is an analogue of CPU core in GPU architecture. Data is stored there in so called tiles.\n- **From Shared Memory to Tensor Core Registries**. Streaming Multiprocessors operates their tensor cores in parallel and upload part of the tiles into tensor core registries.\n\nSo any bottlenecks in data loading flow would lead to suboptimal utilization of tensor cores, no matter how many of them you have in your GPU.\n\n![CUDA Hardware Architecture](./img/cuda-hardware-architecture.png \"CUDA Hardware Architecture\")\n<div class=\"image-title\">CUDA Hardware Architecture (<a target=\"_blank\" rel=\"noopener\" href=\"https://dadaiscrazy.github.io/usuba/2020/03/28/CUDA-basics.html\" title=\"source of the image\">source</a>)</div>\n\nWith that being said, these are roughly the main GPU features important for ML tasks:\n\n- **Global GPU Memory** - defines how big batch sizes you can use during training or how quality samples you can use if it comes to computer vision\n- **Memory Bandwidth** - a rate at which data is being transferred inside of the device\n- **Architecture** - the more recent architecture is the better. Newer architectures may be better in terms of shared memory size, feature set (like mixed precision computations) and could be more efficient in terms of wattage per effective computations metric.\n\nAdditionally, you should think about these factors:\n\n- **Performance per Cost**\n- **GPU Cooling**\n- **GPU Wattage**\n\nThankfully, you can find much more on that in the <a target=\"_blank\" rel=\"noopener\" href=\"https://timdettmers.com/2020/09/07/which-gpu-for-deep-learning/\">Tim's post</a>.\n\n### Motherboard\n\nMotherboard integrates most of the components and also provides:\n\n- most of the I/O ports (like USB, Ethernet, etc)\n- chipset with BIOS\n- WiFi, Bluetooth adapters\n\nMotherboard provides other interfaces to power your stuff. Among them, the one of most important is CPU. The motherboards are divided into AMD- and Intel-compatible sockets which are not interchangable. Hence, you need to make sure **CPU of you choice** is **compatible with your motherboard**.\n\n**Number of PCI ports** is another thing to consider. Since PCI ports are used to connect GPUs, you need to plan ahead your build and rooms for upgrades (to be able to add more cards in the future, for example). Also, pay attention that, effectively, graphic cards takes more then slot of space. We want to have **as much space as possible** between cards for **better air cooling**.\n\nAlso, I'm pretty sure you would be happy to have build-in WiFi adapter. Otherwise, the only way to connect a PC would be via ethernet cable which is not alway convenient (or just buy an external adapter).\n\n### CPU\n\nTBU\n\n### RAM\n\nTBU\n\n### Storage\n\nTBU\n\n### Power System Unit\n\nTBU\n\n### Cooling\n\nWith a great power comes a great ~~responsibility~~ need for cooling.\n\n### PC Case\n\nTBU\n\n## My Parts List\n\nCreating a multi-GPU cluster was not on my list. Yet still I wanted to have a room for improvements. So I took <a target=\"_blank\" rel=\"noopener\" href=\"https://pcpartpicker.com/user/tim_dettmers/saved/#view=mZ2rD3\">2-GPUs barebone from Tim's templates</a> as a base for my workstation and adjusted it a bit to match what I could find on the local market. Here is my final list of components:\n\n- GPU: <a target=\"_blank\" rel=\"noopener\" href=\"https://www.newegg.com/gigabyte-geforce-rtx-3070-gv-n3070aorus-m-8gd/p/N82E16814932359\">Gigabyte GeForce RTX 3070 8Gb Aorus Master</a>\n- Matherboard: <a target=\"_blank\" rel=\"noopener\" href=\"https://www.newegg.com/msi-performance-gaming-x470-gaming-plus-max/p/N82E16813144266\">MSI x470 Gaming Plus</a>\n- CPU: <a target=\"_blank\" rel=\"noopener\" href=\"https://www.newegg.com/amd-ryzen-5-3600/p/N82E16819113569\">AMD Ryzen 5 3600</a>\n- RAM: <a target=\"_blank\" rel=\"noopener\" href=\"https://www.newegg.com/g-skill-32gb-288-pin-ddr4-sdram/p/N82E16820232091\">G.Skill Ripjaws V Series 32Gb (2 x 16Gb)</a>\n- Storage: <a target=\"_blank\" rel=\"noopener\" href=\"https://www.newegg.com/samsung-970-evo-plus-500gb/p/N82E16820147742\">Samsung 970 Evo 500Gb M.2-2280 NVME</a>\n- Cooling: <a target=\"_blank\" rel=\"noopener\" href=\"https://www.newegg.com/cooler-master-hyper-212-black-edition-rr-212s-20pk-r1/p/N82E16835103278\">Cooler Master Hyper 212 Black Edition</a>\n- PSU: <a target=\"_blank\" rel=\"noopener\" href=\"https://pcpartpicker.com/product/MfJwrH/evga-power-supply-220g20750xr\">EVGA G2 750W 80+ Gold</a>\n- PC Case: <a target=\"_blank\" rel=\"noopener\" href=\"https://www.newegg.com/matte-black-nzxt-h-series-h510-atx-mid-tower/p/N82E16811146315\">NZXT H510</a>\n- Wireless Adapter: <a target=\"_blank\" rel=\"noopener\" href=\"https://www.newegg.com/tp-link-archer-t2u-plus-usb-2-0/p/N82E16833704471\">TP-Link Archer T2U Plus</a>\n\nThe same list on PCPartsPicker can be found <a target=\"_blank\" rel=\"noopener\" href=\"https://pcpartpicker.com/user/roman-glushko/saved/8gZHGX\">here</a>.\n\n![GPU Price Dynamics: end of 2020 - beginning of 2021](./img/gpu-price-dynamics.png \"GPU Price Dynamics: end of 2020 - beginning of 2021\")\n<div class=\"image-title\">GPU Price Dynamics: end of 2020 - beginning of 2021. Wild time</div>\n\n## Hardware Installation\n\n![PC Parts](./img/pc-parts.jpg \"PC Parts\")\n<div class=\"image-title\">PC parts arrived. I think I could build a new house with these boxes. Stay tuned for more updates on this</div>\n\n\n### Motherboard\n\n![MSI X470 Gaming Max Unboxing](./img/msi-x470-gaming-max-unboxing.jpg \"MSI X470 Gaming Max Unboxing\")\n<div class=\"image-title\">Motherboard Unboxing</div>\n\n![MotherBoard](./img/msi-x470-gamin-plus-detailed-view.jpg \"MotherBoard\")\n<div class=\"image-title\">Motherboard. Detailed View</div>\n\n### CPU\n\n![AMD Ryzen 5 3600 Unboxing](./img/amd-ryzen-5-3600-unboxing.jpg \"AMD Ryzen 5 3600 Unboxing\")\n<div class=\"image-title\">CPU Unboxing</div>\n\n![AM4 CPU Socket](./img/am4-cpu-socket.jpg \"AM4 CPU Socket\")\n<div class=\"image-title\">CPU Socket</div>\n\nTBU\n\n### SSD\n\n![Samsung 970 EVO M.2 SSD Unboxing](./img/samsung-970-evo-m.2-unboxing.jpg \"Samsung 970 EVO M.2 SSD Unboxing\")\n<div class=\"image-title\">M.2 SSD Unboxing</div>\n\n`video: title: \"M.2 Installation\": ./img/ssd-m.2-installation.mp4`\n<div class=\"image-title\">M.2 Installation</div>\n\n![SSD Installation. M.2 Screw](./img/ssd-m.2-installation.jpg \"SSD Installation. M.2 Screw\")\n<div class=\"image-title\">SSD Installation. M.2 Screw</div>\n\n### RAM\n\n![G.Skill Ripjaws V Series 32Gb Unboxing](./img/g.skill-ripjaws-v-series-32gb-unboxing.jpg \"G.Skill Ripjaws V Series 32Gb Unboxing\")\n<div class=\"image-title\">RAM Unboxing</div>\n\n![RAM Installation](./img/ram-installation.jpg \"RAM Installation\")\n<div class=\"image-title\">RAM Installation</div>\n\n### Cooler\n\n![Cooler Unboxing](./img/cooler-master-hyper-212-black-unboxing.jpg \"Cooler Unboxing\")\n<div class=\"image-title\">Cooler Unboxing</div>\n\n## Software Installation\n\n## CUDA Setup\n\n## Workflow\n\n## Summary\n\n![My Deep Learning Workstation 1.0](./img/deep-learning-workstation-final-look.jpg \"My Deep Learning Workstation 1.0\")\n<div class=\"image-title\">My Deep Learning Workstation 1.0</div>\n\n\n## References\n\n- <a target=\"_blank\" rel=\"noopener\" href=\"https://timdettmers.com/2018/12/16/deep-learning-hardware-guide/\">A Full Hardware Guide to Deep Learning</a>\n- <a target=\"_blank\" rel=\"noopener\" href=\"https://timdettmers.com/2020/09/07/which-gpu-for-deep-learning/\">Which GPU(s) to Get for Deep Learning: My Experience and Advice for Using GPUs in Deep Learning</a>\n- <a target=\"_blank\" rel=\"noopener\" href=\"https://pcpartpicker.com/user/tim_dettmers/saved/#view=mZ2rD3\">Deep Learning Barebones on PCPartPicker</a>","wordcount":1550}</script><script data-react-helmet="true" type="text/javascript" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" async=""></script><link rel="icon" href="/favicon-32x32.png?v=58a31253e5b93c1d7e74e8a017ff47b3"/><link rel="manifest" href="/manifest.webmanifest"/><meta name="theme-color" content="#ffffff"/><link rel="apple-touch-icon" sizes="48x48" href="/icons/icon-48x48.png?v=58a31253e5b93c1d7e74e8a017ff47b3"/><link rel="apple-touch-icon" sizes="72x72" href="/icons/icon-72x72.png?v=58a31253e5b93c1d7e74e8a017ff47b3"/><link rel="apple-touch-icon" sizes="96x96" href="/icons/icon-96x96.png?v=58a31253e5b93c1d7e74e8a017ff47b3"/><link rel="apple-touch-icon" sizes="144x144" href="/icons/icon-144x144.png?v=58a31253e5b93c1d7e74e8a017ff47b3"/><link rel="apple-touch-icon" sizes="192x192" href="/icons/icon-192x192.png?v=58a31253e5b93c1d7e74e8a017ff47b3"/><link rel="apple-touch-icon" sizes="256x256" href="/icons/icon-256x256.png?v=58a31253e5b93c1d7e74e8a017ff47b3"/><link rel="apple-touch-icon" sizes="384x384" href="/icons/icon-384x384.png?v=58a31253e5b93c1d7e74e8a017ff47b3"/><link rel="apple-touch-icon" sizes="512x512" href="/icons/icon-512x512.png?v=58a31253e5b93c1d7e74e8a017ff47b3"/><link rel="preload" as="font" type="font/woff2" crossorigin="anonymous" href="/static/webfonts/s/dancingscript/v16/If2cXTr6YS-zF4S-kcSWSVi_sxjsohD9F50Ruu7BMSo3Sup8.woff2"/><link rel="preload" as="font" type="font/woff2" crossorigin="anonymous" href="/static/webfonts/s/ledger/v11/j8_q6-HK1L3if_sBnMrx.woff2"/><style>@font-face{font-family:Dancing Script;font-style:normal;font-weight:400;font-display:swap;src:url(/static/webfonts/s/dancingscript/v16/If2cXTr6YS-zF4S-kcSWSVi_sxjsohD9F50Ruu7BMSo3Sup8.woff2) format("woff2")}@font-face{font-family:Dancing Script;font-style:normal;font-weight:400;font-display:swap;src:url(/static/webfonts/s/dancingscript/v16/If2cXTr6YS-zF4S-kcSWSVi_sxjsohD9F50Ruu7BMSo3Sup6.woff) format("woff")}@font-face{font-family:Ledger;font-style:normal;font-weight:400;font-display:swap;src:url(/static/webfonts/s/ledger/v11/j8_q6-HK1L3if_sBnMrx.woff2) format("woff2")}@font-face{font-family:Ledger;font-style:normal;font-weight:400;font-display:swap;src:url(/static/webfonts/s/ledger/v11/j8_q6-HK1L3if_sBnMr3.woff) format("woff")}</style><link rel="preconnect dns-prefetch" href="https://www.google-analytics.com"/><style type="text/css">
    .anchor.before {
      position: absolute;
      top: 0;
      left: 0;
      transform: translateX(-100%);
      padding-right: 4px;
    }
    .anchor.after {
      display: inline-block;
      padding-left: 4px;
    }
    h1 .anchor svg,
    h2 .anchor svg,
    h3 .anchor svg,
    h4 .anchor svg,
    h5 .anchor svg,
    h6 .anchor svg {
      visibility: hidden;
    }
    h1:hover .anchor svg,
    h2:hover .anchor svg,
    h3:hover .anchor svg,
    h4:hover .anchor svg,
    h5:hover .anchor svg,
    h6:hover .anchor svg,
    h1 .anchor:focus svg,
    h2 .anchor:focus svg,
    h3 .anchor:focus svg,
    h4 .anchor:focus svg,
    h5 .anchor:focus svg,
    h6 .anchor:focus svg {
      visibility: visible;
    }
  </style><script>
    document.addEventListener("DOMContentLoaded", function(event) {
      var hash = window.decodeURI(location.hash.replace('#', ''))
      if (hash !== '') {
        var element = document.getElementById(hash)
        if (element) {
          var scrollTop = window.pageYOffset || document.documentElement.scrollTop || document.body.scrollTop
          var clientTop = document.documentElement.clientTop || document.body.clientTop || 0
          var offset = element.getBoundingClientRect().top + scrollTop - clientTop
          // Wait for the browser to finish rendering before scrolling.
          setTimeout((function() {
            window.scrollTo(0, offset - 0)
          }), 0)
        }
      }
    })
  </script><link rel="canonical" href="https://www.romaglushko.com/blog/how-i-built-my-ml-workstation/" data-baseprotocol="https:" data-basehost="www.romaglushko.com"/><link rel="sitemap" type="application/xml" href="/sitemap.xml"/><link as="script" rel="preload" href="/webpack-runtime-ffe28ca2ddebee3dccf4.js"/><link as="script" rel="preload" href="/framework-984c7a17186e83dc1ff4.js"/><link as="script" rel="preload" href="/app-e39ef23d44e95f2a8c12.js"/><link as="script" rel="preload" href="/styles-8636a280cbc61d53ad10.js"/><link as="script" rel="preload" href="/cb1608f2-6457b2b7ea9500c04ebb.js"/><link as="script" rel="preload" href="/a9a7754c-52ee971a981a422e7452.js"/><link as="script" rel="preload" href="/a510f34a924899f38f7aa0d53277b2c9f4857ad7-297391715d2e12113f02.js"/><link as="script" rel="preload" href="/059c0ea648e8bc79d52034ba1cf1bfc380f9444d-a4fc9b8066b0203e6078.js"/><link as="script" rel="preload" href="/bc2c5684014d51ee40621353fd54f57d7b8b3bb5-73ee4f5bc1b65ee475c2.js"/><link as="script" rel="preload" href="/4622c33586ad0108e870f951288ae6aa3beabfab-45b8a591d79b385bde09.js"/><link as="script" rel="preload" href="/component---src-templates-blog-template-js-038bf2396ef654b3f050.js"/><link as="fetch" rel="preload" href="/page-data/blog/how-i-built-my-ml-workstation/page-data.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/app-data.json" crossorigin="anonymous"/></head><body><script>
void function() {
  window.__onThemeChange = function() {}

  var preferredTheme
  try {
    preferredTheme = localStorage.getItem('theme')
  } catch (err) { }

  function setTheme(newTheme) {
    if (preferredTheme && document.body.classList.contains(preferredTheme)) {
      document.body.classList.replace(preferredTheme, newTheme)
    } else {
      document.body.classList.add(newTheme)
    }

    window.__theme = newTheme
    preferredTheme = newTheme
    window.__onThemeChange(newTheme)
  }

  window.__setPreferredTheme = function(newTheme) {
    setTheme(newTheme)
    try {
      localStorage.setItem('theme', newTheme)
    } catch (err) {}
  }

  var darkQuery = window.matchMedia('(prefers-color-scheme: dark)')
  darkQuery.addListener(function(e) {
    window.__setPreferredTheme(e.matches ? 'dark' : 'light')
  })

  setTheme(preferredTheme || (darkQuery.matches ? 'dark' : 'light'))
}()
    </script><div id="___gatsby"><div style="outline:none" tabindex="-1" id="gatsby-focus-wrapper"><div><div class="blogpost-header"><div class="view-page-header"><div class="view-page-header-wrapper"><div class="logo-wrapper"><div class="logo"><div class="logo-img gatsby-image-wrapper" style="position:relative;overflow:hidden"><div aria-hidden="true" style="width:100%;padding-bottom:100%"></div><img aria-hidden="true" src="data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAUABQDASIAAhEBAxEB/8QAGAABAQADAAAAAAAAAAAAAAAAAAQBAgP/xAAWAQEBAQAAAAAAAAAAAAAAAAABAAL/2gAMAwEAAhADEAAAAa5sT1a5nMmooB//xAAbEAACAwADAAAAAAAAAAAAAAABAgADERIUIv/aAAgBAQABBQI3iLeyntCO4gYIcrm+7zyGz//EABURAQEAAAAAAAAAAAAAAAAAACBB/9oACAEDAQE/AYP/xAAXEQEAAwAAAAAAAAAAAAAAAAAAECFB/9oACAECAQE/AVsj/8QAHhAAAgEDBQAAAAAAAAAAAAAAAAECEBExEiEiI3H/2gAIAQEABj8CssnKTkjBpS3Z2RzS4vaf/8QAGxABAAIDAQEAAAAAAAAAAAAAAQARMUFhoSH/2gAIAQEAAT8hFs1Kn38NJic/stDHziK9wK12cGC7BFSxaf/aAAwDAQACAAMAAAAQZBd//8QAGBEBAQADAAAAAAAAAAAAAAAAAAERIUH/2gAIAQMBAT8QmDTqv//EABYRAQEBAAAAAAAAAAAAAAAAABEBIP/aAAgBAgEBPxCrg//EAB8QAQACAgICAwAAAAAAAAAAAAEAESExQVFhccHR4f/aAAgBAQABPxBhG3mB7/IibGGnZ0614mT4YrVCxHbhtlbwwVt0ucu3pPqDrcQHrMplsJgiGLn/2Q==" alt="" style="position:absolute;top:0;left:0;width:100%;height:100%;object-fit:cover;object-position:center;opacity:1;transition-delay:500ms"/><noscript><picture><source srcset="/static/339a70ba95708d2e3aae7d14d7b17b18/b13df/photo.jpg 40w,
/static/339a70ba95708d2e3aae7d14d7b17b18/4e333/photo.jpg 80w,
/static/339a70ba95708d2e3aae7d14d7b17b18/e75b5/photo.jpg 160w,
/static/339a70ba95708d2e3aae7d14d7b17b18/40426/photo.jpg 240w,
/static/339a70ba95708d2e3aae7d14d7b17b18/c01e2/photo.jpg 320w,
/static/339a70ba95708d2e3aae7d14d7b17b18/f9913/photo.jpg 750w" sizes="(max-width: 160px) 100vw, 160px" /><img loading="lazy" sizes="(max-width: 160px) 100vw, 160px" srcset="/static/339a70ba95708d2e3aae7d14d7b17b18/b13df/photo.jpg 40w,
/static/339a70ba95708d2e3aae7d14d7b17b18/4e333/photo.jpg 80w,
/static/339a70ba95708d2e3aae7d14d7b17b18/e75b5/photo.jpg 160w,
/static/339a70ba95708d2e3aae7d14d7b17b18/40426/photo.jpg 240w,
/static/339a70ba95708d2e3aae7d14d7b17b18/c01e2/photo.jpg 320w,
/static/339a70ba95708d2e3aae7d14d7b17b18/f9913/photo.jpg 750w" src="/static/339a70ba95708d2e3aae7d14d7b17b18/e75b5/photo.jpg" alt="" style="position:absolute;top:0;left:0;opacity:1;width:100%;height:100%;object-fit:cover;object-position:center"/></picture></noscript></div></div><div class="name"><a href="/blog/">Roman <br/> Glushko</a></div></div><h1 class="blog-title"><a href="/"></a></h1></div></div><nav class="main-navigation"><ul><li><a title="Go Home" href="/">Home</a></li><li><a title="Go to Technical blog" href="/blog/">Blog</a></li><li><a title="Go to Thoughts" href="/thoughts/">Thoughts</a></li></ul></nav></div><main><article class="blog-wrapper"><header><div class="cover-filter"><div class="cover gatsby-image-wrapper" style="position:relative;overflow:hidden"><div aria-hidden="true" style="width:100%;padding-bottom:133.29411764705884%"></div><img aria-hidden="true" src="data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAbABQDASIAAhEBAxEB/8QAGgAAAgIDAAAAAAAAAAAAAAAAAAQDBQECBv/EABYBAQEBAAAAAAAAAAAAAAAAAAACAf/aAAwDAQACEAMQAAABRkhbmsFwHPPp77l0Lkv/xAAcEAABBAMBAAAAAAAAAAAAAAACAAEDEhARIhP/2gAIAQEAAQUCtyBWTQS6aIkIkOPNyV1H0LYid6f/xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAEDAQE/AR//xAAWEQADAAAAAAAAAAAAAAAAAAAAEBH/2gAIAQIBAT8BK//EACAQAAIBAQkAAAAAAAAAAAAAAAABIRECECAiMTJRYXH/2gAIAQEABj8CpB4bGTHAk1q1dmti6K4P/8QAHRABAAICAgMAAAAAAAAAAAAAAQARECExQVFxgf/aAAgBAQABPyF0cafZRSsIkUmzGoQiF6ZYLmuoaHxr3FTgIY0z/9oADAMBAAIAAwAAABB4xTL/xAAYEQACAwAAAAAAAAAAAAAAAAAAEQEQQf/aAAgBAwEBPxDWOb//xAAYEQACAwAAAAAAAAAAAAAAAAAAARARYf/aAAgBAgEBPxB5Kj//xAAfEAEAAgMAAQUAAAAAAAAAAAABABEhMVFxQWGRwdH/2gAIAQEAAT8QS80o5c7s1KU0AFbAr8iy/Ih9wdwNJQNdgogRd+ur41CmQPZlgEFAzXi5mTdAdeT1iqZWyJiewAQLZ//Z" alt="" style="position:absolute;top:0;left:0;width:100%;height:100%;object-fit:cover;object-position:center;opacity:1;transition-delay:500ms"/><noscript><picture><source srcset="/static/e402de674af0047178bbcc6e2754204d/809fc/machine-learning-workstation.jpg 850w,
/static/e402de674af0047178bbcc6e2754204d/4f4f6/machine-learning-workstation.jpg 1700w,
/static/e402de674af0047178bbcc6e2754204d/fd1df/machine-learning-workstation.jpg 3024w" sizes="(max-width: 3024px) 100vw, 3024px" /><img loading="lazy" sizes="(max-width: 3024px) 100vw, 3024px" srcset="/static/e402de674af0047178bbcc6e2754204d/809fc/machine-learning-workstation.jpg 850w,
/static/e402de674af0047178bbcc6e2754204d/4f4f6/machine-learning-workstation.jpg 1700w,
/static/e402de674af0047178bbcc6e2754204d/fd1df/machine-learning-workstation.jpg 3024w" src="/static/e402de674af0047178bbcc6e2754204d/fd1df/machine-learning-workstation.jpg" alt="" style="position:absolute;top:0;left:0;opacity:1;width:100%;height:100%;object-fit:cover;object-position:center"/></picture></noscript></div></div><h1>How I built my ML workstation ðŸ”¬</h1><div class="blog-details"><time class="blog-createdat" dateTime="2021-04-07">Apr 7, 2021</time><span> â€¢ </span><span class="blog-time2read">10<!-- --> min read</span><div class="theme-switcher"><div class="theme-switcher-toggler"><div class="theme-switcher-track"></div><div class="theme-switcher-thumb"></div><input type="checkbox" class="theme-switcher-input" aria-label="Switch between Dark and Light mode"/></div></div></div><ul class="blog-tags"><li>machine learning</li><li>computer engineering</li></ul></header><div id="intro" class="blog-divider"></div><div class="content-wrapper"><div class="blog-content-nav-wrapper"><ul class="blog-content-nav"><h2>Content</h2><li class=""><a href="#intro">Intro</a></li></ul></div><div class="content blog-content"><p>Kaggle Kernels and Google Colab are great.</p>
<div style="width:100%;height:0;padding-bottom:73%;position:relative;"><iframe src="https://giphy.com/embed/UmBdALbYTmCJ2" width="100%" height="100%" style="position:absolute" frameBorder="0" class="giphy-embed" allowFullScreen></iframe></div><p><a href="https://giphy.com/gifs/UmBdALbYTmCJ2"></a></p>
<p>I would drop my mic at this point if this article was not be about building a custom ML workstation.</p>
<p>There is always some "buts" that makes our lives harder. When you start to approach nearly real life problems and see hundreds of gigabytes large datasets, your gut feeling starts to tell you that your CPU or AMD GPU devices are not going to be enough to do meaningful things. This is how I came here.</p>
<p>I was taking part in <a href="https://www.kaggle.com/c/hpa-single-cell-image-classification">Human Protein Atlas (HPA) - Single Cell Classification</a> competition on Kaggle. HPA dataset contains nearly 150Gb of 8bits 4-channels protein images. 16bits variant of the dataset holds 350Gb.</p>
<p>Here is what I had at my disposal:</p>
<ul>
<li>MacBook Pro 2019 (Intel Core i9 &#x26;&#x26; Intel UHD Graphics 630 1536MB &#x26;&#x26; 16GB DDR4)</li>
<li>~30h GPU and/or ~30h TPU hours per week on Kaggle Kernels</li>
</ul>
<p>Sounds good. I though I would be able to prototype locally and then execute notebooks on the cloud GPU. What could go wrong?</p>
<h2 id="life-without-gpu" style="position:relative;"><a href="#life-without-gpu" aria-label="life without gpu permalink" class="anchor before"><svg class="anchor-icon" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Life Without GPU</h2>
<p>As it turned out, there are a lot of frictions in the mentioned workflow.</p>
<p>First of all, my solution source code quickly became an entire project with a lot of source code and dependencies. I used <a href="https://python-poetry.org/">poetry</a> as a package manager and decided to generate an installable package every time I made meaningful changes to the project in order to test them in the cloud. These installable packages I was uploading into a private Kaggle dataset which in turn was mounted to a notebook. The notebook was calling classes and functions from the package.</p>
<p>This approach to bring a full-size project turns out to have underwater stones. Kaggle notebooks randomly thrown weird errors after installing project packages. I think it was related to dependency version mismatch and I spotted errors like "method X is not found in package Y", etc. Autoreload was not helpful. Several mornings in a row I started my day dealing with new and new suddenly occurred unearthly issues.</p>
<div style="width:100%;height:0;padding-bottom:75%;position:relative;"><iframe src="https://giphy.com/embed/l2YWmG9FBDtiqHTi0" width="100%" height="100%" style="position:absolute" frameBorder="0" class="giphy-embed" allowFullScreen></iframe></div><p><a href="https://giphy.com/gifs/gilmoregirls-netflix-gilmore-girls-l2YWmG9FBDtiqHTi0"></a></p>
<p>While working on the competition, I switched from Keras to PyTorch. PyTorch is much slower on CPU then TensorFlow or Keras. It was time consuming to even perform a dev run of my recent changes. However, PyTorch has outstanding support in academic and other ML-associated communities which means a bunch of (<strong>almost</strong>) read-to-use examples of state-of-art technics.</p>
<p>Also, when you run your code in the cloud, you can not easily experiment. You have to plan what you are going to experiment with and make that part somehow configurable.</p>
<p>All in all, the experience was frustrating. I clearly realized if I wanted to do more complex deep learning experiments and projects, then I just need to have 24/7 access to any kind of GPUs.</p>
<h2 id="investigation" style="position:relative;"><a href="#investigation" aria-label="investigation permalink" class="anchor before"><svg class="anchor-icon" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Investigation</h2>
<p>I have never been interested in custom PC building, hardware or gaming. So it took me a while to understand what did it cost me to build a custom machine.</p>
<div style="width:100%;height:0;padding-bottom:75%;position:relative;"><iframe src="https://giphy.com/embed/kxkmUjgUwzhk7uIxOA" width="100%" height="100%" style="position:absolute" frameBorder="0" class="giphy-embed" allowFullScreen></iframe></div><p><a href="https://giphy.com/gifs/hyperrpg-twitch-kollok-kollok1991-kxkmUjgUwzhk7uIxOA"></a></p>
<p>There are a lot of resources on building gaming PCs. While building a deep learning workstation sounds like a similar task, there are nuances that should be accounted in order to build a cost-efficient and ML-compatible machine.</p>
<p>I have found a few useful blog posts which helped me to quickly grasp the topic. Particularly, I could highlight two posts from <a target="_blank" rel="noopener" href="https://twitter.com/Tim_Dettmers">Tim Dettmers</a>:</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://timdettmers.com/2018/12/16/deep-learning-hardware-guide/">A Full Hardware Guide to Deep Learning</a></li>
<li><a target="_blank" rel="noopener" href="https://timdettmers.com/2020/09/07/which-gpu-for-deep-learning/">Which GPU(s) to Get for Deep Learning: My Experience and Advice for Using GPUs in Deep Learning</a></li>
</ul>
<p>In his blog, Tim explained at length importance of each PC part for ML workstation and provides general pieces of advice on choosing them. Here I'm going to mention information that was helpful for me along with details Tim did not focus on.</p>
<p>Also, <a target="_blank" rel="noopener" href="https://pcpartpicker.com">PCPartsPicker's Builder</a> was super helpful during planning PC. It suggested possible components compatibilities and things to check before ordering the list. It helped to overcome my constant fear that I could buy something that would not work together.</p>
<h2 id="parts-for-ml-build" style="position:relative;"><a href="#parts-for-ml-build" aria-label="parts for ml build permalink" class="anchor before"><svg class="anchor-icon" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Parts for ML build</h2>
<p>When it comes to building a deep learning machine (or any custom PC), there are 8 parts that should be considered:</p>
<ul>
<li><a href="#gpu">GPU</a></li>
<li><a href="#motherboard">Motherboard (a.k.a. MoBo)</a></li>
<li><a href="#cpu">CPU</a></li>
<li><a href="#ram">RAM</a></li>
<li><a href="#storage">Storage</a></li>
<li><a href="#power-system-unit">Power System Unit (PSU)</a></li>
<li><a href="#cooling">Cooling</a></li>
<li><a href="#pc-case">PC case</a></li>
</ul>
<p>Here is an overview:</p>
<h3 id="gpu" style="position:relative;"><a href="#gpu" aria-label="gpu permalink" class="anchor before"><svg class="anchor-icon" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>GPU</h3>
<p>GPU is <strong>the key component</strong> of any ML workstation. It's designed to perform computations on <strong>big chunks of data</strong> (throughput-optimized) <strong>in parallel</strong> which makes it perfect for model training or inference where it's really needed (<a target="_blank" rel="noopener" href="https://www.quora.com/Why-are-GPUs-well-suited-to-deep-learning/answer/Tim-Dettmers-1" title="Why GPU is faster then CPU?">here is details</a>).</p>
<p>The very fist consideration is that we need <strong>NVIDIA graphic cards only</strong> for deep learning. Unfortunately, there is a monopoly in ML framework world. Most of the popular and production-ready frameworks (TensorFlow, PyTorch, Keras) are designed and optimized for CUDA-enabled devices. CUDA is a proprietary platform and set of APIs for parallel computations owned by NVIDIA. This is the reason why we mean "CUDA cards" when talk about the GPU in ML context.</p>
<p>It makes sense to dig just slightly deeper in a simplified CUDA architecture. Modern GPUs are based on <strong>tensor cores</strong> that are capable of multiplying <strong>4x4 matrices in one operation</strong> which is blazing fast. Despite that, tensor cores need data to perform computations on. Data passes the following way in order to be loaded efficiently:</p>
<ul>
<li><strong>From CPU to Global GPU Memory</strong>. CPU threads load preprocessed batches into entirely separate GPU device memory (don't be confused with PC RAM). The device memory is the slowest kind of memory in the GPU.</li>
<li><strong>From Global GPU Memory to Shared Memory</strong>. Shared memory is <strong>~10-50x faster</strong> then the global GPU memory, but it's also much smaller (normally hundreds of Kbs). This memory is purely available for a Streaming Multiprocessor (SM) that is an analogue of CPU core in GPU architecture. Data is stored there in so called tiles.</li>
<li><strong>From Shared Memory to Tensor Core Registries</strong>. Streaming Multiprocessors operates their tensor cores in parallel and upload part of the tiles into tensor core registries.</li>
</ul>
<p>So any bottlenecks in data loading flow would lead to suboptimal utilization of tensor cores, no matter how many of them you have in your GPU.</p>
<p><span
      class="gatsby-resp-image-wrapper"
      style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; "
    >
      <span
    class="gatsby-resp-image-background-image"
    style="padding-bottom: 50.588235294117645%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAIAAAA7N+mxAAAACXBIWXMAAAsSAAALEgHS3X78AAACLUlEQVQoz22OzW/ScBzG+6940sTFxLi7Fw+e/GNmou5klungssw5XRQ3dLqBKMpGxyiwMUrHy5DS9scPGH0B2tIX3lZGoYxtyWyyoyaffPLkeb6HL0KUCEblgM4DjaNV1g6MjcYCiQJyhVE4oLC0fAKaLFA4pskW5aJh9qSGpCkqApvtumDVhWEJdmhSFrhBjTP52rAottn6sCEMeX5QKEiVcs+eGtyo3Op3I/TZ4/XTJ24Eim0qDZgMU8yX8EjihGZJIg8prqxYkBHJeK58XMHDOJWH4LhIJsmTvmn4SeOW83RqEYGSGgx820E3Ewn0h8+FpzCf50OciFX1SeYovbW2jB+Gk9u+Y/dm0u8lPrqrtUY3zFzcfWs+WEFoQavvQhiBEKVKQaqIwVqQpnEOyP1qViz7c6WUKEFed3hbMN96h4q5SgsD5p3F3v0lBHB63wO1Tyl1LS25jvT17GCDrm9kqYbRPBQNV1Z9T3RQ3KqkB3lilEs2DbUbZK6nVifTqwijac0gaG8zsv8P603x39OdACNjJdLscnmx84tSfhdEX0b4ktR9uZ6HLHP1LkaP7benVxBh66A9F9Od+8o8ps5jtvWFfX0hqjpQ3RFpOffVVxHFZi6svY62XkYbX+Paz7R1e+ns3htEcUWvZkLns3uT2fDkxi/2xs9DxtMd69munW8a2/bN5Uyos3qgB7LXDz+PH60jw8uR+T9GV9a/5eBiaF2fD3Sjghb4GPwLYbjbXB3M818AAAAASUVORK5CYII='); background-size: cover; display: block;"
  ></span>
  <img
        class="gatsby-resp-image-image"
        alt="CUDA Hardware Architecture"
        title="CUDA Hardware Architecture"
        src="/static/31e01e49012ed2c375a2f5d65fd7050b/c5bb3/cuda-hardware-architecture.png"
        srcset="/static/31e01e49012ed2c375a2f5d65fd7050b/04472/cuda-hardware-architecture.png 170w,
/static/31e01e49012ed2c375a2f5d65fd7050b/9f933/cuda-hardware-architecture.png 340w,
/static/31e01e49012ed2c375a2f5d65fd7050b/c5bb3/cuda-hardware-architecture.png 680w,
/static/31e01e49012ed2c375a2f5d65fd7050b/02cd5/cuda-hardware-architecture.png 821w"
        sizes="(max-width: 680px) 100vw, 680px"
        style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;"
        loading="lazy"
      />
    </span></p>
<div class="image-title">CUDA Hardware Architecture (<a target="_blank" rel="noopener" href="https://dadaiscrazy.github.io/usuba/2020/03/28/CUDA-basics.html" title="source of the image">source</a>)</div>
<p>With that being said, these are roughly the main GPU features important for ML tasks:</p>
<ul>
<li><strong>Global GPU Memory</strong> - defines how big batch sizes you can use during training or how quality samples you can use if it comes to computer vision</li>
<li><strong>Memory Bandwidth</strong> - a rate at which data is being transferred inside of the device</li>
<li><strong>Architecture</strong> - the more recent architecture is the better. Newer architectures may be better in terms of shared memory size, feature set (like mixed precision computations) and could be more efficient in terms of wattage per effective computations metric.</li>
</ul>
<p>Additionally, you should think about these factors:</p>
<ul>
<li><strong>Performance per Cost</strong></li>
<li><strong>GPU Cooling</strong></li>
<li><strong>GPU Wattage</strong></li>
</ul>
<p>Thankfully, you can find much more on that in the <a target="_blank" rel="noopener" href="https://timdettmers.com/2020/09/07/which-gpu-for-deep-learning/">Tim's post</a>.</p>
<h3 id="motherboard" style="position:relative;"><a href="#motherboard" aria-label="motherboard permalink" class="anchor before"><svg class="anchor-icon" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Motherboard</h3>
<p>Motherboard integrates most of the components and also provides:</p>
<ul>
<li>most of the I/O ports (like USB, Ethernet, etc)</li>
<li>chipset with BIOS</li>
<li>WiFi, Bluetooth adapters</li>
</ul>
<p>Motherboard provides other interfaces to power your stuff. Among them, the one of most important is CPU. The motherboards are divided into AMD- and Intel-compatible sockets which are not interchangable. Hence, you need to make sure <strong>CPU of you choice</strong> is <strong>compatible with your motherboard</strong>.</p>
<p><strong>Number of PCI ports</strong> is another thing to consider. Since PCI ports are used to connect GPUs, you need to plan ahead your build and rooms for upgrades (to be able to add more cards in the future, for example). Also, pay attention that, effectively, graphic cards takes more then slot of space. We want to have <strong>as much space as possible</strong> between cards for <strong>better air cooling</strong>.</p>
<p>Also, I'm pretty sure you would be happy to have build-in WiFi adapter. Otherwise, the only way to connect a PC would be via ethernet cable which is not alway convenient (or just buy an external adapter).</p>
<h3 id="cpu" style="position:relative;"><a href="#cpu" aria-label="cpu permalink" class="anchor before"><svg class="anchor-icon" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>CPU</h3>
<p>TBU</p>
<h3 id="ram" style="position:relative;"><a href="#ram" aria-label="ram permalink" class="anchor before"><svg class="anchor-icon" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>RAM</h3>
<p>TBU</p>
<h3 id="storage" style="position:relative;"><a href="#storage" aria-label="storage permalink" class="anchor before"><svg class="anchor-icon" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Storage</h3>
<p>TBU</p>
<h3 id="power-system-unit" style="position:relative;"><a href="#power-system-unit" aria-label="power system unit permalink" class="anchor before"><svg class="anchor-icon" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Power System Unit</h3>
<p>TBU</p>
<h3 id="cooling" style="position:relative;"><a href="#cooling" aria-label="cooling permalink" class="anchor before"><svg class="anchor-icon" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Cooling</h3>
<p>With a great power comes a great <del>responsibility</del> need for cooling.</p>
<h3 id="pc-case" style="position:relative;"><a href="#pc-case" aria-label="pc case permalink" class="anchor before"><svg class="anchor-icon" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>PC Case</h3>
<p>TBU</p>
<h2 id="my-parts-list" style="position:relative;"><a href="#my-parts-list" aria-label="my parts list permalink" class="anchor before"><svg class="anchor-icon" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>My Parts List</h2>
<p>Creating a multi-GPU cluster was not on my list. Yet still I wanted to have a room for improvements. So I took <a target="_blank" rel="noopener" href="https://pcpartpicker.com/user/tim_dettmers/saved/#view=mZ2rD3">2-GPUs barebone from Tim's templates</a> as a base for my workstation and adjusted it a bit to match what I could find on the local market. Here is my final list of components:</p>
<ul>
<li>GPU: <a target="_blank" rel="noopener" href="https://www.newegg.com/gigabyte-geforce-rtx-3070-gv-n3070aorus-m-8gd/p/N82E16814932359">Gigabyte GeForce RTX 3070 8Gb Aorus Master</a></li>
<li>Matherboard: <a target="_blank" rel="noopener" href="https://www.newegg.com/msi-performance-gaming-x470-gaming-plus-max/p/N82E16813144266">MSI x470 Gaming Plus</a></li>
<li>CPU: <a target="_blank" rel="noopener" href="https://www.newegg.com/amd-ryzen-5-3600/p/N82E16819113569">AMD Ryzen 5 3600</a></li>
<li>RAM: <a target="_blank" rel="noopener" href="https://www.newegg.com/g-skill-32gb-288-pin-ddr4-sdram/p/N82E16820232091">G.Skill Ripjaws V Series 32Gb (2 x 16Gb)</a></li>
<li>Storage: <a target="_blank" rel="noopener" href="https://www.newegg.com/samsung-970-evo-plus-500gb/p/N82E16820147742">Samsung 970 Evo 500Gb M.2-2280 NVME</a></li>
<li>Cooling: <a target="_blank" rel="noopener" href="https://www.newegg.com/cooler-master-hyper-212-black-edition-rr-212s-20pk-r1/p/N82E16835103278">Cooler Master Hyper 212 Black Edition</a></li>
<li>PSU: <a target="_blank" rel="noopener" href="https://pcpartpicker.com/product/MfJwrH/evga-power-supply-220g20750xr">EVGA G2 750W 80+ Gold</a></li>
<li>PC Case: <a target="_blank" rel="noopener" href="https://www.newegg.com/matte-black-nzxt-h-series-h510-atx-mid-tower/p/N82E16811146315">NZXT H510</a></li>
<li>Wireless Adapter: <a target="_blank" rel="noopener" href="https://www.newegg.com/tp-link-archer-t2u-plus-usb-2-0/p/N82E16833704471">TP-Link Archer T2U Plus</a></li>
</ul>
<p>The same list on PCPartsPicker can be found <a target="_blank" rel="noopener" href="https://pcpartpicker.com/user/roman-glushko/saved/8gZHGX">here</a>.</p>
<p><span
      class="gatsby-resp-image-wrapper"
      style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; "
    >
      <span
    class="gatsby-resp-image-background-image"
    style="padding-bottom: 28.82352941176471%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAGCAIAAABM9SnKAAAACXBIWXMAABYlAAAWJQFJUiTwAAAAtUlEQVQY03VPS25CMQzM/eFQnIJ1kWg3harCL/Jz7Ik7CT8h0WgWk3g+ToHVntmBfj94w3PyK5liDmwtXS804z/z0A81womOGI9W5bi378+CVab5oc9nA3lbO2EVTQf3cSV301ikpP4mAtGYmuHpxhlFOQG3Dk+WZ84l8sYJ1YL6M23WqXNGYMi43gDuK7we/qK1ECmAM0aWxSOYSvnpfG6tXbmIuI/mWquq5iyXw8fXdiO73R+UTWCgpXUv2QAAAABJRU5ErkJggg=='); background-size: cover; display: block;"
  ></span>
  <img
        class="gatsby-resp-image-image"
        alt="GPU Price Dynamics: end of 2020 - beginning of 2021"
        title="GPU Price Dynamics: end of 2020 - beginning of 2021"
        src="/static/94a0fe9154e1ecdbf20afbb7d072931a/c5bb3/gpu-price-dynamics.png"
        srcset="/static/94a0fe9154e1ecdbf20afbb7d072931a/04472/gpu-price-dynamics.png 170w,
/static/94a0fe9154e1ecdbf20afbb7d072931a/9f933/gpu-price-dynamics.png 340w,
/static/94a0fe9154e1ecdbf20afbb7d072931a/c5bb3/gpu-price-dynamics.png 680w,
/static/94a0fe9154e1ecdbf20afbb7d072931a/b12f7/gpu-price-dynamics.png 1020w,
/static/94a0fe9154e1ecdbf20afbb7d072931a/b5a09/gpu-price-dynamics.png 1360w,
/static/94a0fe9154e1ecdbf20afbb7d072931a/6c86f/gpu-price-dynamics.png 1720w"
        sizes="(max-width: 680px) 100vw, 680px"
        style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;"
        loading="lazy"
      />
    </span></p>
<div class="image-title">GPU Price Dynamics: end of 2020 - beginning of 2021. Wild time</div>
<h2 id="hardware-installation" style="position:relative;"><a href="#hardware-installation" aria-label="hardware installation permalink" class="anchor before"><svg class="anchor-icon" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Hardware Installation</h2>
<p><span
      class="gatsby-resp-image-wrapper"
      style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; "
    >
      <span
    class="gatsby-resp-image-background-image"
    style="padding-bottom: 75.29411764705883%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAPABQDASIAAhEBAxEB/8QAGAAAAwEBAAAAAAAAAAAAAAAAAAEDAgX/xAAVAQEBAAAAAAAAAAAAAAAAAAABAv/aAAwDAQACEAMQAAABlTamugID/8QAHBAAAQQDAQAAAAAAAAAAAAAAAgABAxETFCEx/9oACAEBAAEFAssiGQ79Wu6aE6Eef//EABYRAQEBAAAAAAAAAAAAAAAAAAABEf/aAAgBAwEBPwFtf//EABURAQEAAAAAAAAAAAAAAAAAAAAh/9oACAECAQE/AUf/xAAaEAABBQEAAAAAAAAAAAAAAAAAARARITIx/9oACAEBAAY/AtWbZeEQhZ//xAAbEAACAwADAAAAAAAAAAAAAAAAAREhUUGBkf/aAAgBAQABPyGaVWTKx9uBNInpfrNi8nuQ6n//2gAMAwEAAgADAAAAEFvv/8QAFxEAAwEAAAAAAAAAAAAAAAAAAAERYf/aAAgBAwEBPxBqGJ//xAAWEQEBAQAAAAAAAAAAAAAAAAABABH/2gAIAQIBAT8Q0ZJ//8QAHBABAQACAgMAAAAAAAAAAAAAAREAITFBUXGB/9oACAEBAAE/ECBcCPAD6xcShtRWUKEVLxlU3dCWlwqlCXGpTt56+Z//2Q=='); background-size: cover; display: block;"
  ></span>
  <img
        class="gatsby-resp-image-image"
        alt="PC Parts"
        title="PC Parts"
        src="/static/622bb14ac740d8200c6cdc3fbe3cf8b0/7bf67/pc-parts.jpg"
        srcset="/static/622bb14ac740d8200c6cdc3fbe3cf8b0/651be/pc-parts.jpg 170w,
/static/622bb14ac740d8200c6cdc3fbe3cf8b0/d30a3/pc-parts.jpg 340w,
/static/622bb14ac740d8200c6cdc3fbe3cf8b0/7bf67/pc-parts.jpg 680w,
/static/622bb14ac740d8200c6cdc3fbe3cf8b0/990cb/pc-parts.jpg 1020w,
/static/622bb14ac740d8200c6cdc3fbe3cf8b0/c44b8/pc-parts.jpg 1360w,
/static/622bb14ac740d8200c6cdc3fbe3cf8b0/d2602/pc-parts.jpg 4032w"
        sizes="(max-width: 680px) 100vw, 680px"
        style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;"
        loading="lazy"
      />
    </span></p>
<div class="image-title">PC parts arrived. I think I could build a new house with these boxes. Stay tuned for more updates on this</div>
<h3 id="motherboard-1" style="position:relative;"><a href="#motherboard-1" aria-label="motherboard 1 permalink" class="anchor before"><svg class="anchor-icon" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Motherboard</h3>
<p><span
      class="gatsby-resp-image-wrapper"
      style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; "
    >
      <span
    class="gatsby-resp-image-background-image"
    style="padding-bottom: 75.29411764705883%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAPABQDASIAAhEBAxEB/8QAGAAAAgMAAAAAAAAAAAAAAAAAAAMBAgT/xAAVAQEBAAAAAAAAAAAAAAAAAAABAP/aAAwDAQACEAMQAAABbiawZKkf/8QAGBAAAwEBAAAAAAAAAAAAAAAAAAECAwT/2gAIAQEAAQUCrWx76GNVUrGxc4lMn//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8BP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8BP//EAB0QAAEDBQEAAAAAAAAAAAAAAAABEUECEiExUZH/2gAIAQEABj8C2R4OqycMjW1H/8QAHRAAAgEEAwAAAAAAAAAAAAAAAREAITFBUYGR0f/aAAgBAQABPyF8jDQjd4FdXoI4igvAGrcQSguvZ//aAAwDAQACAAMAAAAQNP8A/8QAFhEBAQEAAAAAAAAAAAAAAAAAAAEh/9oACAEDAQE/EK1//8QAFhEBAQEAAAAAAAAAAAAAAAAAAAEh/9oACAECAQE/EIx//8QAGhABAQADAQEAAAAAAAAAAAAAAREAIVFBMf/aAAgBAQABPxBQSUGlrzGs1eUZO1Y0nhhUUEI3dnc6u2iCb+GIBFsqx//Z'); background-size: cover; display: block;"
  ></span>
  <img
        class="gatsby-resp-image-image"
        alt="MSI X470 Gaming Max Unboxing"
        title="MSI X470 Gaming Max Unboxing"
        src="/static/ddf2d90e112f8ccf1bdfc1be92a7dc6d/7bf67/msi-x470-gaming-max-unboxing.jpg"
        srcset="/static/ddf2d90e112f8ccf1bdfc1be92a7dc6d/651be/msi-x470-gaming-max-unboxing.jpg 170w,
/static/ddf2d90e112f8ccf1bdfc1be92a7dc6d/d30a3/msi-x470-gaming-max-unboxing.jpg 340w,
/static/ddf2d90e112f8ccf1bdfc1be92a7dc6d/7bf67/msi-x470-gaming-max-unboxing.jpg 680w,
/static/ddf2d90e112f8ccf1bdfc1be92a7dc6d/990cb/msi-x470-gaming-max-unboxing.jpg 1020w,
/static/ddf2d90e112f8ccf1bdfc1be92a7dc6d/c44b8/msi-x470-gaming-max-unboxing.jpg 1360w,
/static/ddf2d90e112f8ccf1bdfc1be92a7dc6d/d2602/msi-x470-gaming-max-unboxing.jpg 4032w"
        sizes="(max-width: 680px) 100vw, 680px"
        style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;"
        loading="lazy"
      />
    </span></p>
<div class="image-title">Motherboard Unboxing</div>
<p><span
      class="gatsby-resp-image-wrapper"
      style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; "
    >
      <span
    class="gatsby-resp-image-background-image"
    style="padding-bottom: 75.29411764705883%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAPABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAAQDBf/EABUBAQEAAAAAAAAAAAAAAAAAAAAB/9oADAMBAAIQAxAAAAHaKic7Aj//xAAaEAADAQADAAAAAAAAAAAAAAABAgMAERMj/9oACAEBAAEFAq0PY1H0DzKq+whRtBSkv//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8BP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8BP//EABsQAQEAAQUAAAAAAAAAAAAAAAEAAhEhMTKR/9oACAEBAAY/AkMrs+xZaFsQZc3/xAAcEAADAAIDAQAAAAAAAAAAAAAAAREhYTFBUXH/2gAIAQEAAT8hx/zohWZfQ59uvY+iHfTgjGxUUSn/2gAMAwEAAgADAAAAEFPv/8QAFREBAQAAAAAAAAAAAAAAAAAAEBH/2gAIAQMBAT8Qh//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8QP//EABsQAQADAAMBAAAAAAAAAAAAAAEAESExQaFR/9oACAEBAAE/EGqzTFiZsVVSaAe/YufYVW8y7oZSqrDIjQTtTyX1AkseWf/Z'); background-size: cover; display: block;"
  ></span>
  <img
        class="gatsby-resp-image-image"
        alt="MotherBoard"
        title="MotherBoard"
        src="/static/9f0f1d64b3bd0237f2db19703401dffc/7bf67/msi-x470-gamin-plus-detailed-view.jpg"
        srcset="/static/9f0f1d64b3bd0237f2db19703401dffc/651be/msi-x470-gamin-plus-detailed-view.jpg 170w,
/static/9f0f1d64b3bd0237f2db19703401dffc/d30a3/msi-x470-gamin-plus-detailed-view.jpg 340w,
/static/9f0f1d64b3bd0237f2db19703401dffc/7bf67/msi-x470-gamin-plus-detailed-view.jpg 680w,
/static/9f0f1d64b3bd0237f2db19703401dffc/990cb/msi-x470-gamin-plus-detailed-view.jpg 1020w,
/static/9f0f1d64b3bd0237f2db19703401dffc/c44b8/msi-x470-gamin-plus-detailed-view.jpg 1360w,
/static/9f0f1d64b3bd0237f2db19703401dffc/d2602/msi-x470-gamin-plus-detailed-view.jpg 4032w"
        sizes="(max-width: 680px) 100vw, 680px"
        style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;"
        loading="lazy"
      />
    </span></p>
<div class="image-title">Motherboard. Detailed View</div>
<h3 id="cpu-1" style="position:relative;"><a href="#cpu-1" aria-label="cpu 1 permalink" class="anchor before"><svg class="anchor-icon" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>CPU</h3>
<p><span
      class="gatsby-resp-image-wrapper"
      style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; "
    >
      <span
    class="gatsby-resp-image-background-image"
    style="padding-bottom: 75.29411764705883%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAPABQDASIAAhEBAxEB/8QAGAAAAwEBAAAAAAAAAAAAAAAAAAQFAQP/xAAVAQEBAAAAAAAAAAAAAAAAAAABAP/aAAwDAQACEAMQAAABal2OA4MBf//EABoQAAIDAQEAAAAAAAAAAAAAAAIDAAEREhP/2gAIAQEAAQUCfeQ3sqLdoNrofEZwM//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8BP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8BP//EABkQAAIDAQAAAAAAAAAAAAAAAAABAhExEP/aAAgBAQAGPwLaKU2K+YYf/8QAGhABAQEBAAMAAAAAAAAAAAAAAREAMVFhcf/aAAgBAQABPyFWRfGRYHcyxWd86pAvvXa2mjw7/9oADAMBAAIAAwAAABAT7//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8QP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8QP//EABkQAQADAQEAAAAAAAAAAAAAAAEAESExUf/aAAgBAQABPxBYeq2AJOSmswpq7eOwCLzSOQzwCrYFoBP/2Q=='); background-size: cover; display: block;"
  ></span>
  <img
        class="gatsby-resp-image-image"
        alt="AMD Ryzen 5 3600 Unboxing"
        title="AMD Ryzen 5 3600 Unboxing"
        src="/static/e02e45de02e74ca8360508308316e325/7bf67/amd-ryzen-5-3600-unboxing.jpg"
        srcset="/static/e02e45de02e74ca8360508308316e325/651be/amd-ryzen-5-3600-unboxing.jpg 170w,
/static/e02e45de02e74ca8360508308316e325/d30a3/amd-ryzen-5-3600-unboxing.jpg 340w,
/static/e02e45de02e74ca8360508308316e325/7bf67/amd-ryzen-5-3600-unboxing.jpg 680w,
/static/e02e45de02e74ca8360508308316e325/990cb/amd-ryzen-5-3600-unboxing.jpg 1020w,
/static/e02e45de02e74ca8360508308316e325/c44b8/amd-ryzen-5-3600-unboxing.jpg 1360w,
/static/e02e45de02e74ca8360508308316e325/d2602/amd-ryzen-5-3600-unboxing.jpg 4032w"
        sizes="(max-width: 680px) 100vw, 680px"
        style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;"
        loading="lazy"
      />
    </span></p>
<div class="image-title">CPU Unboxing</div>
<p><span
      class="gatsby-resp-image-wrapper"
      style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; "
    >
      <span
    class="gatsby-resp-image-background-image"
    style="padding-bottom: 75.29411764705883%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAPABQDASIAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAAAAMC/8QAFQEBAQAAAAAAAAAAAAAAAAAAAAH/2gAMAwEAAhADEAAAAcymgD//xAAYEAEBAQEBAAAAAAAAAAAAAAABAAIRIv/aAAgBAQABBQLw2gksj3XW7f/EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8BP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8BP//EABYQAAMAAAAAAAAAAAAAAAAAACAhQf/aAAgBAQAGPwKsv//EABsQAQADAQADAAAAAAAAAAAAAAEAESExQWFx/9oACAEBAAE/IS/PI/IdKvYQ1sIXmQhS72XPU//aAAwDAQACAAMAAAAQmO//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/ED//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/ED//xAAcEAEBAAICAwAAAAAAAAAAAAABEQBBIVExYZH/2gAIAQEAAT8QTtwL4jT9w64lCd5RlTioYYkhDcLC9XWTALAWbz//2Q=='); background-size: cover; display: block;"
  ></span>
  <img
        class="gatsby-resp-image-image"
        alt="AM4 CPU Socket"
        title="AM4 CPU Socket"
        src="/static/045c290ae614a6313441666f9e29f975/7bf67/am4-cpu-socket.jpg"
        srcset="/static/045c290ae614a6313441666f9e29f975/651be/am4-cpu-socket.jpg 170w,
/static/045c290ae614a6313441666f9e29f975/d30a3/am4-cpu-socket.jpg 340w,
/static/045c290ae614a6313441666f9e29f975/7bf67/am4-cpu-socket.jpg 680w,
/static/045c290ae614a6313441666f9e29f975/990cb/am4-cpu-socket.jpg 1020w,
/static/045c290ae614a6313441666f9e29f975/c44b8/am4-cpu-socket.jpg 1360w,
/static/045c290ae614a6313441666f9e29f975/d2602/am4-cpu-socket.jpg 4032w"
        sizes="(max-width: 680px) 100vw, 680px"
        style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;"
        loading="lazy"
      />
    </span></p>
<div class="image-title">CPU Socket</div>
<p>TBU</p>
<h3 id="ssd" style="position:relative;"><a href="#ssd" aria-label="ssd permalink" class="anchor before"><svg class="anchor-icon" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>SSD</h3>
<p><span
      class="gatsby-resp-image-wrapper"
      style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; "
    >
      <span
    class="gatsby-resp-image-background-image"
    style="padding-bottom: 75.29411764705883%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAPABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAwACBP/EABUBAQEAAAAAAAAAAAAAAAAAAAAB/9oADAMBAAIQAxAAAAHqLYw0Ef/EABoQAAICAwAAAAAAAAAAAAAAAAABAgMEEyH/2gAIAQEAAQUCnYqxZCk9hYcEj//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8BP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8BP//EABsQAAICAwEAAAAAAAAAAAAAAAARASECEBJx/9oACAEBAAY/ArlCib81eLHwiT//xAAZEAEAAwEBAAAAAAAAAAAAAAABABExIWH/2gAIAQEAAT8hYyZkKdDIO0Toyi2BhRoV5URslWz/2gAMAwEAAgADAAAAEGff/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPxA//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPxA//8QAHRABAQEAAQUBAAAAAAAAAAAAAREAMSFBUWGBkf/aAAgBAQABPxAZ1BRzw36wd2Bqor5woiaCDP3Sh3hFH3PcoAvo3//Z'); background-size: cover; display: block;"
  ></span>
  <img
        class="gatsby-resp-image-image"
        alt="Samsung 970 EVO M.2 SSD Unboxing"
        title="Samsung 970 EVO M.2 SSD Unboxing"
        src="/static/93bbe63fcbd60e670507fc142978c935/7bf67/samsung-970-evo-m.2-unboxing.jpg"
        srcset="/static/93bbe63fcbd60e670507fc142978c935/651be/samsung-970-evo-m.2-unboxing.jpg 170w,
/static/93bbe63fcbd60e670507fc142978c935/d30a3/samsung-970-evo-m.2-unboxing.jpg 340w,
/static/93bbe63fcbd60e670507fc142978c935/7bf67/samsung-970-evo-m.2-unboxing.jpg 680w,
/static/93bbe63fcbd60e670507fc142978c935/990cb/samsung-970-evo-m.2-unboxing.jpg 1020w,
/static/93bbe63fcbd60e670507fc142978c935/c44b8/samsung-970-evo-m.2-unboxing.jpg 1360w,
/static/93bbe63fcbd60e670507fc142978c935/d2602/samsung-970-evo-m.2-unboxing.jpg 4032w"
        sizes="(max-width: 680px) 100vw, 680px"
        style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;"
        loading="lazy"
      />
    </span></p>
<div class="image-title">M.2 SSD Unboxing</div>
<p>
		<video
			src=/e539608a0d504df968e3fb85d5656f81/ssd-m.2-installation.mp4
			width="100%"
			height="auto"
			preload="auto"
			muted="true"
			title="M.2 Installation"
			autoplay
			playsinline
			controls
			loop
		></video>
	</p>
<div class="image-title">M.2 Installation</div>
<p><span
      class="gatsby-resp-image-wrapper"
      style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; "
    >
      <span
    class="gatsby-resp-image-background-image"
    style="padding-bottom: 51.764705882352935%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAKABQDASIAAhEBAxEB/8QAFwAAAwEAAAAAAAAAAAAAAAAAAAMEAv/EABUBAQEAAAAAAAAAAAAAAAAAAAAB/9oADAMBAAIQAxAAAAGfLJCsYS//xAAbEAABBAMAAAAAAAAAAAAAAAACAAEREjEyQf/aAAgBAQABBQKKIyl7Qjx0Nf/EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8BP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8BP//EABcQAAMBAAAAAAAAAAAAAAAAAAEQICH/2gAIAQEABj8C1CP/xAAaEAACAwEBAAAAAAAAAAAAAAAAAREhMUGh/9oACAEBAAE/IVq2C1qp2mOHqUeghdT/2gAMAwEAAgADAAAAEBAP/8QAFREBAQAAAAAAAAAAAAAAAAAAABH/2gAIAQMBAT8QR//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8QP//EABwQAQADAQADAQAAAAAAAAAAAAEAESExUWFxwf/aAAgBAQABPxDUh6t6zI3ALKiCTA3XjPyJrr1fuAWpt1cAtB179Z//2Q=='); background-size: cover; display: block;"
  ></span>
  <img
        class="gatsby-resp-image-image"
        alt="SSD Installation. M.2 Screw"
        title="SSD Installation. M.2 Screw"
        src="/static/1cb3129b991db37119494b5968f160ee/7bf67/ssd-m.2-installation.jpg"
        srcset="/static/1cb3129b991db37119494b5968f160ee/651be/ssd-m.2-installation.jpg 170w,
/static/1cb3129b991db37119494b5968f160ee/d30a3/ssd-m.2-installation.jpg 340w,
/static/1cb3129b991db37119494b5968f160ee/7bf67/ssd-m.2-installation.jpg 680w,
/static/1cb3129b991db37119494b5968f160ee/990cb/ssd-m.2-installation.jpg 1020w,
/static/1cb3129b991db37119494b5968f160ee/c44b8/ssd-m.2-installation.jpg 1360w,
/static/1cb3129b991db37119494b5968f160ee/03076/ssd-m.2-installation.jpg 4028w"
        sizes="(max-width: 680px) 100vw, 680px"
        style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;"
        loading="lazy"
      />
    </span></p>
<div class="image-title">SSD Installation. M.2 Screw</div>
<h3 id="ram-1" style="position:relative;"><a href="#ram-1" aria-label="ram 1 permalink" class="anchor before"><svg class="anchor-icon" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>RAM</h3>
<p><span
      class="gatsby-resp-image-wrapper"
      style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; "
    >
      <span
    class="gatsby-resp-image-background-image"
    style="padding-bottom: 75.29411764705883%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAPABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAABAABBf/EABUBAQEAAAAAAAAAAAAAAAAAAAAB/9oADAMBAAIQAxAAAAFBUGjpWx//xAAZEAADAQEBAAAAAAAAAAAAAAABAgMABBT/2gAIAQEAAQUCrVkx6qDQc0nSZc+amipSf//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8BP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8BP//EABwQAAIBBQEAAAAAAAAAAAAAAAABMQISISJBkf/aAAgBAQAGPwLU54XMwQhKqT//xAAaEAEAAgMBAAAAAAAAAAAAAAABABEQIWFR/9oACAEBAAE/IWgAwjVny8K6W2FOYvdD0d4+n//aAAwDAQACAAMAAAAQNx//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/ED//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/ED//xAAbEAEBAAMAAwAAAAAAAAAAAAABEQAhMUGRsf/aAAgBAQABPxBVQiyXzjlevrT3zAJqECcc06ghbI3DhdnN9ZIOVWbz/9k='); background-size: cover; display: block;"
  ></span>
  <img
        class="gatsby-resp-image-image"
        alt="G.Skill Ripjaws V Series 32Gb Unboxing"
        title="G.Skill Ripjaws V Series 32Gb Unboxing"
        src="/static/095f252042efa7d046d514eb2f584955/7bf67/g.skill-ripjaws-v-series-32gb-unboxing.jpg"
        srcset="/static/095f252042efa7d046d514eb2f584955/651be/g.skill-ripjaws-v-series-32gb-unboxing.jpg 170w,
/static/095f252042efa7d046d514eb2f584955/d30a3/g.skill-ripjaws-v-series-32gb-unboxing.jpg 340w,
/static/095f252042efa7d046d514eb2f584955/7bf67/g.skill-ripjaws-v-series-32gb-unboxing.jpg 680w,
/static/095f252042efa7d046d514eb2f584955/990cb/g.skill-ripjaws-v-series-32gb-unboxing.jpg 1020w,
/static/095f252042efa7d046d514eb2f584955/c44b8/g.skill-ripjaws-v-series-32gb-unboxing.jpg 1360w,
/static/095f252042efa7d046d514eb2f584955/d2602/g.skill-ripjaws-v-series-32gb-unboxing.jpg 4032w"
        sizes="(max-width: 680px) 100vw, 680px"
        style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;"
        loading="lazy"
      />
    </span></p>
<div class="image-title">RAM Unboxing</div>
<p><span
      class="gatsby-resp-image-wrapper"
      style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; "
    >
      <span
    class="gatsby-resp-image-background-image"
    style="padding-bottom: 43.529411764705884%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAJABQDASIAAhEBAxEB/8QAFwAAAwEAAAAAAAAAAAAAAAAAAAEEA//EABUBAQEAAAAAAAAAAAAAAAAAAAAB/9oADAMBAAIQAxAAAAFS2xwzMP/EABsQAAIBBQAAAAAAAAAAAAAAAAIDAAEREhMx/9oACAEBAAEFAmNPImMvtOVhdKf/xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAaEAABBQEAAAAAAAAAAAAAAAAAAhARITFC/9oACAEBAAY/Aqk6NFv/AP/EABsQAAICAwEAAAAAAAAAAAAAAAABETEhQXGB/9oACAEBAAE/IZDW8mWTT0ol56XFpZcP/9oADAMBAAIAAwAAABDs/wD/xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/ED//xAAVEQEBAAAAAAAAAAAAAAAAAAAQEf/aAAgBAgEBPxCn/8QAHBABAAICAwEAAAAAAAAAAAAAAQARIaExYcHw/9oACAEBAAE/EKdUMUXMc0nNKK3MVEAvMzNjwmkT4O5//9k='); background-size: cover; display: block;"
  ></span>
  <img
        class="gatsby-resp-image-image"
        alt="RAM Installation"
        title="RAM Installation"
        src="/static/e1bacb52da1160f342ae46460b7bd6b8/7bf67/ram-installation.jpg"
        srcset="/static/e1bacb52da1160f342ae46460b7bd6b8/651be/ram-installation.jpg 170w,
/static/e1bacb52da1160f342ae46460b7bd6b8/d30a3/ram-installation.jpg 340w,
/static/e1bacb52da1160f342ae46460b7bd6b8/7bf67/ram-installation.jpg 680w,
/static/e1bacb52da1160f342ae46460b7bd6b8/990cb/ram-installation.jpg 1020w,
/static/e1bacb52da1160f342ae46460b7bd6b8/c44b8/ram-installation.jpg 1360w,
/static/e1bacb52da1160f342ae46460b7bd6b8/d2602/ram-installation.jpg 4032w"
        sizes="(max-width: 680px) 100vw, 680px"
        style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;"
        loading="lazy"
      />
    </span></p>
<div class="image-title">RAM Installation</div>
<h3 id="cooler" style="position:relative;"><a href="#cooler" aria-label="cooler permalink" class="anchor before"><svg class="anchor-icon" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Cooler</h3>
<p><span
      class="gatsby-resp-image-wrapper"
      style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; "
    >
      <span
    class="gatsby-resp-image-background-image"
    style="padding-bottom: 75.29411764705883%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAPABQDASIAAhEBAxEB/8QAFwAAAwEAAAAAAAAAAAAAAAAAAAIEA//EABUBAQEAAAAAAAAAAAAAAAAAAAEA/9oADAMBAAIQAxAAAAGiG9CY2B//xAAZEAADAQEBAAAAAAAAAAAAAAABAgMRBBP/2gAIAQEAAQUCrvpd3U8zkyMdrWZKqoC//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPwE//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPwE//8QAGxAAAwADAQEAAAAAAAAAAAAAAAERAhIhIqH/2gAIAQEABj8C5BTKKHrrN9vhipWhH//EABsQAAICAwEAAAAAAAAAAAAAAAERACExUXFB/9oACAEBAAE/IXA+G48+5XsfyuNmdyahL4BxyCQan//aAAwDAQACAAMAAAAQrB//xAAVEQEBAAAAAAAAAAAAAAAAAAAAIf/aAAgBAwEBPxBH/8QAFhEBAQEAAAAAAAAAAAAAAAAAAAER/9oACAECAQE/EIuv/8QAHBABAQADAQADAAAAAAAAAAAAAREAITFBYXGB/9oACAEBAAE/ED5OCdrvUtyg23e17hJ0KtZjuCcPqncRhCWIJ8k9mCckGvzP/9k='); background-size: cover; display: block;"
  ></span>
  <img
        class="gatsby-resp-image-image"
        alt="Cooler Unboxing"
        title="Cooler Unboxing"
        src="/static/c387652dbd0a362eb8b3c1d9c06a3cae/7bf67/cooler-master-hyper-212-black-unboxing.jpg"
        srcset="/static/c387652dbd0a362eb8b3c1d9c06a3cae/651be/cooler-master-hyper-212-black-unboxing.jpg 170w,
/static/c387652dbd0a362eb8b3c1d9c06a3cae/d30a3/cooler-master-hyper-212-black-unboxing.jpg 340w,
/static/c387652dbd0a362eb8b3c1d9c06a3cae/7bf67/cooler-master-hyper-212-black-unboxing.jpg 680w,
/static/c387652dbd0a362eb8b3c1d9c06a3cae/990cb/cooler-master-hyper-212-black-unboxing.jpg 1020w,
/static/c387652dbd0a362eb8b3c1d9c06a3cae/c44b8/cooler-master-hyper-212-black-unboxing.jpg 1360w,
/static/c387652dbd0a362eb8b3c1d9c06a3cae/d2602/cooler-master-hyper-212-black-unboxing.jpg 4032w"
        sizes="(max-width: 680px) 100vw, 680px"
        style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;"
        loading="lazy"
      />
    </span></p>
<div class="image-title">Cooler Unboxing</div>
<h2 id="software-installation" style="position:relative;"><a href="#software-installation" aria-label="software installation permalink" class="anchor before"><svg class="anchor-icon" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Software Installation</h2>
<h2 id="cuda-setup" style="position:relative;"><a href="#cuda-setup" aria-label="cuda setup permalink" class="anchor before"><svg class="anchor-icon" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>CUDA Setup</h2>
<h2 id="workflow" style="position:relative;"><a href="#workflow" aria-label="workflow permalink" class="anchor before"><svg class="anchor-icon" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Workflow</h2>
<h2 id="summary" style="position:relative;"><a href="#summary" aria-label="summary permalink" class="anchor before"><svg class="anchor-icon" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Summary</h2>
<p><span
      class="gatsby-resp-image-wrapper"
      style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; "
    >
      <span
    class="gatsby-resp-image-background-image"
    style="padding-bottom: 75.29411764705883%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAPABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAAMBBf/EABQBAQAAAAAAAAAAAAAAAAAAAAL/2gAMAwEAAhADEAAAAeNlpJSBP//EABkQAQACAwAAAAAAAAAAAAAAAAEAAhAhMf/aAAgBAQABBQIiYqatyf/EABURAQEAAAAAAAAAAAAAAAAAABBB/9oACAEDAQE/AYf/xAAVEQEBAAAAAAAAAAAAAAAAAAAQEf/aAAgBAgEBPwGH/8QAFxAAAwEAAAAAAAAAAAAAAAAAABBBIf/aAAgBAQAGPwLXCL//xAAaEAADAQADAAAAAAAAAAAAAAAAAREhMUFR/9oACAEBAAE/IZtmQlyPIbUkzvY2k1XsHp//2gAMAwEAAgADAAAAENc//8QAFhEBAQEAAAAAAAAAAAAAAAAAARAR/9oACAEDAQE/EETU/8QAFhEAAwAAAAAAAAAAAAAAAAAAARBR/9oACAECAQE/ELC//8QAGxABAQEAAgMAAAAAAAAAAAAAAREAIVExQWH/2gAIAQEAAT8QsQCkhPGMnIvIOcCeroBihA4R6SdhOucqvwN//9k='); background-size: cover; display: block;"
  ></span>
  <img
        class="gatsby-resp-image-image"
        alt="My Deep Learning Workstation 1.0"
        title="My Deep Learning Workstation 1.0"
        src="/static/83cf2035c7744bdb8ca1e9bde131a68e/7bf67/deep-learning-workstation-final-look.jpg"
        srcset="/static/83cf2035c7744bdb8ca1e9bde131a68e/651be/deep-learning-workstation-final-look.jpg 170w,
/static/83cf2035c7744bdb8ca1e9bde131a68e/d30a3/deep-learning-workstation-final-look.jpg 340w,
/static/83cf2035c7744bdb8ca1e9bde131a68e/7bf67/deep-learning-workstation-final-look.jpg 680w,
/static/83cf2035c7744bdb8ca1e9bde131a68e/990cb/deep-learning-workstation-final-look.jpg 1020w,
/static/83cf2035c7744bdb8ca1e9bde131a68e/c44b8/deep-learning-workstation-final-look.jpg 1360w,
/static/83cf2035c7744bdb8ca1e9bde131a68e/d2602/deep-learning-workstation-final-look.jpg 4032w"
        sizes="(max-width: 680px) 100vw, 680px"
        style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;"
        loading="lazy"
      />
    </span></p>
<div class="image-title">My Deep Learning Workstation 1.0</div>
<h2 id="references" style="position:relative;"><a href="#references" aria-label="references permalink" class="anchor before"><svg class="anchor-icon" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>References</h2>
<ul>
<li><a target="_blank" rel="noopener" href="https://timdettmers.com/2018/12/16/deep-learning-hardware-guide/">A Full Hardware Guide to Deep Learning</a></li>
<li><a target="_blank" rel="noopener" href="https://timdettmers.com/2020/09/07/which-gpu-for-deep-learning/">Which GPU(s) to Get for Deep Learning: My Experience and Advice for Using GPUs in Deep Learning</a></li>
<li><a target="_blank" rel="noopener" href="https://pcpartpicker.com/user/tim_dettmers/saved/#view=mZ2rD3">Deep Learning Barebones on PCPartPicker</a></li>
</ul></div></div></article><div class="social-share-wrapper"><h3>Share Your Love</h3><button aria-label="Share Via Facebook" title="Share Via Facebook" class="react-share__ShareButton social-share-item facebook" style="background-color:transparent;border:none;padding:0;font:inherit;color:inherit;cursor:pointer"><svg aria-hidden="true" focusable="false" data-prefix="fab" data-icon="facebook" class="svg-inline--fa fa-facebook fa-w-16 " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M504 256C504 119 393 8 256 8S8 119 8 256c0 123.78 90.69 226.38 209.25 245V327.69h-63V256h63v-54.64c0-62.15 37-96.48 93.67-96.48 27.14 0 55.52 4.84 55.52 4.84v61h-31.28c-30.8 0-40.41 19.12-40.41 38.73V256h68.78l-11 71.69h-57.78V501C413.31 482.38 504 379.78 504 256z"></path></svg></button><button aria-label="Share Via Twitter" class="react-share__ShareButton social-share-item twitter" style="background-color:transparent;border:none;padding:0;font:inherit;color:inherit;cursor:pointer"><svg aria-hidden="true" focusable="false" data-prefix="fab" data-icon="twitter" class="svg-inline--fa fa-twitter fa-w-16 " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"></path></svg></button><button aria-label="Share Via LinkedIn" class="react-share__ShareButton social-share-item linkedin" style="background-color:transparent;border:none;padding:0;font:inherit;color:inherit;cursor:pointer"><svg aria-hidden="true" focusable="false" data-prefix="fab" data-icon="linkedin-in" class="svg-inline--fa fa-linkedin-in fa-w-14 " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M100.28 448H7.4V148.9h92.88zM53.79 108.1C24.09 108.1 0 83.5 0 53.8a53.79 53.79 0 0 1 107.58 0c0 29.7-24.1 54.3-53.79 54.3zM447.9 448h-92.68V302.4c0-34.7-.7-79.2-48.29-79.2-48.29 0-55.69 37.7-55.69 76.7V448h-92.78V148.9h89.08v40.8h1.3c12.4-23.5 42.69-48.3 87.88-48.3 94 0 111.28 61.9 111.28 142.3V448z"></path></svg></button><button aria-label="Share Via Reddit" class="react-share__ShareButton social-share-item reddit" style="background-color:transparent;border:none;padding:0;font:inherit;color:inherit;cursor:pointer"><svg aria-hidden="true" focusable="false" data-prefix="fab" data-icon="reddit" class="svg-inline--fa fa-reddit fa-w-16 " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M201.5 305.5c-13.8 0-24.9-11.1-24.9-24.6 0-13.8 11.1-24.9 24.9-24.9 13.6 0 24.6 11.1 24.6 24.9 0 13.6-11.1 24.6-24.6 24.6zM504 256c0 137-111 248-248 248S8 393 8 256 119 8 256 8s248 111 248 248zm-132.3-41.2c-9.4 0-17.7 3.9-23.8 10-22.4-15.5-52.6-25.5-86.1-26.6l17.4-78.3 55.4 12.5c0 13.6 11.1 24.6 24.6 24.6 13.8 0 24.9-11.3 24.9-24.9s-11.1-24.9-24.9-24.9c-9.7 0-18 5.8-22.1 13.8l-61.2-13.6c-3-.8-6.1 1.4-6.9 4.4l-19.1 86.4c-33.2 1.4-63.1 11.3-85.5 26.8-6.1-6.4-14.7-10.2-24.1-10.2-34.9 0-46.3 46.9-14.4 62.8-1.1 5-1.7 10.2-1.7 15.5 0 52.6 59.2 95.2 132 95.2 73.1 0 132.3-42.6 132.3-95.2 0-5.3-.6-10.8-1.9-15.8 31.3-16 19.8-62.5-14.9-62.5zM302.8 331c-18.2 18.2-76.1 17.9-93.6 0-2.2-2.2-6.1-2.2-8.3 0-2.5 2.5-2.5 6.4 0 8.6 22.8 22.8 87.3 22.8 110.2 0 2.5-2.2 2.5-6.1 0-8.6-2.2-2.2-6.1-2.2-8.3 0zm7.7-75c-13.6 0-24.6 11.1-24.6 24.9 0 13.6 11.1 24.6 24.6 24.6 13.8 0 24.9-11.1 24.9-24.6 0-13.8-11-24.9-24.9-24.9z"></path></svg></button><button aria-label="Add to Pocket" class="react-share__ShareButton social-share-item pocket" style="background-color:transparent;border:none;padding:0;font:inherit;color:inherit;cursor:pointer"><svg aria-hidden="true" focusable="false" data-prefix="fab" data-icon="get-pocket" class="svg-inline--fa fa-get-pocket fa-w-14 " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M407.6 64h-367C18.5 64 0 82.5 0 104.6v135.2C0 364.5 99.7 464 224.2 464c124 0 223.8-99.5 223.8-224.2V104.6c0-22.4-17.7-40.6-40.4-40.6zm-162 268.5c-12.4 11.8-31.4 11.1-42.4 0C89.5 223.6 88.3 227.4 88.3 209.3c0-16.9 13.8-30.7 30.7-30.7 17 0 16.1 3.8 105.2 89.3 90.6-86.9 88.6-89.3 105.5-89.3 16.9 0 30.7 13.8 30.7 30.7 0 17.8-2.9 15.7-114.8 123.2z"></path></svg></button></div><div class="comment-box"></div></main><aside class="blogpost-sidebar"><div class="blog-navigation-wrapper"><h3>Read Other Posts</h3><nav class="blog-navigation"><div class="nav-links"><a rel="next" class="next-post" href="/blog/heapify/">Heapify âœŒï¸<!-- --> â†’</a><a class="all-posts" href="/blog">All Posts</a></div></nav></div></aside><footer><div class="footer-wrapper"><div class="social"><ul class="social-list"><li class="social-item social-twitter"><a href="https://twitter.com/roma_glushko" title="Roman Glushko on Twitter" target="blank"><svg aria-hidden="true" focusable="false" data-prefix="fab" data-icon="twitter" class="svg-inline--fa fa-twitter fa-w-16 fa-2x " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"></path></svg></a></li><li class="social-item social-github"><a href="https://github.com/roma-glushko" title="Roman Glushko on Github" target="blank"><svg aria-hidden="true" focusable="false" data-prefix="fab" data-icon="github-alt" class="svg-inline--fa fa-github-alt fa-w-15 fa-2x " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 480 512"><path fill="currentColor" d="M186.1 328.7c0 20.9-10.9 55.1-36.7 55.1s-36.7-34.2-36.7-55.1 10.9-55.1 36.7-55.1 36.7 34.2 36.7 55.1zM480 278.2c0 31.9-3.2 65.7-17.5 95-37.9 76.6-142.1 74.8-216.7 74.8-75.8 0-186.2 2.7-225.6-74.8-14.6-29-20.2-63.1-20.2-95 0-41.9 13.9-81.5 41.5-113.6-5.2-15.8-7.7-32.4-7.7-48.8 0-21.5 4.9-32.3 14.6-51.8 45.3 0 74.3 9 108.8 36 29-6.9 58.8-10 88.7-10 27 0 54.2 2.9 80.4 9.2 34-26.7 63-35.2 107.8-35.2 9.8 19.5 14.6 30.3 14.6 51.8 0 16.4-2.6 32.7-7.7 48.2 27.5 32.4 39 72.3 39 114.2zm-64.3 50.5c0-43.9-26.7-82.6-73.5-82.6-18.9 0-37 3.4-56 6-14.9 2.3-29.8 3.2-45.1 3.2-15.2 0-30.1-.9-45.1-3.2-18.7-2.6-37-6-56-6-46.8 0-73.5 38.7-73.5 82.6 0 87.8 80.4 101.3 150.4 101.3h48.2c70.3 0 150.6-13.4 150.6-101.3zm-82.6-55.1c-25.8 0-36.7 34.2-36.7 55.1s10.9 55.1 36.7 55.1 36.7-34.2 36.7-55.1-10.9-55.1-36.7-55.1z"></path></svg></a></li><li class="social-item social-linkedin"><a href="https://www.linkedin.com/in/glushko-roman" title="Roman Glushko on LinkedIn" target="blank"><svg aria-hidden="true" focusable="false" data-prefix="fab" data-icon="linkedin-in" class="svg-inline--fa fa-linkedin-in fa-w-14 fa-2x " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M100.28 448H7.4V148.9h92.88zM53.79 108.1C24.09 108.1 0 83.5 0 53.8a53.79 53.79 0 0 1 107.58 0c0 29.7-24.1 54.3-53.79 54.3zM447.9 448h-92.68V302.4c0-34.7-.7-79.2-48.29-79.2-48.29 0-55.69 37.7-55.69 76.7V448h-92.78V148.9h89.08v40.8h1.3c12.4-23.5 42.69-48.3 87.88-48.3 94 0 111.28 61.9 111.28 142.3V448z"></path></svg></a></li><li class="social-item social-email"><a href="mailto:roman.glushko.m@gmail.com" title="Roman Glushko&#x27;s Email"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="envelope" class="svg-inline--fa fa-envelope fa-w-16 fa-2x " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"></path></svg></a></li><li class="social-item social-kaggle"><a href="https://www.kaggle.com/glushko" title="Roman Glushko on Kaggle" target="blank"><svg aria-hidden="true" focusable="false" data-prefix="fab" data-icon="kaggle" class="svg-inline--fa fa-kaggle fa-w-10 fa-2x " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><path fill="currentColor" d="M304.2 501.5L158.4 320.3 298.2 185c2.6-2.7 1.7-10.5-5.3-10.5h-69.2c-3.5 0-7 1.8-10.5 5.3L80.9 313.5V7.5q0-7.5-7.5-7.5H21.5Q14 0 14 7.5v497q0 7.5 7.5 7.5h51.9q7.5 0 7.5-7.5v-109l30.8-29.3 110.5 140.6c3 3.5 6.5 5.3 10.5 5.3h66.9q5.25 0 6-3z"></path></svg></a></li></ul></div><div class="copyright">Roman Glushko Â© 1996 - <!-- -->2021</div></div></footer><div class="mathjax"></div></div></div><div id="gatsby-announcer" style="position:absolute;top:0;width:1px;height:1px;padding:0;overflow:hidden;clip:rect(0, 0, 0, 0);white-space:nowrap;border:0" aria-live="assertive" aria-atomic="true"></div></div><script>
  
  function gaOptout(){document.cookie=disableStr+'=true; expires=Thu, 31 Dec 2099 23:59:59 UTC;path=/',window[disableStr]=!0}var gaProperty='UA-148139633-1',disableStr='ga-disable-'+gaProperty;document.cookie.indexOf(disableStr+'=true')>-1&&(window[disableStr]=!0);
  if(!(parseInt(navigator.doNotTrack) === 1 || parseInt(window.doNotTrack) === 1 || parseInt(navigator.msDoNotTrack) === 1 || navigator.doNotTrack === "yes")) {
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  }
  if (typeof ga === "function") {
    ga('create', 'UA-148139633-1', 'auto', {});
      ga('set', 'anonymizeIp', true);
      
      
      
      
      }</script><script id="gatsby-script-loader">/*<![CDATA[*/window.pagePath="/blog/how-i-built-my-ml-workstation/";/*]]>*/</script><script id="gatsby-chunk-mapping">/*<![CDATA[*/window.___chunkMapping={"app":["/app-e39ef23d44e95f2a8c12.js"],"component---cache-caches-gatsby-plugin-offline-app-shell-js":["/component---cache-caches-gatsby-plugin-offline-app-shell-js-f94ad01b5542d484ff45.js"],"component---src-pages-404-js":["/component---src-pages-404-js-5d2317f3b3c9361fdfb5.js"],"component---src-pages-blog-js":["/component---src-pages-blog-js-4fddce6f89c4c4b42e93.js"],"component---src-pages-index-js":["/component---src-pages-index-js-65d32d5205b7961d46b0.js"],"component---src-pages-lab-js":["/component---src-pages-lab-js-1016e3994c62376cf425.js"],"component---src-pages-lab-rockpaperscissor-index-js":["/component---src-pages-lab-rockpaperscissor-index-js-67b65b8b031d783329ec.js"],"component---src-pages-nn-design-js":["/component---src-pages-nn-design-js-4a8bceb15a0b90a1e975.js"],"component---src-pages-thoughts-js":["/component---src-pages-thoughts-js-338836d083d27d102d1f.js"],"component---src-templates-blog-template-js":["/component---src-templates-blog-template-js-038bf2396ef654b3f050.js"],"component---src-templates-thought-template-js":["/component---src-templates-thought-template-js-2a7c4125ec528520e09e.js"]};/*]]>*/</script><script src="/component---src-templates-blog-template-js-038bf2396ef654b3f050.js" async=""></script><script src="/4622c33586ad0108e870f951288ae6aa3beabfab-45b8a591d79b385bde09.js" async=""></script><script src="/bc2c5684014d51ee40621353fd54f57d7b8b3bb5-73ee4f5bc1b65ee475c2.js" async=""></script><script src="/059c0ea648e8bc79d52034ba1cf1bfc380f9444d-a4fc9b8066b0203e6078.js" async=""></script><script src="/a510f34a924899f38f7aa0d53277b2c9f4857ad7-297391715d2e12113f02.js" async=""></script><script src="/a9a7754c-52ee971a981a422e7452.js" async=""></script><script src="/cb1608f2-6457b2b7ea9500c04ebb.js" async=""></script><script src="/styles-8636a280cbc61d53ad10.js" async=""></script><script src="/app-e39ef23d44e95f2a8c12.js" async=""></script><script src="/framework-984c7a17186e83dc1ff4.js" async=""></script><script src="/webpack-runtime-ffe28ca2ddebee3dccf4.js" async=""></script></body></html>