<!DOCTYPE html><html lang="en" class="blogpost-view-page"><head><meta charSet="utf-8"/><meta http-equiv="x-ua-compatible" content="ie=edge"/><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/><link rel="stylesheet" href="/styles.f71cb3284614804b3c73.css"/><title data-react-helmet="true">Design LRU Cache - Blog by Roman Glushko</title><meta data-react-helmet="true" name="image" property="og:image" content="https://www.romaglushko.com/static/7a2b18b535412ccd4663e743ae4093de/35aef/kelly-sikkema-v9FQR4tbIq8-unsplash.jpg"/><meta data-react-helmet="true" name="description" property="og:description" content="Have fun designing least-recently-used cache in Python"/><meta data-react-helmet="true" name="keywords" content="algorithmic coding,data structures,python"/><meta data-react-helmet="true" name="author" content="@roma_glushko"/><meta data-react-helmet="true" property="og:title" content="Design LRU Cache - Blog"/><meta data-react-helmet="true" property="og:type" content="article"/><meta data-react-helmet="true" name="twitter:card" content="summary"/><meta data-react-helmet="true" name="twitter:creator" content="@roma_glushko"/><meta data-react-helmet="true" name="twitter:title" content="Design LRU Cache - Blog"/><meta data-react-helmet="true" name="twitter:description" content="Have fun designing least-recently-used cache in Python"/><meta data-react-helmet="true" property="og:url" content="https://www.romaglushko.com/blog/design-lru-cache/"/><script data-react-helmet="true" type="application/ld+json">{"@context":"http://schema.org","@type":"BlogPosting","image":"/static/7a2b18b535412ccd4663e743ae4093de/35aef/kelly-sikkema-v9FQR4tbIq8-unsplash.jpg","headline":"Design LRU Cache","dateCreated":"2021-06-16","datePublished":"2021-06-16","dateModified":"2021-06-16","inLanguage":"en-US","isFamilyFriendly":"true","author":{"@type":"Person","name":"Roman Glushko"},"publisher":{"@type":"Organization","name":"Roman Glushko's Website"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://www.romaglushko.com/blog/design-lru-cache/"},"keywords":["algorithmic coding","data structures","python"],"genre":["machine learning","software engineering","science","deep learning","statistics"],"articleSection":"Technical Blog","articleBody":"\n\nWhile preparing for coding interviews, I went through a large number of algorithmic challenges. I found particularly interesting one subset of problems - challenges related to designing some tools that we all use and rarely stop and think about how they work.\n\nIn this article, we are going to take a look at the Least Recently Used (LRU) cache.\n\n**Least Recently Used Cache** is a key-value storage that has some capacity and a specific key eviction policy. Whenever it's specified in Gb, percentage of RAM or number of keys, the cache capacity is useful to prevent the storage from overflowing the available memory resources and shutting down unexpectedly.\n\nBut what can we do when we are about to reach our capacity limits?\n\nThis is where eviction is helpful. In the case of LRU policy, we can just **remove key-values that were not accessed for the longest time** a.k.a least-recently-used items. This is a pretty natural things to do and it's commonly used in such popular key-value storages as Redis.\n\nAnother part to pay attention to is cache. **Cache** is a kind of storage that is usually **optimized for reading and retrieving information** that would be time- or resource-consuming to calculate or collect without the cache.\n\n## Problem Framing\n\nNow we have a broad context around LRU cache use cases and we are ready to formulate the challenge.\n\nWe want to design a **class that represents LRU cache and has the following APIs**:\n\n- `LRUCache(capacity: int)` class should be initialized with a capacity of the storage where the capacity is simply a number of keys that storage can hold.\n- `get(key: int)` method which can retrieve the value by key in constant time (O(1)).\n- `put(key: int, value: int)` method which stores key-value pair in the cache in constant time (O(1)). If a key is already in the storage, we need to replace its value with a new one. `put()` method should be constrained by capacity value and should not exceed it. When capacity restriction is about to be reached, we need to evict the least-recently-used item to put a new key-value pair to the storage.\n\nSince we are trying to design a cache storage, pretty much every operation should be done in **constant time execution on average** to keep it practically useful. This means that key eviction should also happen in O(1) complexity range.\n\n## Brainstorm Solutions\n\nWhen I think about cache, **dictionaries or hashtables** come to my mind.\n\n![Cache based on a hashtable](./img/cache-based-on-hashtable.svg \"Cache based on a hashtable\")\n<div class=\"image-title\">Cache based on a hashtable</div>\n\nHashtables allow to **read and write key-value pairs in constant time with high probability**. \n\nThe problem with dictionaries is that they usually don't guarantee order in which they manage keys. So we don't have a way to quickly remove least-recently-used items. We could introduce a notion of last-used timestamps for each item in the hashtable and update these timestamps during accessing the keys in `get()` method.\n\n\n![Timestamps won't help us because of sequential search we need to do on the hashtable](./img/cache-based-on-hashtable-with-timestamps.svg \"Cache as a hashtable\")\n<div class=\"image-title\">Timestamps won't help us because of sequential search we need to do on the hashtable</div>\n\nHowever, it would still **take us O(n) in order to find items to evict** by timestamps. It's too time-consuming to meet our requirements.\n\nLet's not get hung up on hashtables. The problem with tracking item usage can be solved with **linked lists**.\n\n![Cache based a linked list](./img/cache-based-on-linked-list.svg \"Cache based a linked list\")\n<div class=\"image-title\">Cache based a linked list</div>\n\nWith linked lists, we could **keep track of item usages in constant time**. We could simply move the item we currently access to the top of the list. In a natural way, **least used items end up being at the very bottom of the list** and we would get a list ordered by item usage as we go. Since we need to relink our items, it would be helpful to have reference to the previous and next items on the list.\n\nNevertheless, linked lists don't meet our requirements completely. It would **take us O(n) in order to find and retrieve item by key**. This is a sad complexity for cache storages.\n\nTo sum up, hashtables luck the advantages of linked lists and linked lists luck advantages of hashtables. We find to **find a way to combine hashtables and linked lists** such that we meet our LRU cache requirements.\n\n## Design Solution\n\nAfter a little bit of thinking, it may click that we can **map our keys not to the values directly, but to the linked list nodes** that represent these values. Mapping keys to list nodes means that the **dictionary will hold node references** that don't depend on node positions in the list itself. So we would be able to **rearrange list items without a need to remap** them in the dictionary.\n\n![LRU Cache Architecture](./img/lru-cache-architecture.svg \"LRU Cache Architecture\")\n<div class=\"image-title\">LRU cache architecture based on combination of hashtable and linked list</div>\n\n\n## Implement Solution\n\nLet's start our implementation from create APIs which we want to see in the linked list:\n\n```python\nfrom typing import Dict, Optional\n\n\nclass Node:\n    \"\"\"\n    Linked List Node. Contains key-value pair and links to neighbor elements.\n    \"\"\"\n    def __init__(self, key: int, value: int, prev=None, next=None):\n        self.key: int = key\n        self.value: int = value\n\n        self.prev: Optional[Node] = prev\n        self.next: Optional[Node] = next\n\n\nclass LinkedList:\n    \"\"\"\n    Linked List. Represents usage history of cache items\n    \"\"\"\n    head: Optional[Node] = None\n    tail: Optional[Node] = None\n\n    def add_to_head(self, item: Node) -> None:\n        \"\"\"\n        Add node to the very top of the list\n        \"\"\"\n        if self.head is not None:\n            item.next = self.head\n            self.head.prev = item\n\n        if self.tail is None:\n            self.tail = item\n\n        self.head = item\n\n    def unlink(self, item: Node) -> None:\n        \"\"\"\n        Remove references to the node from other nodes on the list\n        \"\"\"\n        if item is None:\n            return\n\n        prev_item: Node = item.prev\n        next_item: Node = item.next\n\n        # unlink the item node:\n        # link prev and next items\n        # removing referenced to the current item node\n        if prev_item is not None:\n            prev_item.next = next_item\n\n        if next_item is not None:\n            next_item.prev = prev_item\n\n        if self.head == item:\n            # item was the first element in the list\n            self.head = next_item\n\n        if self.tail == item:\n            # item was the last element in the list\n            self.tail = prev_item\n\n        # make sure that the item itself doesn't have references to other nodes\n        item.prev = None\n        item.next = None\n```\n\nAll node manipulations (e.g. `add_to_head()`, `unlink()` methods) operates in constant time and doesn't depend on the size of the linked list.\n\nHaving a linked list implemented, we can actually code the idea of LRU architecture we came up with:\n\n```python\nclass LRUCache:\n    \"\"\"\n    Implementation of cache storage with LRU eviction policy\n    \"\"\"\n    capacity: int\n    cache_map: Dict[int, Node]\n    history: LinkedList\n\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.cache_map = {}\n        self.history = LinkedList()\n\n    def get(self, key: int) -> int:\n        \"\"\"\n        Retrieve value by its key or -1 otherwise\n        \"\"\"\n        if key not in self.cache_map:\n            return -1\n\n        value_node: Node = self.cache_map[key]\n\n        if self.history.head != value_node:\n            # make item the most recently used\n            self.history.unlink(value_node)\n            self.history.add_to_head(value_node)\n\n        return value_node.value\n\n    def put(self, key: int, value: int) -> None:\n        \"\"\"\n        Add a new key-value pair to the cache.\n        If key exists, replace its value by a new one.\n        If capacity is reached, evict the LRU item and insert a new pair\n        \"\"\"\n        value_node: Node = Node(key, value)\n\n        if key in self.cache_map:\n            self.remove_item(self.cache_map[key])\n\n        if len(self.cache_map) >= self.capacity:\n            # no space left, needs to evict the least recently used item\n            self.evict_least_recent_item()\n\n        self.history.add_to_head(value_node)\n        self.cache_map[key] = value_node\n\n    def evict_least_recent_item(self) -> None:\n        \"\"\"\n        Evict the least recently used item\n        \"\"\"\n        lru_item: Node = self.history.tail\n\n        if lru_item is None:\n            return\n\n        self.remove_item(lru_item)\n\n    def remove_item(self, item: Node) -> None:\n        \"\"\"\n        Remove item represented by node from the map and the list\n        \"\"\"\n        self.history.unlink(item)\n\n        del self.cache_map[item.key]\n        del item\n\n```\n\nThe `get()` and `put()` methods only rely on methods that run in constant time, so our implementation has **constant running time on average**. Just like we have required earlier. In order to get here, we consume `O(2N)` memory to build a map and a linked list.\n\nThis solution is common and can be implemented in any general purpose language. Specifically speaking about Python, it provides `OrderedDict` data structure that helps to implement LRU cache in a much **more concise way**. Let's take a look:\n\n```python\nfrom collections import OrderedDict\n\n\nclass LRUCache:\n    \"\"\"\n    This is alternative implementation of LRU cache based on OrderedDict\n    \"\"\"\n    capacity: int\n    cache_map: OrderedDict\n\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.cache_map = OrderedDict()\n\n    def get(self, key: int) -> int:\n        if key not in self.cache_map:\n            return -1\n\n        value = self.cache_map[key]\n        self.cache_map.move_to_end(key)\n\n        return value\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.cache_map:\n            self.cache_map[key] = value\n            self.cache_map.move_to_end(key)\n            return\n\n        if len(self.cache_map) >= self.capacity:\n            lru_key = next(iter(self.cache_map))\n            del self.cache_map[lru_key]\n\n        self.cache_map[key] = value\n```\n\nOrderedDict seems to be introduced specifically to implement [LRU cache](https://docs.python.org/3/library/collections.html#ordereddict-examples-and-recipes). We may expect that under the hood it has been implemented in a similar way to what we came up with since the runtime and memory usage are pretty the same for both versions.\n\n## Summary\n\nWe went through designing and implementing our own LRU cache. We combined the advantages of hashtables and linked list and built efficient cache storage on top of them.\n\nBesides being an interesting task, the problem is a common question in the coding interviews. So if you are preparing right now, feel free to implement LRU cache yourself on Leetcode.\n\n## References\n\n- <a target=\"_blank\" rel=\"noopener\" href=\"https://github.com/roma-glushko/leetcode-solutions/blob/master/src/design/lru_cache.py\">Implementation on GitHub</a>\n- <a target=\"_blank\" rel=\"noopener\" href=\"https://leetcode.com/problems/lru-cache/\">[LeetCode] 146. LRU Cache</a>\n- <a target=\"_blank\" rel=\"noopener\" href=\"https://www.amazon.com/Cracking-Coding-Interview-Programming-Questions/dp/0984782850\">Cracking the Coding Interview book by Gayle MacDowell</a>","wordcount":1010}</script><script data-react-helmet="true" type="application/ld+json">{"@context":"http://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Home","item":"https://www.romaglushko.com/"},{"@type":"ListItem","position":2,"name":"Blog","item":"https://www.romaglushko.com/blog/"},{"@type":"ListItem","position":3,"name":"Design LRU Cache","item":"https://www.romaglushko.com/blog/design-lru-cache/"}]}</script><link crossorigin="" href="https://utteranc.es" rel="preconnect"/><link crossorigin="" href="https://www.google-analytics.com" rel="preconnect"/><link rel="icon" href="/favicon-32x32.png?v=58a31253e5b93c1d7e74e8a017ff47b3"/><link rel="manifest" href="/manifest.webmanifest"/><meta name="theme-color" content="#ffffff"/><link rel="apple-touch-icon" sizes="48x48" href="/icons/icon-48x48.png?v=58a31253e5b93c1d7e74e8a017ff47b3"/><link rel="apple-touch-icon" sizes="72x72" href="/icons/icon-72x72.png?v=58a31253e5b93c1d7e74e8a017ff47b3"/><link rel="apple-touch-icon" sizes="96x96" href="/icons/icon-96x96.png?v=58a31253e5b93c1d7e74e8a017ff47b3"/><link rel="apple-touch-icon" sizes="144x144" href="/icons/icon-144x144.png?v=58a31253e5b93c1d7e74e8a017ff47b3"/><link rel="apple-touch-icon" sizes="192x192" href="/icons/icon-192x192.png?v=58a31253e5b93c1d7e74e8a017ff47b3"/><link rel="apple-touch-icon" sizes="256x256" href="/icons/icon-256x256.png?v=58a31253e5b93c1d7e74e8a017ff47b3"/><link rel="apple-touch-icon" sizes="384x384" href="/icons/icon-384x384.png?v=58a31253e5b93c1d7e74e8a017ff47b3"/><link rel="apple-touch-icon" sizes="512x512" href="/icons/icon-512x512.png?v=58a31253e5b93c1d7e74e8a017ff47b3"/><link rel="preload" as="font" type="font/woff2" crossorigin="anonymous" href="/static/webfonts/s/dancingscript/v16/If2cXTr6YS-zF4S-kcSWSVi_sxjsohD9F50Ruu7BMSo3Sup8.woff2"/><link rel="preload" as="font" type="font/woff2" crossorigin="anonymous" href="/static/webfonts/s/dancingscript/v16/If2cXTr6YS-zF4S-kcSWSVi_sxjsohD9F50Ruu7B1i03Sup8.woff2"/><link rel="preload" as="font" type="font/woff2" crossorigin="anonymous" href="/static/webfonts/s/ledger/v11/j8_q6-HK1L3if_sBnMrx.woff2"/><style>@font-face{font-family:Dancing Script;font-style:normal;font-weight:400;font-display:swap;src:url(/static/webfonts/s/dancingscript/v16/If2cXTr6YS-zF4S-kcSWSVi_sxjsohD9F50Ruu7BMSo3Sup8.woff2) format("woff2")}@font-face{font-family:Dancing Script;font-style:normal;font-weight:700;font-display:swap;src:url(/static/webfonts/s/dancingscript/v16/If2cXTr6YS-zF4S-kcSWSVi_sxjsohD9F50Ruu7B1i03Sup8.woff2) format("woff2")}@font-face{font-family:Dancing Script;font-style:normal;font-weight:400;font-display:swap;src:url(/static/webfonts/s/dancingscript/v16/If2cXTr6YS-zF4S-kcSWSVi_sxjsohD9F50Ruu7BMSo3Sup6.woff) format("woff")}@font-face{font-family:Dancing Script;font-style:normal;font-weight:700;font-display:swap;src:url(/static/webfonts/s/dancingscript/v16/If2cXTr6YS-zF4S-kcSWSVi_sxjsohD9F50Ruu7B1i03Sup6.woff) format("woff")}@font-face{font-family:Ledger;font-style:normal;font-weight:400;font-display:swap;src:url(/static/webfonts/s/ledger/v11/j8_q6-HK1L3if_sBnMrx.woff2) format("woff2")}@font-face{font-family:Ledger;font-style:normal;font-weight:400;font-display:swap;src:url(/static/webfonts/s/ledger/v11/j8_q6-HK1L3if_sBnMr3.woff) format("woff")}</style><link rel="preconnect dns-prefetch" href="https://www.google-analytics.com"/><link rel="stylesheet"/><script>
    document.addEventListener("DOMContentLoaded", function(event) {
      var hash = window.decodeURI(location.hash.replace('#', ''))
      if (hash !== '') {
        var element = document.getElementById(hash)
        if (element) {
          var scrollTop = window.pageYOffset || document.documentElement.scrollTop || document.body.scrollTop
          var clientTop = document.documentElement.clientTop || document.body.clientTop || 0
          var offset = element.getBoundingClientRect().top + scrollTop - clientTop
          // Wait for the browser to finish rendering before scrolling.
          setTimeout((function() {
            window.scrollTo(0, offset - 0)
          }), 0)
        }
      }
    })
  </script><link rel="canonical" href="https://www.romaglushko.com/blog/design-lru-cache/" data-baseprotocol="https:" data-basehost="www.romaglushko.com"/><link rel="sitemap" type="application/xml" href="/sitemap.xml"/><link as="script" rel="preload" href="/webpack-runtime-e5fcbe9a63e5500432cd.js"/><link as="script" rel="preload" href="/framework-68e90182ffbbad46751e.js"/><link as="script" rel="preload" href="/app-de8843e408d337e1ffde.js"/><link as="script" rel="preload" href="/styles-8636a280cbc61d53ad10.js"/><link as="script" rel="preload" href="/02e3c991cb460df38a850baf561b952fff7f05a7-120d26a5ba92bd694f64.js"/><link as="script" rel="preload" href="/7fec078d47fb9647f833e2e6379c6e0182872dcf-593e4006fd0d611c716c.js"/><link as="script" rel="preload" href="/b1d143cac6741dab3b540359698892a994dd2b72-5c00bc2a1de84a36b201.js"/><link as="script" rel="preload" href="/418ffc66a997cc995fb5d56035c003ac177781e9-36f98251fe0a8b5a1e7e.js"/><link as="script" rel="preload" href="/4622c33586ad0108e870f951288ae6aa3beabfab-02f3c1a86851f16b2a8d.js"/><link as="script" rel="preload" href="/component---src-templates-blog-template-js-8c20b9928e4e055258bf.js"/><link as="fetch" rel="preload" href="/page-data/blog/design-lru-cache/page-data.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/app-data.json" crossorigin="anonymous"/></head><body><script>
void function() {
  window.__onThemeChange = function() {}

  var preferredTheme
  try {
    preferredTheme = localStorage.getItem('theme')
  } catch (err) { }

  function setTheme(newTheme) {
    if (preferredTheme && document.body.classList.contains(preferredTheme)) {
      document.body.classList.replace(preferredTheme, newTheme)
    } else {
      document.body.classList.add(newTheme)
    }

    window.__theme = newTheme
    preferredTheme = newTheme
    window.__onThemeChange(newTheme)
  }

  window.__setPreferredTheme = function(newTheme) {
    setTheme(newTheme)
    try {
      localStorage.setItem('theme', newTheme)
    } catch (err) {}
  }

  var darkQuery = window.matchMedia('(prefers-color-scheme: dark)')
  darkQuery.addListener(function(e) {
    window.__setPreferredTheme(e.matches ? 'dark' : 'light')
  })

  setTheme(preferredTheme || (darkQuery.matches ? 'dark' : 'light'))
}()
    </script><div id="___gatsby"><div style="outline:none" tabindex="-1" id="gatsby-focus-wrapper"><div><div class="blogpost-header"><div class="view-page-header"><div class="view-page-header-wrapper"><div class="logo-wrapper"><div class="logo"><div class="logo-img gatsby-image-wrapper" style="position:relative;overflow:hidden"><div aria-hidden="true" style="width:100%;padding-bottom:100%"></div><img aria-hidden="true" src="data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAUABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAAEEBf/EABYBAQEBAAAAAAAAAAAAAAAAAAIBBP/aAAwDAQACEAMQAAABtmSLU1KeLAa+iHm//8QAHBABAAICAwEAAAAAAAAAAAAAAQACAxIEISNB/9oACAEBAAEFAkuCLNbTNl1lczWHZd9vnHfL/8QAGBEAAwEBAAAAAAAAAAAAAAAAAAECMRD/2gAIAQMBAT8BS5OFaf/EABYRAAMAAAAAAAAAAAAAAAAAAAABEP/aAAgBAgEBPwGo/8QAGRAAAgMBAAAAAAAAAAAAAAAAAAEQESES/9oACAEBAAY/ArMuOU9NLQxx/8QAHBABAAICAwEAAAAAAAAAAAAAAQARIVExYXGR/9oACAEBAAE/IXCVlFftHewg5k+Rq7IcxhphiNu2Lii09n//2gAMAwEAAgADAAAAEKAPfP/EABoRAAICAwAAAAAAAAAAAAAAAAABETEhQfD/2gAIAQMBAT8Qa0OVgt7Ref/EABcRAQEBAQAAAAAAAAAAAAAAAAAxARH/2gAIAQIBAT8Q2uNqH//EAB4QAQACAgEFAAAAAAAAAAAAAAEAESExUUFhcYGh/9oACAEBAAE/EKIFxuEXF2cBIp2+ZREzlLBC1DYAUnrr3irELKYzK1D7GCYEbhQw0tz/2Q==" alt="" style="position:absolute;top:0;left:0;width:100%;height:100%;object-fit:cover;object-position:center;opacity:1;transition-delay:500ms"/><noscript><picture><source srcset="/static/7d8b62b999b9a2fb28b8ab360138da37/b13df/photo3.jpg 40w,
/static/7d8b62b999b9a2fb28b8ab360138da37/4e333/photo3.jpg 80w,
/static/7d8b62b999b9a2fb28b8ab360138da37/e75b5/photo3.jpg 160w,
/static/7d8b62b999b9a2fb28b8ab360138da37/40426/photo3.jpg 240w,
/static/7d8b62b999b9a2fb28b8ab360138da37/c01e2/photo3.jpg 320w,
/static/7d8b62b999b9a2fb28b8ab360138da37/b1563/photo3.jpg 3677w" sizes="(max-width: 160px) 100vw, 160px" /><img loading="lazy" sizes="(max-width: 160px) 100vw, 160px" srcset="/static/7d8b62b999b9a2fb28b8ab360138da37/b13df/photo3.jpg 40w,
/static/7d8b62b999b9a2fb28b8ab360138da37/4e333/photo3.jpg 80w,
/static/7d8b62b999b9a2fb28b8ab360138da37/e75b5/photo3.jpg 160w,
/static/7d8b62b999b9a2fb28b8ab360138da37/40426/photo3.jpg 240w,
/static/7d8b62b999b9a2fb28b8ab360138da37/c01e2/photo3.jpg 320w,
/static/7d8b62b999b9a2fb28b8ab360138da37/b1563/photo3.jpg 3677w" src="/static/7d8b62b999b9a2fb28b8ab360138da37/e75b5/photo3.jpg" alt="" style="position:absolute;top:0;left:0;opacity:1;width:100%;height:100%;object-fit:cover;object-position:center"/></picture></noscript></div></div><div class="name"><a href="/blog/" title="back to blog">Roman <br/> Glushko</a></div></div><h2 class="blog-title"><a href="/blog/" title="back to the homepage">Blog</a></h2></div></div><nav class="main-navigation"><ul><li><a rel="home" title="Go Home" href="/">Home</a></li><li><a title="Go to Technical blog" href="/blog/">Blog</a></li><li><a title="Go to Thoughts" href="/thoughts/">Thoughts</a></li><li><a title="Review My CVs" href="/cv/machine-learning-engineer/">CV</a></li></ul></nav></div><main><article class="blog-wrapper"><header><figure class="cover"><div class="cover-filter"><div class="cover-image gatsby-image-wrapper" style="position:relative;overflow:hidden"><div aria-hidden="true" style="width:100%;padding-bottom:66.70588235294117%"></div><img aria-hidden="true" src="data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAANABQDASIAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAAAAIE/8QAFQEBAQAAAAAAAAAAAAAAAAAAAQL/2gAMAwEAAhADEAAAAaxMwwgz/8QAGhAAAgMBAQAAAAAAAAAAAAAAAgMAAREEEv/aAAgBAQABBQKufzGL0shONZtcTLn/xAAWEQEBAQAAAAAAAAAAAAAAAAABEFH/2gAIAQMBAT8BHZ//xAAVEQEBAAAAAAAAAAAAAAAAAAAQEf/aAAgBAgEBPwGH/8QAGhAAAgMBAQAAAAAAAAAAAAAAAAERMVEQIf/aAAgBAQAGPwJtu8IllnlYZz//xAAaEAADAQEBAQAAAAAAAAAAAAAAARExIUFh/9oACAEBAAE/IWaEO6wthKbXgeL+mwsVzkRiP//aAAwDAQACAAMAAAAQoy//xAAWEQEBAQAAAAAAAAAAAAAAAAABABH/2gAIAQMBAT8Q1iC3/8QAFhEBAQEAAAAAAAAAAAAAAAAAAQBR/9oACAECAQE/EHELf//EAB0QAQACAgIDAAAAAAAAAAAAAAEAESExQdFRgZH/2gAIAQEAAT8QxmvdaHcMXASWB4IoGysDmOtqeUuvUpMV0e/rzBQLvE//2Q==" alt="" style="position:absolute;top:0;left:0;width:100%;height:100%;object-fit:cover;object-position:center;opacity:1;transition-delay:500ms"/><noscript><picture><source srcset="/static/7a2b18b535412ccd4663e743ae4093de/809fc/kelly-sikkema-v9FQR4tbIq8-unsplash.jpg 850w,
/static/7a2b18b535412ccd4663e743ae4093de/4f4f6/kelly-sikkema-v9FQR4tbIq8-unsplash.jpg 1700w,
/static/7a2b18b535412ccd4663e743ae4093de/35aef/kelly-sikkema-v9FQR4tbIq8-unsplash.jpg 3400w,
/static/7a2b18b535412ccd4663e743ae4093de/9a201/kelly-sikkema-v9FQR4tbIq8-unsplash.jpg 5100w,
/static/7a2b18b535412ccd4663e743ae4093de/d6b2d/kelly-sikkema-v9FQR4tbIq8-unsplash.jpg 5568w" sizes="(max-width: 3400px) 100vw, 3400px" /><img loading="lazy" sizes="(max-width: 3400px) 100vw, 3400px" srcset="/static/7a2b18b535412ccd4663e743ae4093de/809fc/kelly-sikkema-v9FQR4tbIq8-unsplash.jpg 850w,
/static/7a2b18b535412ccd4663e743ae4093de/4f4f6/kelly-sikkema-v9FQR4tbIq8-unsplash.jpg 1700w,
/static/7a2b18b535412ccd4663e743ae4093de/35aef/kelly-sikkema-v9FQR4tbIq8-unsplash.jpg 3400w,
/static/7a2b18b535412ccd4663e743ae4093de/9a201/kelly-sikkema-v9FQR4tbIq8-unsplash.jpg 5100w,
/static/7a2b18b535412ccd4663e743ae4093de/d6b2d/kelly-sikkema-v9FQR4tbIq8-unsplash.jpg 5568w" src="/static/7a2b18b535412ccd4663e743ae4093de/35aef/kelly-sikkema-v9FQR4tbIq8-unsplash.jpg" alt="" style="position:absolute;top:0;left:0;opacity:1;width:100%;height:100%;object-fit:cover;object-position:center"/></picture></noscript></div></div><figcaption class="image-title">Photo by <a href="https://unsplash.com/@kellysikkema">Kelly Sikkema</a> on <a href="https://unsplash.com/s/photos/draw-on-paper">Unsplash</a></figcaption></figure><h1>Design LRU Cache</h1><div class="blog-details"><time class="blog-createdat" dateTime="2021-06-16">Jun 16, 2021</time><span> • </span><span class="blog-time2read">7<!-- --> min read</span><div class="theme-switcher"><div class="theme-switcher-toggler"><div class="theme-switcher-track"></div><div class="theme-switcher-thumb"></div><input type="checkbox" class="theme-switcher-input" readonly="" aria-label="Switch between Dark and Light mode"/></div></div></div><ul class="blog-tags"><li>algorithmic coding</li><li>data structures</li><li>python</li></ul></header><div id="intro" class="blog-divider"></div><div class="content-wrapper"><div class="blog-content-nav-wrapper"><ul class="blog-content-nav"><h2>Content</h2><li class=""><a href="#intro">Intro</a></li></ul></div><div class="content blog-content"><p>While preparing for coding interviews, I went through a large number of algorithmic challenges. I found particularly interesting one subset of problems - challenges related to designing some tools that we all use and rarely stop and think about how they work.</p>
<p>In this article, we are going to take a look at the Least Recently Used (LRU) cache.</p>
<p><strong>Least Recently Used Cache</strong> is a key-value storage that has some capacity and a specific key eviction policy. Whenever it's specified in Gb, percentage of RAM or number of keys, the cache capacity is useful to prevent the storage from overflowing the available memory resources and shutting down unexpectedly.</p>
<p>But what can we do when we are about to reach our capacity limits?</p>
<p>This is where eviction is helpful. In the case of LRU policy, we can just <strong>remove key-values that were not accessed for the longest time</strong> a.k.a least-recently-used items. This is a pretty natural things to do and it's commonly used in such popular key-value storages as Redis.</p>
<p>Another part to pay attention to is cache. <strong>Cache</strong> is a kind of storage that is usually <strong>optimized for reading and retrieving information</strong> that would be time- or resource-consuming to calculate or collect without the cache.</p>
<h2 id="problem-framing" style="position:relative;"><a href="#problem-framing" aria-label="problem framing permalink" class="anchor before"><svg class="anchor-icon" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Problem Framing</h2>
<p>Now we have a broad context around LRU cache use cases and we are ready to formulate the challenge.</p>
<p>We want to design a <strong>class that represents LRU cache and has the following APIs</strong>:</p>
<ul>
<li><code class="language-text">LRUCache(capacity: int)</code> class should be initialized with a capacity of the storage where the capacity is simply a number of keys that storage can hold.</li>
<li><code class="language-text">get(key: int)</code> method which can retrieve the value by key in constant time (O(1)).</li>
<li><code class="language-text">put(key: int, value: int)</code> method which stores key-value pair in the cache in constant time (O(1)). If a key is already in the storage, we need to replace its value with a new one. <code class="language-text">put()</code> method should be constrained by capacity value and should not exceed it. When capacity restriction is about to be reached, we need to evict the least-recently-used item to put a new key-value pair to the storage.</li>
</ul>
<p>Since we are trying to design a cache storage, pretty much every operation should be done in <strong>constant time execution on average</strong> to keep it practically useful. This means that key eviction should also happen in O(1) complexity range.</p>
<h2 id="brainstorm-solutions" style="position:relative;"><a href="#brainstorm-solutions" aria-label="brainstorm solutions permalink" class="anchor before"><svg class="anchor-icon" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Brainstorm Solutions</h2>
<p>When I think about cache, <strong>dictionaries or hashtables</strong> come to my mind.</p>
<p><img src="/29e84368c716f70b2bb4e5dd5bd93402/cache-based-on-hashtable.svg" alt="Cache based on a hashtable" loading="lazy">
          </p>
<div class="image-title">Cache based on a hashtable</div>
<p>Hashtables allow to <strong>read and write key-value pairs in constant time with high probability</strong>. </p>
<p>The problem with dictionaries is that they usually don't guarantee order in which they manage keys. So we don't have a way to quickly remove least-recently-used items. We could introduce a notion of last-used timestamps for each item in the hashtable and update these timestamps during accessing the keys in <code class="language-text">get()</code> method.</p>
<p><img src="/4181faf11cec6c2dc73707b3ebfec8be/cache-based-on-hashtable-with-timestamps.svg" alt="Timestamps won" t help us because of sequential search we need to do on the hashtable' loading="lazy">
          </p>
<div class="image-title">Timestamps won't help us because of sequential search we need to do on the hashtable</div>
<p>However, it would still <strong>take us O(n) in order to find items to evict</strong> by timestamps. It's too time-consuming to meet our requirements.</p>
<p>Let's not get hung up on hashtables. The problem with tracking item usage can be solved with <strong>linked lists</strong>.</p>
<p><img src="/b823d5ec2c9b887180d6ba5d7ce67886/cache-based-on-linked-list.svg" alt="Cache based a linked list" loading="lazy">
          </p>
<div class="image-title">Cache based a linked list</div>
<p>With linked lists, we could <strong>keep track of item usages in constant time</strong>. We could simply move the item we currently access to the top of the list. In a natural way, <strong>least used items end up being at the very bottom of the list</strong> and we would get a list ordered by item usage as we go. Since we need to relink our items, it would be helpful to have reference to the previous and next items on the list.</p>
<p>Nevertheless, linked lists don't meet our requirements completely. It would <strong>take us O(n) in order to find and retrieve item by key</strong>. This is a sad complexity for cache storages.</p>
<p>To sum up, hashtables luck the advantages of linked lists and linked lists luck advantages of hashtables. We find to <strong>find a way to combine hashtables and linked lists</strong> such that we meet our LRU cache requirements.</p>
<h2 id="design-solution" style="position:relative;"><a href="#design-solution" aria-label="design solution permalink" class="anchor before"><svg class="anchor-icon" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Design Solution</h2>
<p>After a little bit of thinking, it may click that we can <strong>map our keys not to the values directly, but to the linked list nodes</strong> that represent these values. Mapping keys to list nodes means that the <strong>dictionary will hold node references</strong> that don't depend on node positions in the list itself. So we would be able to <strong>rearrange list items without a need to remap</strong> them in the dictionary.</p>
<p><img src="/fb18912af9367d01561f7c6906a84459/lru-cache-architecture.svg" alt="LRU Cache Architecture" loading="lazy">
          </p>
<div class="image-title">LRU cache architecture based on combination of hashtable and linked list</div>
<h2 id="implement-solution" style="position:relative;"><a href="#implement-solution" aria-label="implement solution permalink" class="anchor before"><svg class="anchor-icon" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Implement Solution</h2>
<p>Let's start our implementation from create APIs which we want to see in the linked list:</p>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">from</span> typing <span class="token keyword">import</span> Dict<span class="token punctuation">,</span> Optional


<span class="token keyword">class</span> <span class="token class-name">Node</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    Linked List Node. Contains key-value pair and links to neighbor elements.
    """</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> key<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span> value<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span> prev<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token builtin">next</span><span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>key<span class="token punctuation">:</span> <span class="token builtin">int</span> <span class="token operator">=</span> key
        self<span class="token punctuation">.</span>value<span class="token punctuation">:</span> <span class="token builtin">int</span> <span class="token operator">=</span> value

        self<span class="token punctuation">.</span>prev<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span>Node<span class="token punctuation">]</span> <span class="token operator">=</span> prev
        self<span class="token punctuation">.</span><span class="token builtin">next</span><span class="token punctuation">:</span> Optional<span class="token punctuation">[</span>Node<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token builtin">next</span>


<span class="token keyword">class</span> <span class="token class-name">LinkedList</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    Linked List. Represents usage history of cache items
    """</span>
    head<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span>Node<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span>
    tail<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span>Node<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span>

    <span class="token keyword">def</span> <span class="token function">add_to_head</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> item<span class="token punctuation">:</span> Node<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> <span class="token boolean">None</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        Add node to the very top of the list
        """</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>head <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            item<span class="token punctuation">.</span><span class="token builtin">next</span> <span class="token operator">=</span> self<span class="token punctuation">.</span>head
            self<span class="token punctuation">.</span>head<span class="token punctuation">.</span>prev <span class="token operator">=</span> item

        <span class="token keyword">if</span> self<span class="token punctuation">.</span>tail <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>tail <span class="token operator">=</span> item

        self<span class="token punctuation">.</span>head <span class="token operator">=</span> item

    <span class="token keyword">def</span> <span class="token function">unlink</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> item<span class="token punctuation">:</span> Node<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> <span class="token boolean">None</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        Remove references to the node from other nodes on the list
        """</span>
        <span class="token keyword">if</span> item <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            <span class="token keyword">return</span>

        prev_item<span class="token punctuation">:</span> Node <span class="token operator">=</span> item<span class="token punctuation">.</span>prev
        next_item<span class="token punctuation">:</span> Node <span class="token operator">=</span> item<span class="token punctuation">.</span><span class="token builtin">next</span>

        <span class="token comment"># unlink the item node:</span>
        <span class="token comment"># link prev and next items</span>
        <span class="token comment"># removing referenced to the current item node</span>
        <span class="token keyword">if</span> prev_item <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            prev_item<span class="token punctuation">.</span><span class="token builtin">next</span> <span class="token operator">=</span> next_item

        <span class="token keyword">if</span> next_item <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            next_item<span class="token punctuation">.</span>prev <span class="token operator">=</span> prev_item

        <span class="token keyword">if</span> self<span class="token punctuation">.</span>head <span class="token operator">==</span> item<span class="token punctuation">:</span>
            <span class="token comment"># item was the first element in the list</span>
            self<span class="token punctuation">.</span>head <span class="token operator">=</span> next_item

        <span class="token keyword">if</span> self<span class="token punctuation">.</span>tail <span class="token operator">==</span> item<span class="token punctuation">:</span>
            <span class="token comment"># item was the last element in the list</span>
            self<span class="token punctuation">.</span>tail <span class="token operator">=</span> prev_item

        <span class="token comment"># make sure that the item itself doesn't have references to other nodes</span>
        item<span class="token punctuation">.</span>prev <span class="token operator">=</span> <span class="token boolean">None</span>
        item<span class="token punctuation">.</span><span class="token builtin">next</span> <span class="token operator">=</span> <span class="token boolean">None</span></code></pre></div>
<p>All node manipulations (e.g. <code class="language-text">add_to_head()</code>, <code class="language-text">unlink()</code> methods) operates in constant time and doesn't depend on the size of the linked list.</p>
<p>Having a linked list implemented, we can actually code the idea of LRU architecture we came up with:</p>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">LRUCache</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    Implementation of cache storage with LRU eviction policy
    """</span>
    capacity<span class="token punctuation">:</span> <span class="token builtin">int</span>
    cache_map<span class="token punctuation">:</span> Dict<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">,</span> Node<span class="token punctuation">]</span>
    history<span class="token punctuation">:</span> LinkedList

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> capacity<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>capacity <span class="token operator">=</span> capacity
        self<span class="token punctuation">.</span>cache_map <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
        self<span class="token punctuation">.</span>history <span class="token operator">=</span> LinkedList<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">get</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> key<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> <span class="token builtin">int</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        Retrieve value by its key or -1 otherwise
        """</span>
        <span class="token keyword">if</span> key <span class="token keyword">not</span> <span class="token keyword">in</span> self<span class="token punctuation">.</span>cache_map<span class="token punctuation">:</span>
            <span class="token keyword">return</span> <span class="token operator">-</span><span class="token number">1</span>

        value_node<span class="token punctuation">:</span> Node <span class="token operator">=</span> self<span class="token punctuation">.</span>cache_map<span class="token punctuation">[</span>key<span class="token punctuation">]</span>

        <span class="token keyword">if</span> self<span class="token punctuation">.</span>history<span class="token punctuation">.</span>head <span class="token operator">!=</span> value_node<span class="token punctuation">:</span>
            <span class="token comment"># make item the most recently used</span>
            self<span class="token punctuation">.</span>history<span class="token punctuation">.</span>unlink<span class="token punctuation">(</span>value_node<span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>history<span class="token punctuation">.</span>add_to_head<span class="token punctuation">(</span>value_node<span class="token punctuation">)</span>

        <span class="token keyword">return</span> value_node<span class="token punctuation">.</span>value

    <span class="token keyword">def</span> <span class="token function">put</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> key<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span> value<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> <span class="token boolean">None</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        Add a new key-value pair to the cache.
        If key exists, replace its value by a new one.
        If capacity is reached, evict the LRU item and insert a new pair
        """</span>
        value_node<span class="token punctuation">:</span> Node <span class="token operator">=</span> Node<span class="token punctuation">(</span>key<span class="token punctuation">,</span> value<span class="token punctuation">)</span>

        <span class="token keyword">if</span> key <span class="token keyword">in</span> self<span class="token punctuation">.</span>cache_map<span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>remove_item<span class="token punctuation">(</span>self<span class="token punctuation">.</span>cache_map<span class="token punctuation">[</span>key<span class="token punctuation">]</span><span class="token punctuation">)</span>

        <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>cache_map<span class="token punctuation">)</span> <span class="token operator">>=</span> self<span class="token punctuation">.</span>capacity<span class="token punctuation">:</span>
            <span class="token comment"># no space left, needs to evict the least recently used item</span>
            self<span class="token punctuation">.</span>evict_least_recent_item<span class="token punctuation">(</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>history<span class="token punctuation">.</span>add_to_head<span class="token punctuation">(</span>value_node<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>cache_map<span class="token punctuation">[</span>key<span class="token punctuation">]</span> <span class="token operator">=</span> value_node

    <span class="token keyword">def</span> <span class="token function">evict_least_recent_item</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> <span class="token boolean">None</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        Evict the least recently used item
        """</span>
        lru_item<span class="token punctuation">:</span> Node <span class="token operator">=</span> self<span class="token punctuation">.</span>history<span class="token punctuation">.</span>tail

        <span class="token keyword">if</span> lru_item <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            <span class="token keyword">return</span>

        self<span class="token punctuation">.</span>remove_item<span class="token punctuation">(</span>lru_item<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">remove_item</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> item<span class="token punctuation">:</span> Node<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> <span class="token boolean">None</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        Remove item represented by node from the map and the list
        """</span>
        self<span class="token punctuation">.</span>history<span class="token punctuation">.</span>unlink<span class="token punctuation">(</span>item<span class="token punctuation">)</span>

        <span class="token keyword">del</span> self<span class="token punctuation">.</span>cache_map<span class="token punctuation">[</span>item<span class="token punctuation">.</span>key<span class="token punctuation">]</span>
        <span class="token keyword">del</span> item</code></pre></div>
<p>The <code class="language-text">get()</code> and <code class="language-text">put()</code> methods only rely on methods that run in constant time, so our implementation has <strong>constant running time on average</strong>. Just like we have required earlier. In order to get here, we consume <code class="language-text">O(2N)</code> memory to build a map and a linked list.</p>
<p>This solution is common and can be implemented in any general purpose language. Specifically speaking about Python, it provides <code class="language-text">OrderedDict</code> data structure that helps to implement LRU cache in a much <strong>more concise way</strong>. Let's take a look:</p>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">from</span> collections <span class="token keyword">import</span> OrderedDict


<span class="token keyword">class</span> <span class="token class-name">LRUCache</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    This is alternative implementation of LRU cache based on OrderedDict
    """</span>
    capacity<span class="token punctuation">:</span> <span class="token builtin">int</span>
    cache_map<span class="token punctuation">:</span> OrderedDict

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> capacity<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>capacity <span class="token operator">=</span> capacity
        self<span class="token punctuation">.</span>cache_map <span class="token operator">=</span> OrderedDict<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">get</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> key<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> <span class="token builtin">int</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> key <span class="token keyword">not</span> <span class="token keyword">in</span> self<span class="token punctuation">.</span>cache_map<span class="token punctuation">:</span>
            <span class="token keyword">return</span> <span class="token operator">-</span><span class="token number">1</span>

        value <span class="token operator">=</span> self<span class="token punctuation">.</span>cache_map<span class="token punctuation">[</span>key<span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>cache_map<span class="token punctuation">.</span>move_to_end<span class="token punctuation">(</span>key<span class="token punctuation">)</span>

        <span class="token keyword">return</span> value

    <span class="token keyword">def</span> <span class="token function">put</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> key<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span> value<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> <span class="token boolean">None</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> key <span class="token keyword">in</span> self<span class="token punctuation">.</span>cache_map<span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>cache_map<span class="token punctuation">[</span>key<span class="token punctuation">]</span> <span class="token operator">=</span> value
            self<span class="token punctuation">.</span>cache_map<span class="token punctuation">.</span>move_to_end<span class="token punctuation">(</span>key<span class="token punctuation">)</span>
            <span class="token keyword">return</span>

        <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>cache_map<span class="token punctuation">)</span> <span class="token operator">>=</span> self<span class="token punctuation">.</span>capacity<span class="token punctuation">:</span>
            lru_key <span class="token operator">=</span> <span class="token builtin">next</span><span class="token punctuation">(</span><span class="token builtin">iter</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>cache_map<span class="token punctuation">)</span><span class="token punctuation">)</span>
            <span class="token keyword">del</span> self<span class="token punctuation">.</span>cache_map<span class="token punctuation">[</span>lru_key<span class="token punctuation">]</span>

        self<span class="token punctuation">.</span>cache_map<span class="token punctuation">[</span>key<span class="token punctuation">]</span> <span class="token operator">=</span> value</code></pre></div>
<p>OrderedDict seems to be introduced specifically to implement <a href="https://docs.python.org/3/library/collections.html#ordereddict-examples-and-recipes">LRU cache</a>. We may expect that under the hood it has been implemented in a similar way to what we came up with since the runtime and memory usage are pretty the same for both versions.</p>
<h2 id="summary" style="position:relative;"><a href="#summary" aria-label="summary permalink" class="anchor before"><svg class="anchor-icon" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Summary</h2>
<p>We went through designing and implementing our own LRU cache. We combined the advantages of hashtables and linked list and built efficient cache storage on top of them.</p>
<p>Besides being an interesting task, the problem is a common question in the coding interviews. So if you are preparing right now, feel free to implement LRU cache yourself on Leetcode.</p>
<h2 id="references" style="position:relative;"><a href="#references" aria-label="references permalink" class="anchor before"><svg class="anchor-icon" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>References</h2>
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/roma-glushko/leetcode-solutions/blob/master/src/design/lru_cache.py">Implementation on GitHub</a></li>
<li><a target="_blank" rel="noopener" href="https://leetcode.com/problems/lru-cache/">[LeetCode] 146. LRU Cache</a></li>
<li><a target="_blank" rel="noopener" href="https://www.amazon.com/Cracking-Coding-Interview-Programming-Questions/dp/0984782850">Cracking the Coding Interview book by Gayle MacDowell</a></li>
</ul></div></div><div id="content-end"></div></article><div class="social-share-wrapper"><h3>Share Your Love</h3><button aria-label="Share Via Facebook" title="Share Via Facebook" class="react-share__ShareButton social-share-item facebook" style="background-color:transparent;border:none;padding:0;font:inherit;color:inherit;cursor:pointer"><svg aria-hidden="true" focusable="false" data-prefix="fab" data-icon="facebook" class="svg-inline--fa fa-facebook fa-w-16 " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M504 256C504 119 393 8 256 8S8 119 8 256c0 123.78 90.69 226.38 209.25 245V327.69h-63V256h63v-54.64c0-62.15 37-96.48 93.67-96.48 27.14 0 55.52 4.84 55.52 4.84v61h-31.28c-30.8 0-40.41 19.12-40.41 38.73V256h68.78l-11 71.69h-57.78V501C413.31 482.38 504 379.78 504 256z"></path></svg></button><button aria-label="Share Via Twitter" class="react-share__ShareButton social-share-item twitter" style="background-color:transparent;border:none;padding:0;font:inherit;color:inherit;cursor:pointer"><svg aria-hidden="true" focusable="false" data-prefix="fab" data-icon="twitter" class="svg-inline--fa fa-twitter fa-w-16 " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"></path></svg></button><button aria-label="Share Via LinkedIn" class="react-share__ShareButton social-share-item linkedin" style="background-color:transparent;border:none;padding:0;font:inherit;color:inherit;cursor:pointer"><svg aria-hidden="true" focusable="false" data-prefix="fab" data-icon="linkedin-in" class="svg-inline--fa fa-linkedin-in fa-w-14 " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M100.28 448H7.4V148.9h92.88zM53.79 108.1C24.09 108.1 0 83.5 0 53.8a53.79 53.79 0 0 1 107.58 0c0 29.7-24.1 54.3-53.79 54.3zM447.9 448h-92.68V302.4c0-34.7-.7-79.2-48.29-79.2-48.29 0-55.69 37.7-55.69 76.7V448h-92.78V148.9h89.08v40.8h1.3c12.4-23.5 42.69-48.3 87.88-48.3 94 0 111.28 61.9 111.28 142.3V448z"></path></svg></button><button aria-label="Share Via Reddit" class="react-share__ShareButton social-share-item reddit" style="background-color:transparent;border:none;padding:0;font:inherit;color:inherit;cursor:pointer"><svg aria-hidden="true" focusable="false" data-prefix="fab" data-icon="reddit" class="svg-inline--fa fa-reddit fa-w-16 " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M201.5 305.5c-13.8 0-24.9-11.1-24.9-24.6 0-13.8 11.1-24.9 24.9-24.9 13.6 0 24.6 11.1 24.6 24.9 0 13.6-11.1 24.6-24.6 24.6zM504 256c0 137-111 248-248 248S8 393 8 256 119 8 256 8s248 111 248 248zm-132.3-41.2c-9.4 0-17.7 3.9-23.8 10-22.4-15.5-52.6-25.5-86.1-26.6l17.4-78.3 55.4 12.5c0 13.6 11.1 24.6 24.6 24.6 13.8 0 24.9-11.3 24.9-24.9s-11.1-24.9-24.9-24.9c-9.7 0-18 5.8-22.1 13.8l-61.2-13.6c-3-.8-6.1 1.4-6.9 4.4l-19.1 86.4c-33.2 1.4-63.1 11.3-85.5 26.8-6.1-6.4-14.7-10.2-24.1-10.2-34.9 0-46.3 46.9-14.4 62.8-1.1 5-1.7 10.2-1.7 15.5 0 52.6 59.2 95.2 132 95.2 73.1 0 132.3-42.6 132.3-95.2 0-5.3-.6-10.8-1.9-15.8 31.3-16 19.8-62.5-14.9-62.5zM302.8 331c-18.2 18.2-76.1 17.9-93.6 0-2.2-2.2-6.1-2.2-8.3 0-2.5 2.5-2.5 6.4 0 8.6 22.8 22.8 87.3 22.8 110.2 0 2.5-2.2 2.5-6.1 0-8.6-2.2-2.2-6.1-2.2-8.3 0zm7.7-75c-13.6 0-24.6 11.1-24.6 24.9 0 13.6 11.1 24.6 24.6 24.6 13.8 0 24.9-11.1 24.9-24.6 0-13.8-11-24.9-24.9-24.9z"></path></svg></button><button aria-label="Add to Pocket" class="react-share__ShareButton social-share-item pocket" style="background-color:transparent;border:none;padding:0;font:inherit;color:inherit;cursor:pointer"><svg aria-hidden="true" focusable="false" data-prefix="fab" data-icon="get-pocket" class="svg-inline--fa fa-get-pocket fa-w-14 " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M407.6 64h-367C18.5 64 0 82.5 0 104.6v135.2C0 364.5 99.7 464 224.2 464c124 0 223.8-99.5 223.8-224.2V104.6c0-22.4-17.7-40.6-40.4-40.6zm-162 268.5c-12.4 11.8-31.4 11.1-42.4 0C89.5 223.6 88.3 227.4 88.3 209.3c0-16.9 13.8-30.7 30.7-30.7 17 0 16.1 3.8 105.2 89.3 90.6-86.9 88.6-89.3 105.5-89.3 16.9 0 30.7 13.8 30.7 30.7 0 17.8-2.9 15.7-114.8 123.2z"></path></svg></button></div></main><aside class="blogpost-sidebar"><div class="blog-navigation-wrapper"><h3>Read Other Posts</h3><nav class="blog-navigation"><div class="nav-links"><a rel="next" class="next-post" href="/blog/heapify/">Heapify ✌️<!-- --> →</a><a rel="prev" class="prev-post" href="/blog/nature-of-distributed-systems/">← <!-- -->Nature of Distributed Systems</a><a class="all-posts" href="/blog/">All Posts</a></div></nav></div></aside><footer><div class="footer-wrapper"><div class="social"><ul class="social-list"><li class="social-item social-linkedin"><a rel="me" itemProp="url" href="https://www.linkedin.com/in/glushko-roman" title="Roman Glushko on LinkedIn" target="blank"><svg aria-hidden="true" focusable="false" data-prefix="fab" data-icon="linkedin-in" class="svg-inline--fa fa-linkedin-in fa-w-14 fa-2x " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M100.28 448H7.4V148.9h92.88zM53.79 108.1C24.09 108.1 0 83.5 0 53.8a53.79 53.79 0 0 1 107.58 0c0 29.7-24.1 54.3-53.79 54.3zM447.9 448h-92.68V302.4c0-34.7-.7-79.2-48.29-79.2-48.29 0-55.69 37.7-55.69 76.7V448h-92.78V148.9h89.08v40.8h1.3c12.4-23.5 42.69-48.3 87.88-48.3 94 0 111.28 61.9 111.28 142.3V448z"></path></svg><span>LinkedIn</span></a></li><li class="social-item social-github"><a rel="me" itemProp="url" href="https://github.com/roma-glushko" title="Roman Glushko on Github" target="blank"><svg aria-hidden="true" focusable="false" data-prefix="fab" data-icon="github-alt" class="svg-inline--fa fa-github-alt fa-w-15 fa-2x " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 480 512"><path fill="currentColor" d="M186.1 328.7c0 20.9-10.9 55.1-36.7 55.1s-36.7-34.2-36.7-55.1 10.9-55.1 36.7-55.1 36.7 34.2 36.7 55.1zM480 278.2c0 31.9-3.2 65.7-17.5 95-37.9 76.6-142.1 74.8-216.7 74.8-75.8 0-186.2 2.7-225.6-74.8-14.6-29-20.2-63.1-20.2-95 0-41.9 13.9-81.5 41.5-113.6-5.2-15.8-7.7-32.4-7.7-48.8 0-21.5 4.9-32.3 14.6-51.8 45.3 0 74.3 9 108.8 36 29-6.9 58.8-10 88.7-10 27 0 54.2 2.9 80.4 9.2 34-26.7 63-35.2 107.8-35.2 9.8 19.5 14.6 30.3 14.6 51.8 0 16.4-2.6 32.7-7.7 48.2 27.5 32.4 39 72.3 39 114.2zm-64.3 50.5c0-43.9-26.7-82.6-73.5-82.6-18.9 0-37 3.4-56 6-14.9 2.3-29.8 3.2-45.1 3.2-15.2 0-30.1-.9-45.1-3.2-18.7-2.6-37-6-56-6-46.8 0-73.5 38.7-73.5 82.6 0 87.8 80.4 101.3 150.4 101.3h48.2c70.3 0 150.6-13.4 150.6-101.3zm-82.6-55.1c-25.8 0-36.7 34.2-36.7 55.1s10.9 55.1 36.7 55.1 36.7-34.2 36.7-55.1-10.9-55.1-36.7-55.1z"></path></svg><span>GitHub</span></a></li><li class="social-item social-email"><a itemProp="email" href="mailto:roman.glushko.m@gmail.com" title="Roman Glushko&#x27;s Email"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="envelope" class="svg-inline--fa fa-envelope fa-w-16 fa-2x " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"></path></svg><span>Email</span></a></li><li class="social-item social-kaggle"><a rel="me" itemProp="url" href="https://www.kaggle.com/glushko" title="Roman Glushko on Kaggle" target="blank"><svg aria-hidden="true" focusable="false" data-prefix="fab" data-icon="kaggle" class="svg-inline--fa fa-kaggle fa-w-10 fa-2x " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><path fill="currentColor" d="M304.2 501.5L158.4 320.3 298.2 185c2.6-2.7 1.7-10.5-5.3-10.5h-69.2c-3.5 0-7 1.8-10.5 5.3L80.9 313.5V7.5q0-7.5-7.5-7.5H21.5Q14 0 14 7.5v497q0 7.5 7.5 7.5h51.9q7.5 0 7.5-7.5v-109l30.8-29.3 110.5 140.6c3 3.5 6.5 5.3 10.5 5.3h66.9q5.25 0 6-3z"></path></svg><span>Kaggle</span></a></li><li class="social-item social-twitter"><a rel="me" itemProp="url" href="https://twitter.com/roma_glushko" title="Roman Glushko on Twitter" target="blank"><svg aria-hidden="true" focusable="false" data-prefix="fab" data-icon="twitter" class="svg-inline--fa fa-twitter fa-w-16 fa-2x " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"></path></svg><span>Twitter</span></a></li><li class="social-item social-patreon"><a rel="me" itemProp="url" href="https://www.patreon.com/roma_glushko" title="Support my content on Patreon" target="blank"><svg aria-hidden="true" focusable="false" data-prefix="fab" data-icon="patreon" class="svg-inline--fa fa-patreon fa-w-16 fa-2x " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M512 194.8c0 101.3-82.4 183.8-183.8 183.8-101.7 0-184.4-82.4-184.4-183.8 0-101.6 82.7-184.3 184.4-184.3C429.6 10.5 512 93.2 512 194.8zM0 501.5h90v-491H0v491z"></path></svg><span>Patreon</span></a></li></ul></div><div class="copyright">Roman Glushko © 1996 - <!-- -->2021<!-- --> <br/><a rel="license" href="https://creativecommons.org/licenses/by/4.0/" title="Content is published under CC BY 4.0 license">CC BY 4.0</a></div></div></footer><span></span></div></div><div id="gatsby-announcer" style="position:absolute;top:0;width:1px;height:1px;padding:0;overflow:hidden;clip:rect(0, 0, 0, 0);white-space:nowrap;border:0" aria-live="assertive" aria-atomic="true"></div></div><script>
  
  function gaOptout(){document.cookie=disableStr+'=true; expires=Thu, 31 Dec 2099 23:59:59 UTC;path=/',window[disableStr]=!0}var gaProperty='UA-148139633-1',disableStr='ga-disable-'+gaProperty;document.cookie.indexOf(disableStr+'=true')>-1&&(window[disableStr]=!0);
  if(true) {
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  }
  if (typeof ga === "function") {
    ga('create', 'UA-148139633-1', 'auto', {"alwaysSendReferrer":true});
      ga('set', 'anonymizeIp', true);
      
      
      
      
      }</script><script id="gatsby-script-loader">/*<![CDATA[*/window.pagePath="/blog/design-lru-cache/";/*]]>*/</script><script id="gatsby-chunk-mapping">/*<![CDATA[*/window.___chunkMapping={"app":["/app-de8843e408d337e1ffde.js"],"component---cache-caches-gatsby-plugin-offline-app-shell-js":["/component---cache-caches-gatsby-plugin-offline-app-shell-js-b8fe54a3d24900f783e9.js"],"component---src-pages-404-js":["/component---src-pages-404-js-25240c9772eb8843e093.js"],"component---src-pages-blog-js":["/component---src-pages-blog-js-e99c6a8ff37f574b6994.js"],"component---src-pages-cv-ecommerce-developer-js":["/component---src-pages-cv-ecommerce-developer-js-97fb261ffcbf68ef4cf6.js"],"component---src-pages-cv-machine-learning-engineer-js":["/component---src-pages-cv-machine-learning-engineer-js-f6a4567784c2d2989a41.js"],"component---src-pages-index-js":["/component---src-pages-index-js-4601b05a178c23e005e7.js"],"component---src-pages-lab-js":["/component---src-pages-lab-js-51059026fd36c41254be.js"],"component---src-pages-lab-rock-paper-scissors-index-js":["/component---src-pages-lab-rock-paper-scissors-index-js-2c3af61226ebfcb1eef5.js"],"component---src-pages-nn-design-js":["/component---src-pages-nn-design-js-4400cf8669cd6162caac.js"],"component---src-pages-thoughts-js":["/component---src-pages-thoughts-js-d76b231dad86726de755.js"],"component---src-templates-blog-template-js":["/component---src-templates-blog-template-js-8c20b9928e4e055258bf.js"],"component---src-templates-thought-template-js":["/component---src-templates-thought-template-js-e858c9732e8fd76c75b3.js"]};/*]]>*/</script><script src="/component---src-templates-blog-template-js-8c20b9928e4e055258bf.js" async=""></script><script src="/4622c33586ad0108e870f951288ae6aa3beabfab-02f3c1a86851f16b2a8d.js" async=""></script><script src="/418ffc66a997cc995fb5d56035c003ac177781e9-36f98251fe0a8b5a1e7e.js" async=""></script><script src="/b1d143cac6741dab3b540359698892a994dd2b72-5c00bc2a1de84a36b201.js" async=""></script><script src="/7fec078d47fb9647f833e2e6379c6e0182872dcf-593e4006fd0d611c716c.js" async=""></script><script src="/02e3c991cb460df38a850baf561b952fff7f05a7-120d26a5ba92bd694f64.js" async=""></script><script src="/styles-8636a280cbc61d53ad10.js" async=""></script><script src="/app-de8843e408d337e1ffde.js" async=""></script><script src="/framework-68e90182ffbbad46751e.js" async=""></script><script src="/webpack-runtime-e5fcbe9a63e5500432cd.js" async=""></script></body></html>