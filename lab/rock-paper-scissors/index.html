<!DOCTYPE html><html lang="en" class="experiment-view-page"><head><meta charSet="utf-8"/><meta http-equiv="x-ua-compatible" content="ie=edge"/><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/><link rel="stylesheet" href="/styles.d592d42a64a6c9e3b422.css"/><title data-react-helmet="true">Rock, Paper, Scissors Game - Lab by Roman Glushko by Roman Glushko</title><meta data-react-helmet="true" name="description" property="og:description" content="Rock, paper, scissors online game powered by Machine Learning"/><meta data-react-helmet="true" name="keywords" content="rock, paper, scissors, online game, machine learning, deep learning, computer vision"/><meta data-react-helmet="true" name="author" content="@roma_glushko"/><meta data-react-helmet="true" property="og:title" content="Rock, Paper, Scissors Game - Lab by Roman Glushko"/><meta data-react-helmet="true" property="og:type" content="article"/><meta data-react-helmet="true" name="twitter:card" content="summary"/><meta data-react-helmet="true" name="twitter:creator" content="@roma_glushko"/><meta data-react-helmet="true" name="twitter:title" content="Rock, Paper, Scissors Game - Lab by Roman Glushko"/><meta data-react-helmet="true" name="twitter:description" content="Rock, paper, scissors online game powered by Machine Learning"/><meta data-react-helmet="true" property="og:url" content="https://www.romaglushko.com/lab/rock-paper-scissors/"/><link crossorigin="" href="https://utteranc.es" rel="preconnect"/><link crossorigin="" href="https://www.google-analytics.com" rel="preconnect"/><link rel="icon" href="/favicon-32x32.png?v=58a31253e5b93c1d7e74e8a017ff47b3"/><link rel="manifest" href="/manifest.webmanifest"/><meta name="theme-color" content="#ffffff"/><link rel="apple-touch-icon" sizes="48x48" href="/icons/icon-48x48.png?v=58a31253e5b93c1d7e74e8a017ff47b3"/><link rel="apple-touch-icon" sizes="72x72" href="/icons/icon-72x72.png?v=58a31253e5b93c1d7e74e8a017ff47b3"/><link rel="apple-touch-icon" sizes="96x96" href="/icons/icon-96x96.png?v=58a31253e5b93c1d7e74e8a017ff47b3"/><link rel="apple-touch-icon" sizes="144x144" href="/icons/icon-144x144.png?v=58a31253e5b93c1d7e74e8a017ff47b3"/><link rel="apple-touch-icon" sizes="192x192" href="/icons/icon-192x192.png?v=58a31253e5b93c1d7e74e8a017ff47b3"/><link rel="apple-touch-icon" sizes="256x256" href="/icons/icon-256x256.png?v=58a31253e5b93c1d7e74e8a017ff47b3"/><link rel="apple-touch-icon" sizes="384x384" href="/icons/icon-384x384.png?v=58a31253e5b93c1d7e74e8a017ff47b3"/><link rel="apple-touch-icon" sizes="512x512" href="/icons/icon-512x512.png?v=58a31253e5b93c1d7e74e8a017ff47b3"/><link rel="preload" as="font" type="font/woff2" crossorigin="anonymous" href="/static/webfonts/s/dancingscript/v19/If2cXTr6YS-zF4S-kcSWSVi_sxjsohD9F50Ruu7BMSo3Sup8.woff2"/><link rel="preload" as="font" type="font/woff2" crossorigin="anonymous" href="/static/webfonts/s/dancingscript/v19/If2cXTr6YS-zF4S-kcSWSVi_sxjsohD9F50Ruu7B1i03Sup8.woff2"/><link rel="preload" as="font" type="font/woff2" crossorigin="anonymous" href="/static/webfonts/s/ledger/v11/j8_q6-HK1L3if_sBnMrx.woff2"/><style>@font-face{font-family:Dancing Script;font-style:normal;font-weight:400;font-display:swap;src:url(/static/webfonts/s/dancingscript/v19/If2cXTr6YS-zF4S-kcSWSVi_sxjsohD9F50Ruu7BMSo3Sup8.woff2) format("woff2")}@font-face{font-family:Dancing Script;font-style:normal;font-weight:700;font-display:swap;src:url(/static/webfonts/s/dancingscript/v19/If2cXTr6YS-zF4S-kcSWSVi_sxjsohD9F50Ruu7B1i03Sup8.woff2) format("woff2")}@font-face{font-family:Dancing Script;font-style:normal;font-weight:400;font-display:swap;src:url(/static/webfonts/s/dancingscript/v19/If2cXTr6YS-zF4S-kcSWSVi_sxjsohD9F50Ruu7BMSo3Sup6.woff) format("woff")}@font-face{font-family:Dancing Script;font-style:normal;font-weight:700;font-display:swap;src:url(/static/webfonts/s/dancingscript/v19/If2cXTr6YS-zF4S-kcSWSVi_sxjsohD9F50Ruu7B1i03Sup6.woff) format("woff")}@font-face{font-family:Ledger;font-style:normal;font-weight:400;font-display:swap;src:url(/static/webfonts/s/ledger/v11/j8_q6-HK1L3if_sBnMrx.woff2) format("woff2")}@font-face{font-family:Ledger;font-style:normal;font-weight:400;font-display:swap;src:url(/static/webfonts/s/ledger/v11/j8_q6-HK1L3if_sBnMr3.woff) format("woff")}</style><link rel="preconnect dns-prefetch" href="https://www.google-analytics.com"/><link rel="stylesheet"/><script>
    document.addEventListener("DOMContentLoaded", function(event) {
      var hash = window.decodeURI(location.hash.replace('#', ''))
      if (hash !== '') {
        var element = document.getElementById(hash)
        if (element) {
          var scrollTop = window.pageYOffset || document.documentElement.scrollTop || document.body.scrollTop
          var clientTop = document.documentElement.clientTop || document.body.clientTop || 0
          var offset = element.getBoundingClientRect().top + scrollTop - clientTop
          // Wait for the browser to finish rendering before scrolling.
          setTimeout((function() {
            window.scrollTo(0, offset - 0)
          }), 0)
        }
      }
    })
  </script><link rel="canonical" href="https://www.romaglushko.com/lab/rock-paper-scissors/" data-baseprotocol="https:" data-basehost="www.romaglushko.com"/><link rel="sitemap" type="application/xml" href="/sitemap.xml"/><link as="script" rel="preload" href="/webpack-runtime-22fa0e136c234d8b60a6.js"/><link as="script" rel="preload" href="/framework-68e90182ffbbad46751e.js"/><link as="script" rel="preload" href="/app-de8843e408d337e1ffde.js"/><link as="script" rel="preload" href="/styles-8636a280cbc61d53ad10.js"/><link as="script" rel="preload" href="/02e3c991cb460df38a850baf561b952fff7f05a7-120d26a5ba92bd694f64.js"/><link as="script" rel="preload" href="/7fec078d47fb9647f833e2e6379c6e0182872dcf-593e4006fd0d611c716c.js"/><link as="script" rel="preload" href="/b1d143cac6741dab3b540359698892a994dd2b72-73811f87155839f25d7a.js"/><link as="script" rel="preload" href="/6e76804234b65a75c3eddcc8586abf2d892ba14a-f9201cc5b5d3fec3b3b8.js"/><link as="script" rel="preload" href="/418ffc66a997cc995fb5d56035c003ac177781e9-1af6fa4b36bef9e9a491.js"/><link as="script" rel="preload" href="/component---src-pages-lab-rock-paper-scissors-index-js-d194efda58a3ec771c63.js"/><link as="fetch" rel="preload" href="/page-data/lab/rock-paper-scissors/page-data.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/app-data.json" crossorigin="anonymous"/></head><body><script>
void function() {
  window.__onThemeChange = function() {}

  var preferredTheme
  try {
    preferredTheme = localStorage.getItem('theme')
  } catch (err) { }

  function setTheme(newTheme) {
    if (preferredTheme && document.body.classList.contains(preferredTheme)) {
      document.body.classList.replace(preferredTheme, newTheme)
    } else {
      document.body.classList.add(newTheme)
    }

    window.__theme = newTheme
    preferredTheme = newTheme
    window.__onThemeChange(newTheme)
  }

  window.__setPreferredTheme = function(newTheme) {
    setTheme(newTheme)
    try {
      localStorage.setItem('theme', newTheme)
    } catch (err) {}
  }

  var darkQuery = window.matchMedia('(prefers-color-scheme: dark)')
  darkQuery.addListener(function(e) {
    window.__setPreferredTheme(e.matches ? 'dark' : 'light')
  })

  setTheme(preferredTheme || (darkQuery.matches ? 'dark' : 'light'))
}()
    </script><div id="___gatsby"><div style="outline:none" tabindex="-1" id="gatsby-focus-wrapper"><div><header class="experiment-header"><div class="view-page-header"><div class="view-page-header-wrapper"><div class="logo-wrapper"><div class="logo"><div class="logo-img gatsby-image-wrapper" style="position:relative;overflow:hidden"><div aria-hidden="true" style="width:100%;padding-bottom:100%"></div><img aria-hidden="true" src="data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAUABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAAEEBf/EABYBAQEBAAAAAAAAAAAAAAAAAAIBBP/aAAwDAQACEAMQAAABtmSLU1KeLAa+iHm//8QAHBABAAICAwEAAAAAAAAAAAAAAQACAxIEISNB/9oACAEBAAEFAkuCLNbTNl1lczWHZd9vnHfL/8QAGBEAAwEBAAAAAAAAAAAAAAAAAAECMRD/2gAIAQMBAT8BS5OFaf/EABYRAAMAAAAAAAAAAAAAAAAAAAABEP/aAAgBAgEBPwGo/8QAGRAAAgMBAAAAAAAAAAAAAAAAAAEQESES/9oACAEBAAY/ArMuOU9NLQxx/8QAHBABAAICAwEAAAAAAAAAAAAAAQARIVExYXGR/9oACAEBAAE/IXCVlFftHewg5k+Rq7IcxhphiNu2Lii09n//2gAMAwEAAgADAAAAEKAPfP/EABoRAAICAwAAAAAAAAAAAAAAAAABETEhQfD/2gAIAQMBAT8Qa0OVgt7Ref/EABcRAQEBAQAAAAAAAAAAAAAAAAAxARH/2gAIAQIBAT8Q2uNqH//EAB4QAQACAgEFAAAAAAAAAAAAAAEAESExUUFhcYGh/9oACAEBAAE/EKIFxuEXF2cBIp2+ZREzlLBC1DYAUnrr3irELKYzK1D7GCYEbhQw0tz/2Q==" alt="" style="position:absolute;top:0;left:0;width:100%;height:100%;object-fit:cover;object-position:center;opacity:1;transition-delay:500ms"/><noscript><picture><source srcset="/static/7d8b62b999b9a2fb28b8ab360138da37/b13df/photo3.jpg 40w,
/static/7d8b62b999b9a2fb28b8ab360138da37/4e333/photo3.jpg 80w,
/static/7d8b62b999b9a2fb28b8ab360138da37/e75b5/photo3.jpg 160w,
/static/7d8b62b999b9a2fb28b8ab360138da37/40426/photo3.jpg 240w,
/static/7d8b62b999b9a2fb28b8ab360138da37/c01e2/photo3.jpg 320w,
/static/7d8b62b999b9a2fb28b8ab360138da37/b1563/photo3.jpg 3677w" sizes="(max-width: 160px) 100vw, 160px" /><img loading="lazy" sizes="(max-width: 160px) 100vw, 160px" srcset="/static/7d8b62b999b9a2fb28b8ab360138da37/b13df/photo3.jpg 40w,
/static/7d8b62b999b9a2fb28b8ab360138da37/4e333/photo3.jpg 80w,
/static/7d8b62b999b9a2fb28b8ab360138da37/e75b5/photo3.jpg 160w,
/static/7d8b62b999b9a2fb28b8ab360138da37/40426/photo3.jpg 240w,
/static/7d8b62b999b9a2fb28b8ab360138da37/c01e2/photo3.jpg 320w,
/static/7d8b62b999b9a2fb28b8ab360138da37/b1563/photo3.jpg 3677w" src="/static/7d8b62b999b9a2fb28b8ab360138da37/e75b5/photo3.jpg" alt="" style="position:absolute;top:0;left:0;opacity:1;width:100%;height:100%;object-fit:cover;object-position:center"/></picture></noscript></div></div><div class="name"><a href="/lab/" title="back to blog">Roman <br/> Glushko</a></div></div><h2 class="blog-title"><a href="/lab/" title="back to the homepage">Lab</a></h2></div></div><nav class="main-navigation"><ul><li><a rel="home" title="Go Home" href="/">Home</a></li><li><a title="Go to my Technical Blog" href="/blog/">Blog</a></li><li><a title="Go to my Lab" href="/lab/">Lab</a></li><li><a title="Go to my Thoughts" href="/thoughts/">Thoughts</a></li><li><a title="Review My CVs" href="/cv/machine-learning-engineer/">CV</a></li></ul></nav></header><div id="hero-header" class="lab-header"><canvas id="neural-network-background"></canvas><h1 class="title">Rock, Paper, Scissors<br/><span class="experiment-category">computer vision</span></h1></div><main class="rockpaperscissor-wrapper"><div id="intro" class="into content"><p><strong>Rock, paper, scissors</strong> is a legendary hand game that many of us played with friends in childhood.</p><p>Rules are simple. You and your opponent choose one of three shapes (<span aria-label="rock figure" role="img">‚úä</span>, <span aria-label="paper figure" role="img">‚úã</span>, <span aria-label="scissors figure" role="img">‚úåÔ∏è</span>), which you both form simultaneously. Your goal is to guess a shape that beats your opponent&#x27;s choice:</p><ul><li>Rock beats Scissors (<span aria-label="rock figure" role="img">‚úä</span> ‚Üí <span aria-label="beats scissors figure" role="img">‚úåÔ∏è</span>)</li><li>Paper covers Rock (<span aria-label="paper figure" role="img">‚úã</span> ‚Üí <span aria-label="beats rock figure" role="img">‚úä</span>)</li><li>Scissors cuts Paper (<span aria-label="scissors figure" role="img">‚úåÔ∏è</span> ‚Üí <span aria-label="beats paper figure" role="img">‚úã</span>)</li></ul><p>Now you have a chance to try to play rock, paper, scissors in an AI-powered game online.</p><h2>How Does it Work?</h2><p>The game requests your web camera access and loads a computer vision model directly into your browser (the game is completely serverless).</p><p>When you press the play button, you have 3 seconds to form one of three choices and to show it on camera. The model will try to predict what form you showed and compare it with another choice which computer simultaneously made with you. The game compares both choices and updates your scores.</p><p>Try to play until you win!</p></div><h2>Try it Yourself</h2><div class="rock-paper-scissors-wrapper"><section class="game-wrapper"><div class="game" style="filter:blur(3px)"><div class="game-item human"><div class="title">üß† You</div><div class="player human"><video width="300" height="300" style="display:block" class="video-background" playsinline="" autoplay="">No Video</video><canvas width="300" height="300" class="human-choice-image" style="display:none"></canvas><div class="computer-choice-mobile"><div class="title">ü§ñ</div><div class="choice-wrapper"></div></div></div></div><div class="game-item controls"><div class="score">0<!-- --> : <!-- -->0</div><button class="play" disabled=""><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="play" class="svg-inline--fa fa-play fa-w-14 " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M424.4 214.7L72.4 6.6C43.8-10.3 0 6.1 0 47.9V464c0 37.5 40.7 60.1 72.4 41.3l352-208c31.4-18.5 31.5-64.1 0-82.6z"></path></svg> Play</button></div><div class="game-item computer"><div class="title">ü§ñ AI</div><div class="player computer"></div></div></div><div class="game-overlay" style="display:flex"><div class="overlay-message"><h3>Wanna Play?</h3><p>Game requests camera control to see your choices</p><button class="start-game">Start Game üéÆ</button><p>no recordings, the game is serverless</p></div></div></section></div><div class="content"><h2 id="more-about-experiment" style="position:relative;"><a href="#more-about-experiment" aria-label="more about experiment permalink" class="anchor before"><svg class="anchor-icon" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>More About Experiment</h2>
<p>I hope you had a great time playing the game and now you are ready to understand what it took me to build it.</p>
<h3 id="baseline" style="position:relative;"><a href="#baseline" aria-label="baseline permalink" class="anchor before"><svg class="anchor-icon" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Baseline</h3>
<p>All machine learning experiments start with data. I wanted to find some open source datasets I would be able to use to build a quick baseline.</p>
<p>Fortunately, I could find a few datasets on Kaggle that seemed to match the goal. Namely, I picked:</p>
<ul>
<li><a href="https://www.kaggle.com/frtgnn/rock-paper-scissor" target="_blank" rel="noopener noreferrer">[Kaggle] frtgnn/rock-paper-scissor dataset</a></li>
</ul>
<p>Here are how samples from the dataset look like:</p>
<p><span class="gatsby-resp-image-wrapper" style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; ">
      <span class="gatsby-resp-image-background-image" style="padding-bottom: 51.17647058823529%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAABYlAAAWJQFJUiTwAAACI0lEQVQoz1VSaW/TQBD170QIkCo+9UuREOqHqigCREOBinJJ3AgQEuQgVG1pSUISh6YFkta5rzp2A3GUq02bRHZs57G7Tk0YabRez7zZ92aGG41GoE6NnqZhwjRNnNo4NP427bzJkxrF0DtnGAaoN6oyjlotyPksaJo+HLJEKV9APMJDOajaRSZJ6LqOQe/EjnEG+UFDtWIGJWEXlVyWBavlfQixLYgpAW9uL2An8BWlVBqaqlrgMTMhsAH30iIS4Qi7M4Y0qSEWwXtc+Ob2oN1oEOk6vM+eIOj+iJc35rH29hVCnz/ZxQyioFkuIhMKYOX+PdycnkFNFMFR5iedNlKbPsjf/dj2ulAp5BlQkUQsX7mEuzPTcEydR+bnjt0vQ1ORI+zEHzEk1tfxeHYWyShvSdbNEZqFOOSID4kND+qKwoDp7S28dzrwdO4yrl44YxekGPZgWoAU45GLhPDaMYdqIQeONnWoE9m9Ln7zHuwF19DudBigLkv48vwR3jmvYX7qHMqZtMWQtIlJH6pol1Io8H58uHOdDFayCmqaRlyF8suPbDSAXr+P0Xh1ug0FriUnbhHZrXrtvxWhpnUUSNFV8vBDtJUauCFprkqGctw9wj4JCIFVq+AYoPZ78D1YxMLFswiveC3JlCFbHUrTxGE2huCLZaKoAo41mCQMBn1061Uc1v+w3TotSPslZ5LYDQdRTO79W+jJXew2cZCM45gM9y8JhtLLfRCNsAAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;"></span>
  <img class="gatsby-resp-image-image" alt="Samples from frtgnn/rock-paper-scissor dataset" title="Samples from frtgnn/rock-paper-scissor dataset" src="/static/441f18a103219fac79241873ad0cce0a/c5bb3/rps-dataset-preview.png" srcset="/static/441f18a103219fac79241873ad0cce0a/04472/rps-dataset-preview.png 170w,
/static/441f18a103219fac79241873ad0cce0a/9f933/rps-dataset-preview.png 340w,
/static/441f18a103219fac79241873ad0cce0a/c5bb3/rps-dataset-preview.png 680w,
/static/441f18a103219fac79241873ad0cce0a/b12f7/rps-dataset-preview.png 1020w,
/static/441f18a103219fac79241873ad0cce0a/b5a09/rps-dataset-preview.png 1360w,
/static/441f18a103219fac79241873ad0cce0a/e1250/rps-dataset-preview.png 1786w" sizes="(max-width: 680px) 100vw, 680px" style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;" loading="lazy">
    </span>
          </p>
<p>Next, I chose a proper model architecture. I did not want to host my final model anywhere on an external server.</p>
<p>This requirement effectively left me with one single option: to use a small-size model and deploy it to my existing static website via <a href="https://www.tensorflow.org/js" target="_blank" rel="noopener noreferrer">TensorFlow.js</a>.</p>
<p>This thought process brought me to <a href="https://arxiv.org/abs/1704.04861" target="_blank" rel="noopener noreferrer">the MobileNet model architecture</a>.</p>
<p>MobileNet is a popular 2M+ params network that performs very well considering its relatively tiny size. Fortunately, TensorFlow supports a few versions of MobileNet trained on <a href="https://www.image-net.org/" target="_blank" rel="noopener noreferrer">the ImageNet dataset</a>. This meant that I was able to start training from the pre-trained weights. It was actually good as it helped to reduce training time considerably and relaxed a need for a large training dataset.</p>
<p>I wasn't the only one on the Internet who was thinking about this idea, so I was quickly able to a good notebook to build my baseline on:</p>
<ul>
<li><a href="https://colab.research.google.com/github/trekhleb/machine-learning-experiments/blob/master/experiments/rock_paper_scissors_mobilenet_v2/rock_paper_scissors_mobilenet_v2.ipynb" target="_blank" rel="noopener noreferrer">[Google Colab] trekhleb/rock-paper-scissors-mobilenet-v2</a></li>
</ul>
<p>Before doing any experiments I'd configured a few more things:</p>
<ul>
<li>configuration management with <a href="https://github.com/roma-glushko/morty" target="_blank" rel="noopener noreferrer">Morty</a> which is my open source project to track ML/DL experiments</li>
<li>experiment tracking with <a href="https://wandb.com/" target="_blank" rel="noopener noreferrer">Weights &#x26; Biases</a></li>
</ul>
<p>The baseline had been successfully established, however, the results of the model were not that good. It made a lot of misclassifications and it was too early to use it.</p>
<h3 id="collecting-a-custom-dataset" style="position:relative;"><a href="#collecting-a-custom-dataset" aria-label="collecting a custom dataset permalink" class="anchor before"><svg class="anchor-icon" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Collecting a Custom Dataset</h3>
<p>One possible reason for that was the training dataset itself. I assumed that it's distributed differently than images I'd got from my webcam.</p>
<p>Besides possible differences in the hidden technical attributes of photos, my images had different compositions. There were backgrounds, other parts of the body (not only one hand in the picture), different light conditions and things like that.</p>
<p><span class="gatsby-resp-image-wrapper" style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; ">
      <span class="gatsby-resp-image-background-image" style="padding-bottom: 34.11764705882353%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAYAAAAIy204AAAACXBIWXMAABYlAAAWJQFJUiTwAAACBUlEQVQozw3O20tTAQDA4fMavfUQFBYRpaXicqLGbKm16dRt7j7dRXfTeYa6oU4tPXkwPermZaEZKd6aLkEoNCIkUwoE08eee+v/+OXD9/4Jcnscb6WBvoZWJpydyJcWPXF2ktPEzO0Me6MM+6L4dTaay/X49Dakth4CGhNirR3F2oniFsl4esnGxhDm4gNU5eXjf6LHr2+k0+GkQ1VD2i5iV9XTW2/mV/Y9S8l+WuvMaFWVhKst1N1WYS/VkmhyErXZGDDZGamyI/z7fUT4eQ1dDhffFsaYj0UwFaqRzAEiT124q2s53Vtnb0Zif3kWMRwhYnBxll1h0Gaky+lgZTROqiOEu1CDcP5xFVH/jAf3S8ilRvkg9aO7W8wrc5DGy2mX08LB7Dif0jJZ5SWHOxsMeES+TshsxvzMhFpYinpINFtxPKxE2NvcoDsQwNfaxnJmjs9vFGruFDBkbKOioAyDWs1pbp1cRuHkYIe/Fye8UxZIdYtMxEIcr82zJnoZatJhK6pAOPlxjM8XoUz9mLOLczZTMqprN4hb3eRdv8mtK1c5eJsik+yjpbScw+1V5PFplMk0JqOLYCDIn7Of7KYlmktKEY6+7BMOhMm/V4Qsv2ZpfoGgxcVUT5yE0Yo2v5hFaYTvY5O8eKRlrqWdwaREZnqKpgYTarWGjdwu21trBM0W/gP93juZ230qPQAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;"></span>
  <img class="gatsby-resp-image-image" alt="Me collecting samples for a custom rock-paper-scissors dataset" title="Me collecting samples for a custom rock-paper-scissors dataset" src="/static/2746e006200ff3d94e4d02c8fbac796c/c5bb3/rps-custom-dataset.png" srcset="/static/2746e006200ff3d94e4d02c8fbac796c/04472/rps-custom-dataset.png 170w,
/static/2746e006200ff3d94e4d02c8fbac796c/9f933/rps-custom-dataset.png 340w,
/static/2746e006200ff3d94e4d02c8fbac796c/c5bb3/rps-custom-dataset.png 680w,
/static/2746e006200ff3d94e4d02c8fbac796c/b12f7/rps-custom-dataset.png 1020w,
/static/2746e006200ff3d94e4d02c8fbac796c/b5a09/rps-custom-dataset.png 1360w,
/static/2746e006200ff3d94e4d02c8fbac796c/11d70/rps-custom-dataset.png 1802w" sizes="(max-width: 680px) 100vw, 680px" style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;" loading="lazy">
    </span>
          </p>
<p>So I decided not to spend much time trying fancy DL techniques for gradient optimization or learning rate schedule, but, instead, I started improving my dataset.</p>
<p>The goal was clear. I needed to take hundreds of images that would be as close as possible to what I expected my model to work with.</p>
<p>It wasn't super easy as it turned out. I had to group all of the images by classes (rock, paper, scissors). Also, I needed to track the number of images per each class to keep the distribution even among all classes. I needed some workflow to make it easy for me and possibly for other people that would decide to help me with this project.</p>
<p>After a bit of thinking, I had come up with the following project:</p>
<ul>
<li><a href="https://github.com/roma-glushko/campy" target="_blank" rel="noopener noreferrer">[Github] roma-glushko/campy project</a></li>
</ul>
<p>Campy is an Electron-based desktop application that can simply take photos of the same size and put them in the right class folder:</p>
<p><span class="gatsby-resp-image-wrapper" style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; ">
      <span class="gatsby-resp-image-background-image" style="padding-bottom: 71.17647058823529%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAOABQDASIAAhEBAxEB/8QAFwAAAwEAAAAAAAAAAAAAAAAAAAIEBf/EABYBAQEBAAAAAAAAAAAAAAAAAAQAAf/aAAwDAQACEAMQAAABevOsxGkOR//EABkQAAIDAQAAAAAAAAAAAAAAAAADAREhAv/aAAgBAQABBQKW0J6uTBGtP//EABYRAAMAAAAAAAAAAAAAAAAAAAIQQf/aAAgBAwEBPwEqv//EABYRAAMAAAAAAAAAAAAAAAAAAAECEP/aAAgBAgEBPwEpP//EABgQAAIDAAAAAAAAAAAAAAAAABAhABEx/9oACAEBAAY/AqcYxn//xAAaEAEAAwEBAQAAAAAAAAAAAAABACExEUFh/9oACAEBAAE/IUZYv2OVisYXB0rjHuR7ejOE/9oADAMBAAIAAwAAABAU7//EABYRAQEBAAAAAAAAAAAAAAAAAAEQQf/aAAgBAwEBPxAKLJ//xAAXEQADAQAAAAAAAAAAAAAAAAAAAREh/9oACAECAQE/EIOmn//EABsQAQACAwEBAAAAAAAAAAAAAAEAESExQVHB/9oACAEBAAE/EBpSWVXofYrC5KizY12NRzVUPWI+WthtgWif/9k=&apos;); background-size: cover; display: block;"></span>
  <img class="gatsby-resp-image-image" alt="Campy UI" title="Campy UI" src="/static/fddfbff0245672241a0148f7bcb192eb/7bf67/campy.jpg" srcset="/static/fddfbff0245672241a0148f7bcb192eb/651be/campy.jpg 170w,
/static/fddfbff0245672241a0148f7bcb192eb/d30a3/campy.jpg 340w,
/static/fddfbff0245672241a0148f7bcb192eb/7bf67/campy.jpg 680w,
/static/fddfbff0245672241a0148f7bcb192eb/990cb/campy.jpg 1020w,
/static/fddfbff0245672241a0148f7bcb192eb/c44b8/campy.jpg 1360w,
/static/fddfbff0245672241a0148f7bcb192eb/e1596/campy.jpg 2048w" sizes="(max-width: 680px) 100vw, 680px" style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;" loading="lazy">
    </span>
          </p>
<p>The UI could have been sexier, but it'd done its job <span role="img">üòå</span></p>
<p>Having Campy in place helped me to streamline dataset building.</p>
<p>Another important thing is the test dataset. I chose to delegate this part to my girlfriend, so I would be more confident that my model was not learning what I looked like and would work with other people as well. Thankfully, girls like to take pictures, so I came with the right request:</p>
<p><span class="gatsby-resp-image-wrapper" style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; ">
      <span class="gatsby-resp-image-background-image" style="padding-bottom: 34.11764705882353%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAYAAAAIy204AAAACXBIWXMAABYlAAAWJQFJUiTwAAACCUlEQVQozw2QW0tTAQCAD0EQVIYpMoOG5jQvzNFlTlybM93mznY888yZ44SbbXV03rKLOPDWQ6MScTbSNTUTopKWUGhkPpgRlPQDeu2ll/7E137BdxHGosMoLRIhdxc9ngBBl0x7YysD4Zuo3m46bB5EWxvjtyLs59YZH9Xo79Po9YXQero42HzJj+0cnR0yQX8Xgmhxoj9aSvGRQtobLpKeTXChogaH2UZ1sQG7vo4zx47jqKng7dwDkvc0xGY39aWV2M+XkZkY5fvmCwLuNnQnTyNIVhGnsRE1T1AcNnbWlwnJEleaHLRUmRlo8XDd48RUUsTX5Xk2HidQXB6aDCZMuiKm1SD/DveZHdYoK9Eh+B0+0on77KbnmRvQ+PhsgYjsRXK4EPPpqtlCaiSOvb6Oqd4AMcVOJKhgqb1E+akCBj1X2c2DPq0s8i45jZCIRvm1s8X77BJ3FR8zg1Hsxir65AB20Y+1vILbzVa215ZYXXiIuVLHUEzFetlMw7mzTAR8HL5a4VsmRS45g7CX22ApOUnBiUK0bj99kosGgz4/fwhjTTWyoQzNZOTNWJyDzFOUNiuq3Eqw2cKIy8ZyJMTh80WSUZVwp4Tw989vsqkn1Naa6I/FGB+Ko0rtHHzeQvG6CfucefMOXt8ZIxvX+PnlA9n0HLnUI/Yyi6xNTTAZC3PjmoJP9PIfcE4o3Td6OS4AAAAASUVORK5CYII=&apos;); background-size: cover; display: block;"></span>
  <img class="gatsby-resp-image-image" alt="Test Dataset" title="Test Dataset" src="/static/5476c7bbb7a386f4dfedd2b2606d8dfd/c5bb3/rps-custom-test-dataset.png" srcset="/static/5476c7bbb7a386f4dfedd2b2606d8dfd/04472/rps-custom-test-dataset.png 170w,
/static/5476c7bbb7a386f4dfedd2b2606d8dfd/9f933/rps-custom-test-dataset.png 340w,
/static/5476c7bbb7a386f4dfedd2b2606d8dfd/c5bb3/rps-custom-test-dataset.png 680w,
/static/5476c7bbb7a386f4dfedd2b2606d8dfd/b12f7/rps-custom-test-dataset.png 1020w,
/static/5476c7bbb7a386f4dfedd2b2606d8dfd/b5a09/rps-custom-test-dataset.png 1360w,
/static/5476c7bbb7a386f4dfedd2b2606d8dfd/81315/rps-custom-test-dataset.png 1656w" sizes="(max-width: 680px) 100vw, 680px" style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;" loading="lazy">
    </span>
          </p>
<p>As a result, we were able to collect:</p>
<ul>
<li>360+ files per each class in the train dataset</li>
<li>260+ files per each class in the validation dataset</li>
<li>150+ files per each class in the test dataset</li>
</ul>
<p>You can find the final dataset on Kaggle:</p>
<ul>
<li><a href="https://www.kaggle.com/glushko/rock-paper-scissors-dataset" target="_blank" rel="noopener noreferrer">[Kaggle] glushko/rock-paper-scissors-dataset dataset</a></li>
</ul>
<p>For training my model, I used not only images I had taken but also the whole dataset I used to train my baseline model on.</p>
<h3 id="fine-tuning" style="position:relative;"><a href="#fine-tuning" aria-label="fine tuning permalink" class="anchor before"><svg class="anchor-icon" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Fine-Tuning</h3>
<p>The custom dataset helped quite a lot, but there were still a noticeable number of errors.</p>
<p>With my initial model architecture, there was merely one single dense layer that was training at that point. It wasn't really enough to gain a good accuracy in this task. So I went for fine-tuning of my MobileNet network.</p>
<p>I took the best configs I was able to get at that point and started to unfreeze more layers starting from the end of the MobileNet feature extractor. With the RMSProp optimizer and 55 unfrozen layers
layers, I was able to get 93% accuracy on my test dataset and significantly reduce the number of misclassifications which was a way more important for the game.</p>
<p>I ended up with the model that was trained for 50 epochs with:</p>
<ul>
<li>MobileNetV2 (55 unfeezed layers)</li>
<li>RMSprop optimizer (I could not beat it <span role="img">üòÑ</span>) with 0.01 L2 regularization</li>
<li>
<p>Small learning rate (10-4)</p>
<h3 id="deployment" style="position:relative;"><a href="#deployment" aria-label="deployment permalink" class="anchor before"><svg class="anchor-icon" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Deployment</h3>
</li>
</ul>
<p>I did not want to buy any servers or cloud instances to run my tiny little pet project. That was a challenging requirement that left me with few options. The most solid one was to use Tensorflow.js.</p>
<p>Tensorflow.js is a JavaScript frontend library that can load Tensorflow models right into the browser and use them to perform predictions.</p>
<p>You will need to <a href="https://www.tensorflow.org/js/tutorials/conversion/import_keras" target="_blank" rel="noopener noreferrer">convert</a> a Tensorflow model to Tensorflow.js compatible format. This is only possible if you persisted the whole model and not just only the model weights.</p>
<p>Next, your model may fail to load in Tensorflow.js if you used any layers in your Tensorflow model that don't map to any layers on Tensorflow.js side. In my case, I used L2 normalization and I had to implement a new layer to map it on the JS side.</p>
<p>After the model is loaded, it may be very slow at the very first prediction, so you may need to call run your predict method on the dummy tensor to warm up the model during the model initialization.</p>
<p>Finally, Tensorflow.js and your model may add a few megabytes to your download resources that can be harmful to your frontend performance. So be sure you load your model weights and Tensorflow.js only where and when they are needed.</p>
<h3 id="conclusions" style="position:relative;"><a href="#conclusions" aria-label="conclusions permalink" class="anchor before"><svg class="anchor-icon" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Conclusions</h3>
<p>I noticed that building AI-enabled applications, even simple ones, is quite a different story than training models in Jupyter notebooks just for the sake of training and getting the best possible score. You stop evaluating the success of your project by some metrics and you are getting focused on how well your project solves your problem.</p>
<h2 id="resources" style="position:relative;"><a href="#resources" aria-label="resources permalink" class="anchor before"><svg class="anchor-icon" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Resources</h2>
<ul>
<li><a href="https://github.com/roma-glushko/rock-paper-scissors" target="_blank" rel="noopener noreferrer">[Github] roma-glushko/rock-paper-scissors project</a></li>
<li><a href="https://github.com/roma-glushko/romaglushko.com-lab/tree/master/rock-paper-scissors" target="_blank" rel="noopener noreferrer">[Github] Trained Tensorflow.js model</a></li>
<li><a href="https://www.kaggle.com/glushko/rock-paper-scissors-dataset" target="_blank" rel="noopener noreferrer">[Kaggle] glushko/rock-paper-scissors-dataset dataset</a></li>
<li><a href="https://trekhleb.dev/machine-learning-experiments/#/experiments/RockPaperScissorsMobilenetV2" target="_blank" rel="noopener noreferrer">[trekhleb.dev] Rock Paper Scissors (MobilenetV2)</a></li>
</ul></div><div id="content-end"></div><span></span></main><footer><div class="footer-wrapper"><div class="social"><ul class="social-list"><li class="social-item social-linkedin"><a rel="me" itemProp="url" href="https://www.linkedin.com/in/glushko-roman" title="Roman Glushko on LinkedIn" target="blank"><svg aria-hidden="true" focusable="false" data-prefix="fab" data-icon="linkedin-in" class="svg-inline--fa fa-linkedin-in fa-w-14 fa-2x " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M100.28 448H7.4V148.9h92.88zM53.79 108.1C24.09 108.1 0 83.5 0 53.8a53.79 53.79 0 0 1 107.58 0c0 29.7-24.1 54.3-53.79 54.3zM447.9 448h-92.68V302.4c0-34.7-.7-79.2-48.29-79.2-48.29 0-55.69 37.7-55.69 76.7V448h-92.78V148.9h89.08v40.8h1.3c12.4-23.5 42.69-48.3 87.88-48.3 94 0 111.28 61.9 111.28 142.3V448z"></path></svg><span>LinkedIn</span></a></li><li class="social-item social-github"><a rel="me" itemProp="url" href="https://github.com/roma-glushko" title="Roman Glushko on Github" target="blank"><svg aria-hidden="true" focusable="false" data-prefix="fab" data-icon="github-alt" class="svg-inline--fa fa-github-alt fa-w-15 fa-2x " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 480 512"><path fill="currentColor" d="M186.1 328.7c0 20.9-10.9 55.1-36.7 55.1s-36.7-34.2-36.7-55.1 10.9-55.1 36.7-55.1 36.7 34.2 36.7 55.1zM480 278.2c0 31.9-3.2 65.7-17.5 95-37.9 76.6-142.1 74.8-216.7 74.8-75.8 0-186.2 2.7-225.6-74.8-14.6-29-20.2-63.1-20.2-95 0-41.9 13.9-81.5 41.5-113.6-5.2-15.8-7.7-32.4-7.7-48.8 0-21.5 4.9-32.3 14.6-51.8 45.3 0 74.3 9 108.8 36 29-6.9 58.8-10 88.7-10 27 0 54.2 2.9 80.4 9.2 34-26.7 63-35.2 107.8-35.2 9.8 19.5 14.6 30.3 14.6 51.8 0 16.4-2.6 32.7-7.7 48.2 27.5 32.4 39 72.3 39 114.2zm-64.3 50.5c0-43.9-26.7-82.6-73.5-82.6-18.9 0-37 3.4-56 6-14.9 2.3-29.8 3.2-45.1 3.2-15.2 0-30.1-.9-45.1-3.2-18.7-2.6-37-6-56-6-46.8 0-73.5 38.7-73.5 82.6 0 87.8 80.4 101.3 150.4 101.3h48.2c70.3 0 150.6-13.4 150.6-101.3zm-82.6-55.1c-25.8 0-36.7 34.2-36.7 55.1s10.9 55.1 36.7 55.1 36.7-34.2 36.7-55.1-10.9-55.1-36.7-55.1z"></path></svg><span>GitHub</span></a></li><li class="social-item social-email"><a itemProp="email" href="mailto:roman.glushko.m@gmail.com" title="Roman Glushko&#x27;s Email"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="envelope" class="svg-inline--fa fa-envelope fa-w-16 fa-2x " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"></path></svg><span>Email</span></a></li><li class="social-item social-kaggle"><a rel="me" itemProp="url" href="https://www.kaggle.com/glushko" title="Roman Glushko on Kaggle" target="blank"><svg aria-hidden="true" focusable="false" data-prefix="fab" data-icon="kaggle" class="svg-inline--fa fa-kaggle fa-w-10 fa-2x " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><path fill="currentColor" d="M304.2 501.5L158.4 320.3 298.2 185c2.6-2.7 1.7-10.5-5.3-10.5h-69.2c-3.5 0-7 1.8-10.5 5.3L80.9 313.5V7.5q0-7.5-7.5-7.5H21.5Q14 0 14 7.5v497q0 7.5 7.5 7.5h51.9q7.5 0 7.5-7.5v-109l30.8-29.3 110.5 140.6c3 3.5 6.5 5.3 10.5 5.3h66.9q5.25 0 6-3z"></path></svg><span>Kaggle</span></a></li><li class="social-item social-twitter"><a rel="me" itemProp="url" href="https://twitter.com/roma_glushko" title="Roman Glushko on Twitter" target="blank"><svg aria-hidden="true" focusable="false" data-prefix="fab" data-icon="twitter" class="svg-inline--fa fa-twitter fa-w-16 fa-2x " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"></path></svg><span>Twitter</span></a></li><li class="social-item social-patreon"><a rel="me" itemProp="url" href="https://www.patreon.com/roma_glushko" title="Support my content on Patreon" target="blank"><svg aria-hidden="true" focusable="false" data-prefix="fab" data-icon="patreon" class="svg-inline--fa fa-patreon fa-w-16 fa-2x " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M512 194.8c0 101.3-82.4 183.8-183.8 183.8-101.7 0-184.4-82.4-184.4-183.8 0-101.6 82.7-184.3 184.4-184.3C429.6 10.5 512 93.2 512 194.8zM0 501.5h90v-491H0v491z"></path></svg><span>Patreon</span></a></li></ul></div><div class="copyright">Roman Glushko ¬© 1996 - <!-- -->2021<!-- --> <br/><a rel="license" href="https://creativecommons.org/licenses/by/4.0/" title="Content is published under CC BY 4.0 license">CC BY 4.0</a></div></div></footer></div></div><div id="gatsby-announcer" style="position:absolute;top:0;width:1px;height:1px;padding:0;overflow:hidden;clip:rect(0, 0, 0, 0);white-space:nowrap;border:0" aria-live="assertive" aria-atomic="true"></div></div><script>
  
  function gaOptout(){document.cookie=disableStr+'=true; expires=Thu, 31 Dec 2099 23:59:59 UTC;path=/',window[disableStr]=!0}var gaProperty='UA-148139633-1',disableStr='ga-disable-'+gaProperty;document.cookie.indexOf(disableStr+'=true')>-1&&(window[disableStr]=!0);
  if(true) {
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  }
  if (typeof ga === "function") {
    ga('create', 'UA-148139633-1', 'auto', {"alwaysSendReferrer":true});
      ga('set', 'anonymizeIp', true);
      
      
      
      
      }</script><script id="gatsby-script-loader">/*<![CDATA[*/window.pagePath="/lab/rock-paper-scissors/";/*]]>*/</script><script id="gatsby-chunk-mapping">/*<![CDATA[*/window.___chunkMapping={"app":["/app-de8843e408d337e1ffde.js"],"component---cache-caches-gatsby-plugin-offline-app-shell-js":["/component---cache-caches-gatsby-plugin-offline-app-shell-js-b8fe54a3d24900f783e9.js"],"component---src-pages-404-js":["/component---src-pages-404-js-25240c9772eb8843e093.js"],"component---src-pages-blog-js":["/component---src-pages-blog-js-cd273d639f0c9691a332.js"],"component---src-pages-cv-ecommerce-developer-js":["/component---src-pages-cv-ecommerce-developer-js-cf15df876b34bbb8fc55.js"],"component---src-pages-cv-machine-learning-engineer-js":["/component---src-pages-cv-machine-learning-engineer-js-1ae8099fd502a0f227f7.js"],"component---src-pages-index-js":["/component---src-pages-index-js-2a007b8adef1fde76add.js"],"component---src-pages-lab-js":["/component---src-pages-lab-js-d551f847ebf4bda5e3b4.js"],"component---src-pages-lab-rock-paper-scissors-index-js":["/component---src-pages-lab-rock-paper-scissors-index-js-d194efda58a3ec771c63.js"],"component---src-pages-nn-design-js":["/component---src-pages-nn-design-js-4400cf8669cd6162caac.js"],"component---src-pages-thoughts-js":["/component---src-pages-thoughts-js-d76b231dad86726de755.js"],"component---src-templates-blog-template-js":["/component---src-templates-blog-template-js-95e00e24c0c08926f00c.js"],"component---src-templates-thought-template-js":["/component---src-templates-thought-template-js-5d3117151848a0aee9c1.js"]};/*]]>*/</script><script src="/component---src-pages-lab-rock-paper-scissors-index-js-d194efda58a3ec771c63.js" async=""></script><script src="/418ffc66a997cc995fb5d56035c003ac177781e9-1af6fa4b36bef9e9a491.js" async=""></script><script src="/6e76804234b65a75c3eddcc8586abf2d892ba14a-f9201cc5b5d3fec3b3b8.js" async=""></script><script src="/b1d143cac6741dab3b540359698892a994dd2b72-73811f87155839f25d7a.js" async=""></script><script src="/7fec078d47fb9647f833e2e6379c6e0182872dcf-593e4006fd0d611c716c.js" async=""></script><script src="/02e3c991cb460df38a850baf561b952fff7f05a7-120d26a5ba92bd694f64.js" async=""></script><script src="/styles-8636a280cbc61d53ad10.js" async=""></script><script src="/app-de8843e408d337e1ffde.js" async=""></script><script src="/framework-68e90182ffbbad46751e.js" async=""></script><script src="/webpack-runtime-22fa0e136c234d8b60a6.js" async=""></script></body></html>